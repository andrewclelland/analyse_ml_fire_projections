{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15c4fe9-86b2-45da-bf95-4cc3e57155ac",
   "metadata": {},
   "source": [
    "Notebook to conduct a full analyis of burned area, climate and fire weather indices on an individual ecoregion level.\n",
    "\n",
    "Includes the bias correction process for each climate/fire weather variable. Also includes code to set Winter months to 0 (where necessary) if erroneous values exist.\n",
    "\n",
    "Edit file paths as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81661346-8abc-491a-99ac-55430f84e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d766f207-6833-4b58-be98-b486fa1adc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "# Specify region and root folder\n",
    "region = 'nortsib'\n",
    "region_model = 'nesibco'\n",
    "root = f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}'\n",
    "\n",
    "# Import processed model data\n",
    "df_model = pd.read_csv(f'/home/users/clelland/Model/Analysis/Ecoregion plots combined/area_timeseries_{region_model}_all.csv', parse_dates=['time'], index_col='time')\n",
    "df_actual = pd.read_csv('/home/users/clelland/Model/Analysis/Fire actual 2001-2024.csv', parse_dates=['date'], index_col='date')[f'{region}']\n",
    "\n",
    "# Import CSV files from folder\n",
    "df_e5l = pd.read_csv(f'{root}/e5l_2001_2023_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_access_hist_climate = pd.read_csv(f'{root}/access_climate_2001_2014_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_access_126_climate = pd.read_csv(f'{root}/access_ssp126_climate_2015_2100_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_access_245_climate = pd.read_csv(f'{root}/access_ssp245_climate_2015_2100_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_access_370_climate = pd.read_csv(f'{root}/access_ssp370_climate_2015_2100_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_mri_hist_climate = pd.read_csv(f'{root}/mri_climate_2001_2014_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_mri_126_climate = pd.read_csv(f'{root}/mri_ssp126_climate_2015_2100_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_mri_245_climate = pd.read_csv(f'{root}/mri_ssp245_climate_2015_2100_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_mri_370_climate = pd.read_csv(f'{root}/mri_ssp370_climate_2015_2100_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_cems = pd.read_csv(f'{root}/cems_2001_2023_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_access_hist_fwi = pd.read_csv(f'{root}/access_fwi_2001_2014_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_access_126_fwi = pd.read_csv(f'{root}/access_ssp126_fwi_2015_2100_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_access_245_fwi = pd.read_csv(f'{root}/access_ssp245_fwi_2015_2100_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_access_370_fwi = pd.read_csv(f'{root}/access_ssp370_fwi_2015_2100_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_mri_hist_fwi = pd.read_csv(f'{root}/mri_fwi_2001_2014_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_mri_126_fwi = pd.read_csv(f'{root}/mri_ssp126_fwi_2015_2100_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_mri_245_fwi = pd.read_csv(f'{root}/mri_ssp245_fwi_2015_2100_{region}.csv', parse_dates=['date'], index_col='date')\n",
    "df_mri_370_fwi = pd.read_csv(f'{root}/mri_ssp370_fwi_2015_2100_{region}.csv', parse_dates=['date'], index_col='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504cc4f2-b470-456f-94cc-fbbd35272703",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596d7728-88c4-4af8-9cee-ca59a8f00f62",
   "metadata": {},
   "source": [
    "## BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb57df7-9c3e-4d0b-8e57-e27b00f9dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ba\n",
    "df_ba = pd.DataFrame({\n",
    "    'Actual': df_actual,\n",
    "    'ACCESS_SSP126': df_model['access 126'],\n",
    "    'ACCESS_SSP245': df_model['access 245'],\n",
    "    'ACCESS_SSP370': df_model['access 370'],\n",
    "    'MRI_SSP126': df_model['mri 126'],\n",
    "    'MRI_SSP245': df_model['mri 245'],\n",
    "    'MRI_SSP370': df_model['mri 370']\n",
    "})\n",
    "\n",
    "df_ba.sort_index(inplace=True)\n",
    "\n",
    "# Divide columns by a scaling factor\n",
    "df_ba.iloc[:, 1:4] = df_ba.iloc[:, 1:4] / 16 # ACCESS\n",
    "df_ba.iloc[:, 4:7] = df_ba.iloc[:, 4:7] / 8 # MRI\n",
    "df_ba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f4f76d-76fb-43fb-98f8-1b97c513cc36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### BA Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698165bc-1d08-4952-9e6f-f2226da78a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_plot = df_ba.copy()\n",
    "df_ba_plot.index = pd.to_datetime(df_ba_plot.index)\n",
    "df_ba_plot = df_ba_plot.resample('YE').sum()\n",
    "df_ba_plot.index = df_ba_plot.index + pd.offsets.Day(1)\n",
    "df_ba_plot.index = df_ba_plot.index - pd.offsets.YearBegin(1)\n",
    "df_ba_plot = df_ba_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot first column (only up to 2024)\n",
    "first_col = df_ba_plot.columns[0]\n",
    "df_first = df_ba_plot.loc[:'2024-12-31', first_col]\n",
    "plt.plot(df_first.index, df_first, label=first_col, linewidth=2)\n",
    "\n",
    "# Add extreme year dashed line\n",
    "mean_actual = df_first.mean()\n",
    "std_actual = df_first.std()\n",
    "threshold = mean_actual + 2 * std_actual\n",
    "plt.axhline(threshold, color='gray', linestyle='--', linewidth=1.5)\n",
    "\n",
    "# Plot all other columns (from 2025 onwards)\n",
    "for column in df_ba_plot.columns[1:]:\n",
    "    df_other = df_ba_plot.loc['2025-01-01':, column]\n",
    "    plt.plot(df_other.index, df_other, label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='5YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(f'BA Time Series Yearly sum for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mha')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/ba_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1cd689-e1cf-4083-8bd1-a30e4ed8a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ba_plot.loc[:'2024-01-01']['Actual'].mean())\n",
    "print(df_ba_plot.loc['2025-01-01':]['Model ACCESS_SSP126'].mean())\n",
    "print(df_ba_plot.loc['2025-01-01':]['Model ACCESS_SSP245'].mean())\n",
    "print(df_ba_plot.loc['2025-01-01':]['Model ACCESS_SSP370'].mean())\n",
    "print(df_ba_plot.loc['2025-01-01':]['Model MRI_SSP126'].mean())\n",
    "print(df_ba_plot.loc['2025-01-01':]['Model MRI_SSP245'].mean())\n",
    "print(df_ba_plot.loc['2025-01-01':]['Model MRI_SSP370'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09d73f4-5afd-4cf8-906f-1a77b0963dea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Actual seasonal BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c7b46c-eabf-4ed1-bf87-b652dca960be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL BA PER DECADE - ACTUAL ONLY\n",
    "# Step 1: Add year, month, and decade columns\n",
    "df_season = df_ba.copy().reset_index().rename(columns={'index':'time'})\n",
    "df_season['time'] = pd.to_datetime(df_season['time'])\n",
    "df_season.set_index('time', inplace=True)\n",
    "df_season = df_season.loc[:'2024-12-31']\n",
    "\n",
    "df_season['year'] = df_season.index.year\n",
    "df_season['month'] = df_season.index.month\n",
    "df_season['decade'] = ((df_season['year'] - 1) // 10) * 10 + 1\n",
    "\n",
    "burn_column = 'Actual'\n",
    "\n",
    "# Step 3: Group by decade and month, summing the burn values\n",
    "monthly_burn = df_season.groupby(['decade', 'month'])[burn_column].sum()\n",
    "\n",
    "# Step 4: Calculate yearly totals for each decade\n",
    "yearly_totals = df_season.groupby('decade')[burn_column].sum()\n",
    "\n",
    "# Step 5: Calculate percentage of yearly burn for each month in each decade\n",
    "percent_burn = monthly_burn.div(yearly_totals, level='decade') * 100\n",
    "\n",
    "# Step 6: Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "for decade in percent_burn.index.levels[0]:  # Loop over each decade\n",
    "    label = f\"{decade - 1}s\"\n",
    "    plt.plot(percent_burn.loc[decade].index, percent_burn.loc[decade].values, label=label) # e.g., 2021 â†’ \"2020s\"\n",
    "\n",
    "plt.xticks(ticks=range(1, 13), labels=[\n",
    "    'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'\n",
    "])\n",
    "\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Percent of Yearly Burn (%)')\n",
    "plt.title(f'Actual Total Monthly Burn Percentages by Decade for {region}')\n",
    "plt.grid(True)\n",
    "plt.legend(title='Decade')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/ba_seasonality_plot_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e235f908-aa3b-4dab-9ef1-f48bc95b2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEAN BA AND SD PER DECADE - ACTUAL ONLY\n",
    "# Step 1: Add year, month, and decade columns (already done)\n",
    "df_season = df_ba.copy().reset_index().rename(columns={'index':'time'})\n",
    "df_season['time'] = pd.to_datetime(df_season['time'])\n",
    "df_season.set_index('time', inplace=True)\n",
    "df_season = df_season.loc[:'2024-12-31']\n",
    "\n",
    "df_season['year'] = df_season.index.year\n",
    "df_season['month'] = df_season.index.month\n",
    "df_season['decade'] = ((df_season['year'] - 1) // 10) * 10 + 1\n",
    "\n",
    "burn_column = 'Actual'\n",
    "\n",
    "# Step 2: Group by decade, year, and month to compute actual monthly burn\n",
    "monthly_grouped = df_season.groupby(['decade', 'year', 'month'])[burn_column].sum()\n",
    "\n",
    "# Step 3: Compute yearly totals per decade and year\n",
    "yearly_grouped = df_season.groupby(['decade', 'year'])[burn_column].sum()\n",
    "\n",
    "# Step 4: Calculate percent of yearly burn per month per year\n",
    "# We need to divide monthly values by the corresponding yearly total\n",
    "monthly_percent = monthly_grouped / yearly_grouped.loc[monthly_grouped.index.droplevel('month')] * 100\n",
    "\n",
    "# Step 5: Calculate mean and std dev across years for each decade and month\n",
    "mean_percent = monthly_percent.groupby(['decade', 'month']).mean()\n",
    "std_percent = monthly_percent.groupby(['decade', 'month']).std()\n",
    "\n",
    "# Step 6: Plot with error bars\n",
    "plt.figure(figsize=(10, 6))\n",
    "for decade in mean_percent.index.levels[0]:\n",
    "    label = f\"{decade - 1}s\"\n",
    "    months = mean_percent.loc[decade].index\n",
    "    values = mean_percent.loc[decade].values\n",
    "    errors = std_percent.loc[decade].values\n",
    "\n",
    "    # Calculate upper and lower bounds, ensuring lower bound is not negative\n",
    "    lower = np.maximum(values - errors, 0)\n",
    "    upper = np.minimum(values + errors, 100)\n",
    "\n",
    "    # Plot mean line\n",
    "    plt.plot(months, values, label=label)\n",
    "\n",
    "    # Plot shaded area for Â±1 standard deviation\n",
    "    plt.fill_between(\n",
    "        months,\n",
    "        lower,\n",
    "        upper,\n",
    "        alpha=0.2\n",
    "    )\n",
    "\n",
    "plt.xticks(ticks=range(1, 13), labels=[\n",
    "    'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'\n",
    "])\n",
    "\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Percent of Yearly Burn (%)')\n",
    "plt.title(f'Actual Mean Monthly Burn Percentages by Decade for {region}\\n(with standard deviation)')\n",
    "plt.grid(True)\n",
    "plt.legend(title='Decade')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/ba_seasonality_plot_with_sd_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcbc32b-c08d-48fc-9aa3-44b29e966ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL INDIVIDUAL YEARS PER SCENARIO - ACTUAL\n",
    "# Step 1: Add year, month, and decade columns\n",
    "df_season = df_ba.copy().reset_index().rename(columns={'index':'time'})\n",
    "df_season['time'] = pd.to_datetime(df_season['time'])\n",
    "df_season.set_index('time', inplace=True)\n",
    "df_season = df_season.loc[:'2024-12-31']\n",
    "\n",
    "# Step 1: Add year, month columns\n",
    "df_season['year'] = df_season.index.year\n",
    "df_season['month'] = df_season.index.month\n",
    "\n",
    "burn_column = 'Actual'\n",
    "\n",
    "# Step 3: Group by year and month, summing the burn values\n",
    "monthly_burn = df_season.groupby(['year', 'month'])[burn_column].sum()\n",
    "\n",
    "# Step 4: Calculate yearly totals for each year\n",
    "yearly_totals = df_season.groupby('year')[burn_column].sum()\n",
    "\n",
    "# Step 5: Calculate percentage of yearly burn for each month in each year\n",
    "percent_burn = monthly_burn.div(yearly_totals, level='year') * 100\n",
    "\n",
    "# Step 6: Set up colormap and get a color gradient\n",
    "cmap = cm.viridis\n",
    "norm = plt.Normalize(vmin=percent_burn.index.get_level_values('year').min(),\n",
    "                     vmax=percent_burn.index.get_level_values('year').max())\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Step 7: Plot each year with a different shade\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for year in percent_burn.index.levels[0]:  # Loop over each year\n",
    "    color = cmap(norm(year))  # Get color for the year from the colormap\n",
    "    ax.plot(percent_burn.loc[year].index, percent_burn.loc[year].values, color=color)\n",
    "\n",
    "# Step 8: Add colorbar to the right of the plot\n",
    "cbar = fig.colorbar(sm, ax=ax, pad=0.01)\n",
    "cbar.set_label('Year')\n",
    "\n",
    "# Step 9: Set labels and title\n",
    "ax.set_xticks(range(1, 13))\n",
    "ax.set_xticklabels([\n",
    "    'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'\n",
    "])\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Percent of Yearly Burn (%)')\n",
    "ax.set_title(f'Actual Monthly Burn Percentages by Year for {region}')\n",
    "ax.grid(True)\n",
    "\n",
    "# Step 10: Show the plot\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/ba_seasonality_plot_all_years_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3da39-e87a-4796-934d-8a570a459b3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model seasonal BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd056c-85a0-4e64-bef4-5c99ee9f33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL BA PER DECADE - MODEL ONLY\n",
    "# Step 1: Add year, month, and decade columns\n",
    "df_season = df_ba.copy().reset_index().rename(columns={'index':'time'})\n",
    "df_season['time'] = pd.to_datetime(df_season['time'])\n",
    "df_season.set_index('time', inplace=True)\n",
    "df_season = df_season.loc['2025-01-01':]\n",
    "\n",
    "df_season['year'] = df_season.index.year\n",
    "df_season['month'] = df_season.index.month\n",
    "df_season['decade'] = ((df_season['year'] - 1) // 10) * 10 + 1\n",
    "\n",
    "# Step 2: Choose the column of interest\n",
    "burn_column = 'MRI_SSP370'\n",
    "\n",
    "# Step 3: Group by decade and month, summing the burn values\n",
    "monthly_burn = df_season.groupby(['decade', 'month'])[burn_column].sum()\n",
    "\n",
    "# Step 4: Calculate yearly totals for each decade\n",
    "yearly_totals = df_season.groupby('decade')[burn_column].sum()\n",
    "\n",
    "# Step 5: Calculate percentage of yearly burn for each month in each decade\n",
    "percent_burn = monthly_burn.div(yearly_totals, level='decade') * 100\n",
    "\n",
    "# Step 6: Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "for decade in percent_burn.index.levels[0]:  # Loop over each decade\n",
    "    label = f\"{decade - 1}s\"\n",
    "    plt.plot(percent_burn.loc[decade].index, percent_burn.loc[decade].values, label=label) # e.g., 2021 â†’ \"2020s\"\n",
    "\n",
    "plt.xticks(ticks=range(1, 13), labels=[\n",
    "    'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'\n",
    "])\n",
    "\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Percent of Yearly Burn (%)')\n",
    "plt.title(f'Monthly Total Burn Percentages by Decade for {region} {burn_column}')\n",
    "plt.grid(True)\n",
    "plt.legend(title='Decade')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/ba_seasonality_plot_{region}_mri_370_2025_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8a1233-a692-4c4c-bd6e-8899ba733a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEAN BA AND SD PER DECADE - MODEL ONLY\n",
    "# Step 1: Add year, month, and decade columns (already done)\n",
    "df_season = df_ba.copy().reset_index().rename(columns={'index':'time'})\n",
    "df_season['time'] = pd.to_datetime(df_season['time'])\n",
    "df_season.set_index('time', inplace=True)\n",
    "df_season = df_season.loc['2025-01-01':]\n",
    "\n",
    "df_season['year'] = df_season.index.year\n",
    "df_season['month'] = df_season.index.month\n",
    "df_season['decade'] = ((df_season['year'] - 1) // 10) * 10 + 1\n",
    "\n",
    "# Step 2: Choose the column of interest\n",
    "burn_column = 'ACCESS_SSP126'\n",
    "\n",
    "# Step 2: Group by decade, year, and month to compute actual monthly burn\n",
    "monthly_grouped = df_season.groupby(['decade', 'year', 'month'])[burn_column].sum()\n",
    "\n",
    "# Step 3: Compute yearly totals per decade and year\n",
    "yearly_grouped = df_season.groupby(['decade', 'year'])[burn_column].sum()\n",
    "\n",
    "# Step 4: Calculate percent of yearly burn per month per year\n",
    "# We need to divide monthly values by the corresponding yearly total\n",
    "monthly_percent = monthly_grouped / yearly_grouped.loc[monthly_grouped.index.droplevel('month')] * 100\n",
    "\n",
    "# Step 5: Calculate mean and std dev across years for each decade and month\n",
    "mean_percent = monthly_percent.groupby(['decade', 'month']).mean()\n",
    "std_percent = monthly_percent.groupby(['decade', 'month']).std()\n",
    "\n",
    "# Step 6: Plot with error bars\n",
    "plt.figure(figsize=(10, 6))\n",
    "for decade in mean_percent.index.levels[0]:\n",
    "    label = f\"{decade - 1}s\"\n",
    "    months = mean_percent.loc[decade].index\n",
    "    values = mean_percent.loc[decade].values\n",
    "    errors = std_percent.loc[decade].values\n",
    "\n",
    "    # Calculate upper and lower bounds, ensuring lower bound is not negative\n",
    "    lower = np.maximum(values - errors, 0)\n",
    "    upper = np.minimum(values + errors, 100)\n",
    "\n",
    "    # Plot mean line\n",
    "    plt.plot(months, values, label=label)\n",
    "\n",
    "    # Plot shaded area for Â±1 standard deviation\n",
    "    plt.fill_between(\n",
    "        months,\n",
    "        lower,\n",
    "        upper,\n",
    "        alpha=0.2\n",
    "    )\n",
    "    \n",
    "plt.xticks(ticks=range(1, 13), labels=[\n",
    "    'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'\n",
    "])\n",
    "\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Percent of Yearly Burn (%)')\n",
    "plt.title(f'Monthly Mean Burn Percentages by Decade for {region} {burn_column} \\n(with standard deviation)')\n",
    "plt.grid(True)\n",
    "plt.legend(title='Decade')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/ba_seasonality_plot_with_sd_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e38f67-85b1-4f75-b4a4-efc626f26aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate monthly percent per year (revised method from before)\n",
    "df_season = df_ba.copy().reset_index().rename(columns={'index': 'time'})\n",
    "df_season['time'] = pd.to_datetime(df_season['time'])\n",
    "df_season.set_index('time', inplace=True)\n",
    "df_season = df_season.loc['2025-01-01':]\n",
    "\n",
    "df_season['year'] = df_season.index.year\n",
    "df_season['month'] = df_season.index.month\n",
    "\n",
    "burn_column = 'ACCESS_SSP126'\n",
    "\n",
    "# Total burn per year\n",
    "yearly_totals = df_season.groupby(['year'])[burn_column].sum()\n",
    "\n",
    "# Monthly burn\n",
    "monthly_burn = df_season.groupby(['year', 'month'])[burn_column].sum()\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "monthly_burn_df = monthly_burn.reset_index()\n",
    "monthly_burn_df['yearly_total'] = monthly_burn_df['year'].map(yearly_totals)\n",
    "\n",
    "# Compute percent\n",
    "monthly_burn_df['percent'] = monthly_burn_df[burn_column] / monthly_burn_df['yearly_total'] * 100\n",
    "\n",
    "# Add date for plotting\n",
    "monthly_burn_df['date'] = pd.to_datetime(dict(year=monthly_burn_df['year'],\n",
    "                                              month=monthly_burn_df['month'],\n",
    "                                              day=15))\n",
    "monthly_burn_df.set_index('date', inplace=True)\n",
    "\n",
    "# Pivot the data to have years as columns, months as rows\n",
    "heatmap_data = monthly_burn_df.pivot(index='month', columns='year', values='percent')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.heatmap(heatmap_data, cmap='YlOrRd', linewidths=0.5, linecolor='grey', annot=False, fmt=\".1f\", cbar_kws={'label': '% of Yearly Burn'})\n",
    "\n",
    "# Beautify axis labels\n",
    "plt.yticks(ticks=np.arange(12) + 0.5, labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                                              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], rotation=0)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Month')\n",
    "plt.title(f'Monthly Contribution to Yearly Burn (2025â€“2100) for {region} {burn_column}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea18666-ce1d-4585-bdbe-6e352e375a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEAN BA AND SD PER DECADE - MODEL ONLY\n",
    "# Step 1: Add year, month, and decade columns (already done)\n",
    "df_season = df_ba.copy().reset_index().rename(columns={'index':'time'})\n",
    "df_season['time'] = pd.to_datetime(df_season['time'])\n",
    "df_season.set_index('time', inplace=True)\n",
    "df_season = df_season.loc['2025-01-01':]\n",
    "\n",
    "df_season['year'] = df_season.index.year\n",
    "df_season['month'] = df_season.index.month\n",
    "df_season['decade'] = ((df_season['year'] - 1) // 10) * 10 + 1\n",
    "\n",
    "# Step 2: Choose the column of interest\n",
    "burn_column = 'ACCESS_SSP126'\n",
    "\n",
    "# Step 2: Group by decade, year, and month to compute actual monthly burn\n",
    "monthly_grouped = df_season.groupby(['decade', 'year', 'month'])[burn_column].sum()\n",
    "\n",
    "# Step 3: Compute yearly totals per decade and year\n",
    "yearly_grouped = df_season.groupby(['decade', 'year'])[burn_column].sum()\n",
    "\n",
    "# Step 4: Calculate percent of yearly burn per month per year\n",
    "# We need to divide monthly values by the corresponding yearly total\n",
    "monthly_percent = monthly_grouped / yearly_grouped.loc[monthly_grouped.index.droplevel('month')] * 100\n",
    "\n",
    "# Step 5: Calculate mean and std dev across years for each decade and month\n",
    "mean_percent = monthly_percent.groupby(['decade', 'month']).mean()\n",
    "std_percent = monthly_percent.groupby(['decade', 'month']).std()\n",
    "\n",
    "# Reset and merge mean and std dev\n",
    "mean_df = mean_percent.reset_index()\n",
    "std_df = std_percent.reset_index()\n",
    "combined_df = pd.merge(mean_df, std_df, on=['decade', 'month'], suffixes=('_mean', '_std'))\n",
    "\n",
    "# Create pivot tables\n",
    "mean_pivot = combined_df.pivot(index='month', columns='decade', values=f'{burn_column}_mean')\n",
    "std_pivot = combined_df.pivot(index='month', columns='decade', values=f'{burn_column}_std')\n",
    "\n",
    "# Format the decade labels (e.g., 2001 -> \"2000s\")\n",
    "formatted_columns = [f\"{int(decade) - 1}s\" for decade in mean_pivot.columns]\n",
    "mean_pivot.columns = formatted_columns\n",
    "std_pivot.columns = formatted_columns\n",
    "\n",
    "# Create annotation strings: \"mean Â± std\"\n",
    "annot = mean_pivot.round(1).astype(str) + \" Â± \" + std_pivot.round(1).astype(str)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(mean_pivot, cmap='YlOrRd', annot=annot, fmt='', linewidths=0.5, linecolor='grey',\n",
    "            cbar_kws={'label': 'Mean % of Yearly Burn'})\n",
    "\n",
    "# Y-axis: month names\n",
    "plt.yticks(ticks=np.arange(12) + 0.5, labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                                              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], rotation=0)\n",
    "\n",
    "plt.xlabel('Decade')\n",
    "plt.ylabel('Month')\n",
    "plt.title(f'Monthly Mean Â± Std Dev Burn (% of Yearly) by Decade for {region} {burn_column}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887d4819-d286-4656-8330-80d864a5898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL INDIVIDUAL YEARS PER SCENARIO\n",
    "# Step 1: Add year, month, and decade columns\n",
    "df_season = df_ba.copy().reset_index().rename(columns={'index':'time'})\n",
    "df_season['time'] = pd.to_datetime(df_season['time'])\n",
    "df_season.set_index('time', inplace=True)\n",
    "df_season = df_season.loc['2025-01-01':]\n",
    "\n",
    "# Step 1: Add year, month columns\n",
    "df_season['year'] = df_season.index.year\n",
    "df_season['month'] = df_season.index.month\n",
    "\n",
    "# Step 2: Choose the column of interest\n",
    "burn_column = 'ACCESS_SSP126'\n",
    "\n",
    "# Step 3: Group by year and month, summing the burn values\n",
    "monthly_burn = df_season.groupby(['year', 'month'])[burn_column].sum()\n",
    "\n",
    "# Step 4: Calculate yearly totals for each year\n",
    "yearly_totals = df_season.groupby('year')[burn_column].sum()\n",
    "\n",
    "# Step 5: Calculate percentage of yearly burn for each month in each year\n",
    "percent_burn = monthly_burn.div(yearly_totals, level='year') * 100\n",
    "\n",
    "# Step 6: Set up colormap and get a color gradient\n",
    "cmap = cm.viridis\n",
    "norm = plt.Normalize(vmin=percent_burn.index.get_level_values('year').min(),\n",
    "                     vmax=percent_burn.index.get_level_values('year').max())\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Step 7: Plot each year with a different shade\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for year in percent_burn.index.levels[0]:  # Loop over each year\n",
    "    color = cmap(norm(year))  # Get color for the year from the colormap\n",
    "    ax.plot(percent_burn.loc[year].index, percent_burn.loc[year].values, color=color)\n",
    "\n",
    "# Step 8: Add colorbar to the right of the plot\n",
    "cbar = fig.colorbar(sm, ax=ax, pad=0.01)\n",
    "cbar.set_label('Year')\n",
    "\n",
    "# Step 9: Set labels and title\n",
    "ax.set_xticks(range(1, 13))\n",
    "ax.set_xticklabels([\n",
    "    'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'\n",
    "])\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Percent of Yearly Burn (%)')\n",
    "ax.set_title(f'Monthly Burn Percentages by Year for {region} {burn_column}')\n",
    "ax.grid(True)\n",
    "\n",
    "# Step 10: Show the plot\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/ba_seasonality_plot_all_years_{region}_mri_370_2025_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754c7ca-9f51-4cad-9a45-dc4d64a45f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datetime index\n",
    "df_ba_plot = df_ba.copy()\n",
    "df_ba_plot.index = pd.to_datetime(df_ba_plot.index)\n",
    "df_ba_plot = df_ba_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Determine year range\n",
    "all_years = df_ba_plot.index.year.unique()\n",
    "min_year, max_year = all_years.min(), all_years.max()\n",
    "year_range = pd.Index(range(min_year, max_year + 1))\n",
    "\n",
    "# Build DataFrame: years as index, models as columns, values = month of max burn\n",
    "max_month_df = pd.DataFrame(index=year_range)\n",
    "\n",
    "for column in df_ba_plot.columns:\n",
    "    monthly_data = df_ba_plot[column].groupby(df_ba_plot.index.year)\n",
    "\n",
    "    def get_max_month(group):\n",
    "        if group.isna().all() or group.sum() == 0:\n",
    "            return np.nan  # No valid data\n",
    "        else:\n",
    "            #return group.idxmax().month # Original\n",
    "            max_val = group.max()\n",
    "            max_months = group[group == max_val].index.month\n",
    "            # Choose the month closest to June (month 6)\n",
    "            return max_months[np.abs(max_months - 6).argmin()]\n",
    "\n",
    "    max_months = monthly_data.apply(get_max_month)\n",
    "    max_month_df[column] = max_months.reindex(year_range)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "for column in max_month_df.columns:\n",
    "    # Original (jittery) line\n",
    "    plt.plot(\n",
    "        max_month_df.index,\n",
    "        max_month_df[column],\n",
    "        label=column,\n",
    "        linestyle='-',\n",
    "        alpha=0.4  # lighter line\n",
    "    )\n",
    "    \n",
    "    # Rolling 5-year mean\n",
    "    rolling = max_month_df[column].rolling(window=5, min_periods=3).mean()\n",
    "    plt.plot(\n",
    "        rolling.index,\n",
    "        rolling,\n",
    "        linestyle='-',\n",
    "        linewidth=2,\n",
    "        alpha=0.9,\n",
    "        label=f'{column}'\n",
    "    )\n",
    "\n",
    "# Y-axis: months, flipped\n",
    "plt.yticks(ticks=range(1, 13), labels=[\n",
    "    'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'\n",
    "])\n",
    "#plt.ylim(12.5, 0.5) # All months\n",
    "plt.ylim(10.5, 2.5) # Mar to Oct\n",
    "\n",
    "# X-axis: every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='5YS').year\n",
    "plt.xticks(ticks=years)\n",
    "\n",
    "# Titles and layout\n",
    "plt.title(f'5-year Rolling Mean of Month of Maximum Burned Area per Year â€“ {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Month of Max Burn')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/Summary stats/BA/ba_max_month_{region}.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04975b58-4ea0-4241-bc68-ceca0add216b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Processing - set erroneous months to 0 (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e330e68-faa9-4b9d-9fe3-2398336c830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_edited = df_ba.copy()\n",
    "model_columns = [col for col in df_ba_edited.columns if col != 'Actual']\n",
    "\n",
    "# Create an empty DataFrame to store results\n",
    "min_by_month = pd.DataFrame(index=range(1, 13), columns=model_columns)\n",
    "\n",
    "# Fill the DataFrame with minimum values for each column and month\n",
    "for month in range(1, 13):\n",
    "    month_mask = df_ba_edited.index.month == month\n",
    "    for col in model_columns:\n",
    "        min_val = df_ba_edited.loc[month_mask, col].min()\n",
    "        min_by_month.loc[month, col] = min_val\n",
    "\n",
    "# Rename index for clarity\n",
    "min_by_month.index.name = 'month'\n",
    "\n",
    "min_by_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c3438-5f2e-43d3-81ec-61a839240923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure min_by_month values are floats\n",
    "min_by_month = min_by_month.astype(float)\n",
    "\n",
    "# Apply subtraction of monthly minimums\n",
    "for month in range(1, 13):\n",
    "    # Boolean mask for rows in the current month\n",
    "    month_mask = df_ba_edited.index.month == month\n",
    "    # Subtract corresponding row from min_by_month (broadcast across rows)\n",
    "    df_ba_edited.loc[month_mask, min_by_month.columns] = (\n",
    "        df_ba_edited.loc[month_mask, min_by_month.columns] - min_by_month.loc[month]\n",
    "    )\n",
    "\n",
    "# Set any negative values to 0\n",
    "df_ba_edited[df_ba_edited < 0] = 0\n",
    "df_ba_edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213c005-283f-4fe5-9fae-609f69804cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot edited df\n",
    "df_ba_plot = df_ba_edited.copy()\n",
    "df_ba_plot.index = pd.to_datetime(df_ba_plot.index)\n",
    "df_ba_plot = df_ba_plot.resample('YE').sum()\n",
    "df_ba_plot.index = df_ba_plot.index + pd.offsets.Day(1)\n",
    "df_ba_plot.index = df_ba_plot.index - pd.offsets.YearBegin(1)\n",
    "df_ba_plot = df_ba_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot first column (only up to 2024)\n",
    "first_col = df_ba_plot.columns[0]\n",
    "df_first = df_ba_plot.loc[:'2024-12-31', first_col]\n",
    "plt.plot(df_first.index, df_first, label=first_col, linewidth=2)\n",
    "\n",
    "# Plot all other columns (from 2025 onwards)\n",
    "for column in df_ba_plot.columns[1:]:\n",
    "    df_other = df_ba_plot.loc['2025-01-01':, column]\n",
    "    plt.plot(df_other.index, df_other, label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='5YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(f'Adjusted BA Time Series Yearly sum for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mha')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/ba_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b3d3e6-4ec6-4314-a092-8daa7cc97fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated CSV\n",
    "df_ba_save = df_ba_edited.copy()\n",
    "df_ba_save.iloc[:, 1:] = df_ba_save.iloc[:, 1:] * 10 # Convert back to original raw values\n",
    "df_ba_save.drop('Actual', axis=1, inplace=True)\n",
    "df_ba_save.dropna(how='all', inplace=True)\n",
    "df_ba_save = df_ba_save.reset_index().rename(columns={'index': 'time'})\n",
    "new_column_names = {\n",
    "    'ACCESS_SSP126': 'access 126',\n",
    "    'ACCESS_SSP245': 'access 245',\n",
    "    'ACCESS_SSP370': 'access 370',\n",
    "    'MRI_SSP126': 'mri 126',\n",
    "    'MRI_SSP245': 'mri 245',\n",
    "    'MRI_SSP370': 'mri 370'\n",
    "}\n",
    "df_ba_save.rename(columns=new_column_names, inplace=True)\n",
    "df_ba_save.to_csv(f'/home/users/clelland/Model/Analysis/Ecoregion plots combined/area_timeseries_{region_model}_all.csv', index=False)\n",
    "df_ba_save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052f8ada-4017-4423-84bf-e5e6279ff6d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Climate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a2c002-ac6e-4260-b379-04aaf51b7bea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### RH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9428f6-02f4-4317-9e6a-6ec7d1832593",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Process and bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acee160-07b6-49a3-b311-84bbbf1be57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rh\n",
    "df_rh = pd.DataFrame({\n",
    "    'ERA5-Land': df_e5l['rh'],\n",
    "    'ACCESS_HIST': df_access_hist_climate['rh'],\n",
    "    'ACCESS_SSP126': df_access_126_climate['rh'],\n",
    "    'ACCESS_SSP245': df_access_245_climate['rh'],\n",
    "    'ACCESS_SSP370': df_access_370_climate['rh'],\n",
    "    'MRI_HIST': df_mri_hist_climate['rh'],\n",
    "    'MRI_SSP126': df_mri_126_climate['rh'],\n",
    "    'MRI_SSP245': df_mri_245_climate['rh'],\n",
    "    'MRI_SSP370': df_mri_370_climate['rh'],\n",
    "})\n",
    "\n",
    "df_rh.sort_index(inplace=True)\n",
    "df_rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1911ab-9fd7-453b-99aa-624e5dd25600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias correction\n",
    "df_bias = df_rh.copy()\n",
    "\n",
    "# First, ensure the index is datetime\n",
    "df_bias.index = pd.to_datetime(df_bias.index)\n",
    "\n",
    "# Add month as a new column\n",
    "df_bias['month'] = df_bias.index.month\n",
    "\n",
    "# Create a dictionary to store results\n",
    "diff_results = {}\n",
    "\n",
    "# 1. For 2001â€“2014 (historical)\n",
    "hist_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    diff = df_bias.loc[hist_period, 'ERA5-Land'] - df_bias.loc[hist_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[hist_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 2. For 2015â€“2023 (future scenarios)\n",
    "future_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2023-12-31')\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    diff = df_bias.loc[future_period, 'ERA5-Land'] - df_bias.loc[future_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[future_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 3. Combine all differences into a dataframe\n",
    "diff_df = pd.DataFrame(diff_results)\n",
    "\n",
    "# Optional: sort the dataframe by month\n",
    "diff_df.index.name = 'month'\n",
    "diff_df = diff_df.sort_index()\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a4b36-6efc-461f-a08f-81ca4b1b44f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the period you want to correct\n",
    "hist_correction_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "future_correction_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2100-12-31')\n",
    "\n",
    "# 2. Loop through each model/scenario you want to correct\n",
    "corrected_data = {}\n",
    "corrected_data['ERA5-Land'] = df_bias['ERA5-Land']\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    # Select the original model data for 2001â€“2014\n",
    "    model_data = df_bias.loc[hist_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[hist_correction_period, 'month']\n",
    "    \n",
    "    # Add the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    # Select the original model data for 2015â€“2100\n",
    "    model_data = df_bias.loc[future_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[future_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "# 3. Combine corrected data into a dataframe\n",
    "corrected_df_rh = pd.DataFrame(corrected_data, index=df_bias.index)\n",
    "\n",
    "corrected_df_rh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11b98ee-230d-41df-92d5-77f844dc7816",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9b501b-f802-4eb2-88d1-e45881a4ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rh_plot = df_rh.copy() # Original data\n",
    "#df_rh_plot = corrected_df_rh.copy() # Corrected data\n",
    "df_rh_plot.index = pd.to_datetime(df_rh_plot.index)\n",
    "#df_rh_plot = df_rh_plot.loc['2001':'2014']\n",
    "df_rh_plot = df_rh_plot.loc['2001':'2023']\n",
    "df_rh_plot = df_rh_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot each column\n",
    "for column in df_rh_plot.columns:\n",
    "    plt.plot(df_rh_plot.index, df_rh_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "#years = pd.date_range(start='2001', end='2015', freq='YS')\n",
    "years = pd.date_range(start='2001', end='2023', freq='YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(f'RH Time Series for {region}')\n",
    "#plt.title(f'Corrected RH Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('%')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/rh_plot_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d2f5b-1971-4a4a-8ba9-6426b30a8462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "#df_rh_plot = df_rh.copy() # Original data\n",
    "df_rh_plot = corrected_df_rh.copy() # Corrected data\n",
    "df_rh_plot.index = pd.to_datetime(df_rh_plot.index)\n",
    "df_rh_plot = df_rh_plot.resample('YE').mean()\n",
    "df_rh_plot.index = df_rh_plot.index + pd.offsets.Day(1)\n",
    "df_rh_plot.index = df_rh_plot.index - pd.offsets.YearBegin(1)\n",
    "df_rh_plot = df_rh_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Plot each column\n",
    "for column in df_rh_plot.columns:\n",
    "    plt.plot(df_rh_plot.index, df_rh_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='5YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'RH Time Series Yearly average for {region}')\n",
    "plt.title(f'Corrected RH Time Series Yearly average for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('%')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/rh_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671511da-5f84-49c9-a739-aafb4f12a43a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### TP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76b949a-3788-47e7-92c0-2a791ea9b540",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Process and bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0780797d-7c1e-47f0-993a-56e347c71ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp\n",
    "df_tp = pd.DataFrame({\n",
    "    'ERA5-Land': df_e5l['tp'],\n",
    "    'ACCESS_HIST': df_access_hist_climate['pr'],\n",
    "    'ACCESS_SSP126': df_access_126_climate['tp'],\n",
    "    'ACCESS_SSP245': df_access_245_climate['tp'],\n",
    "    'ACCESS_SSP370': df_access_370_climate['tp'],\n",
    "    'MRI_HIST': df_mri_hist_climate['pr'],\n",
    "    'MRI_SSP126': df_mri_126_climate['tp'],\n",
    "    'MRI_SSP245': df_mri_245_climate['tp'],\n",
    "    'MRI_SSP370': df_mri_370_climate['tp'],\n",
    "})\n",
    "\n",
    "df_tp.sort_index(inplace=True)\n",
    "df_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2a7ba-f65a-4851-af27-3ad2660172c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias correction\n",
    "df_bias = df_tp.copy()\n",
    "\n",
    "# First, ensure the index is datetime\n",
    "df_bias.index = pd.to_datetime(df_bias.index)\n",
    "\n",
    "# Add month as a new column\n",
    "df_bias['month'] = df_bias.index.month\n",
    "\n",
    "# Create a dictionary to store results\n",
    "diff_results = {}\n",
    "\n",
    "# 1. For 2001â€“2014 (historical)\n",
    "hist_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    diff = df_bias.loc[hist_period, 'ERA5-Land'] - df_bias.loc[hist_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[hist_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 2. For 2015â€“2023 (future scenarios)\n",
    "future_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2023-12-31')\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    diff = df_bias.loc[future_period, 'ERA5-Land'] - df_bias.loc[future_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[future_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 3. Combine all differences into a dataframe\n",
    "diff_df = pd.DataFrame(diff_results)\n",
    "\n",
    "# Optional: sort the dataframe by month\n",
    "diff_df.index.name = 'month'\n",
    "diff_df = diff_df.sort_index()\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c6101-95f4-4a5f-96fc-911536e8eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the period you want to correct\n",
    "hist_correction_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "future_correction_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2100-12-31')\n",
    "\n",
    "# 2. Loop through each model/scenario you want to correct\n",
    "corrected_data = {}\n",
    "corrected_data['ERA5-Land'] = df_bias['ERA5-Land']\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    # Select the original model data for 2001â€“2014\n",
    "    model_data = df_bias.loc[hist_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[hist_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    # Select the original model data for 2015â€“2100\n",
    "    model_data = df_bias.loc[future_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[future_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "# 3. Combine corrected data into a dataframe\n",
    "corrected_df_tp = pd.DataFrame(corrected_data, index=df_bias.index)\n",
    "\n",
    "corrected_df_tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdeef3f-d00c-4abf-b184-5d573a240a63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37948193-2340-44f9-96a6-b6b4a40cd81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tp_plot = df_tp.copy() # Original data\n",
    "#df_tp_plot = corrected_df_tp.copy() # Corrected data\n",
    "df_tp_plot.index = pd.to_datetime(df_tp_plot.index)\n",
    "#df_tp_plot = df_tp_plot.loc['2001':'2014']\n",
    "df_tp_plot = df_tp_plot.loc['2001':'2023']\n",
    "df_tp_plot = df_tp_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot each column\n",
    "for column in df_tp_plot.columns:\n",
    "    plt.plot(df_tp_plot.index, df_tp_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "#years = pd.date_range(start='2001', end='2015', freq='YS')\n",
    "years = pd.date_range(start='2001', end='2023', freq='YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(f'TP Time Series for {region}')\n",
    "#plt.title(f'Corrected TP Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('m')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/tp_plot_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ce05e-de9f-4b58-8ca7-6923a09e0556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Original data\n",
    "#df_tp_plot = df_tp.copy() # Original data\n",
    "df_tp_plot = corrected_df_tp.copy() # Corrected data\n",
    "df_tp_plot.index = pd.to_datetime(df_tp_plot.index)\n",
    "df_tp_plot = df_tp_plot.resample('YE').sum()\n",
    "df_tp_plot.index = df_tp_plot.index + pd.offsets.Day(1)\n",
    "df_tp_plot.index = df_tp_plot.index - pd.offsets.YearBegin(1)\n",
    "df_tp_plot = df_tp_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Plot first column (only up to 2024)\n",
    "first_col = df_tp_plot.columns[0]\n",
    "df_first = df_tp_plot.loc[:'2023-12-31', first_col]\n",
    "plt.plot(df_first.index, df_first, label=first_col)\n",
    "\n",
    "# Plot hist columns (only up to 2014)\n",
    "hist_cols = df_tp_plot.columns[[1, 2]]\n",
    "df_hist = df_tp_plot.loc[:'2014-12-31', hist_cols]\n",
    "for col in hist_cols:\n",
    "    plt.plot(df_hist.index, df_hist[col], label=col)\n",
    "    \n",
    "# Plot all other columns (from 2015 onwards)\n",
    "future_cols = list(df_tp_plot.columns[3:])\n",
    "for column in future_cols:\n",
    "    df_other = df_tp_plot.loc['2015-01-01':, column]\n",
    "    plt.plot(df_other.index, df_other, label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='5YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'TP Time Series for {region}')\n",
    "plt.title(f'Corrected TP Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('m')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/tp_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b922e7c-d66b-4560-a197-d6304f5008d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### RLDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03690c68-232c-4401-a550-5344994d71f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Process and bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa3b38-305a-4963-86ed-e3bb03b81703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rlds\n",
    "df_rlds = pd.DataFrame({\n",
    "    'ERA5-Land': df_e5l['rlds'],\n",
    "    'ACCESS_HIST': df_access_hist_climate['rlds'],\n",
    "    'ACCESS_SSP126': df_access_126_climate['rlds'],\n",
    "    'ACCESS_SSP245': df_access_245_climate['rlds'],\n",
    "    'ACCESS_SSP370': df_access_370_climate['rlds'],\n",
    "    'MRI_HIST': df_mri_hist_climate['rlds'],\n",
    "    'MRI_SSP126': df_mri_126_climate['rlds'],\n",
    "    'MRI_SSP245': df_mri_245_climate['rlds'],\n",
    "    'MRI_SSP370': df_mri_370_climate['rlds'],\n",
    "})\n",
    "\n",
    "df_rlds.sort_index(inplace=True)\n",
    "df_rlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cf3f66-07d2-4ae7-a208-219580471cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias correction\n",
    "df_bias = df_rlds.copy()\n",
    "\n",
    "# First, ensure the index is datetime\n",
    "df_bias.index = pd.to_datetime(df_bias.index)\n",
    "\n",
    "# Add month as a new column\n",
    "df_bias['month'] = df_bias.index.month\n",
    "\n",
    "# Create a dictionary to store results\n",
    "diff_results = {}\n",
    "\n",
    "# 1. For 2001â€“2014 (historical)\n",
    "hist_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    diff = df_bias.loc[hist_period, 'ERA5-Land'] - df_bias.loc[hist_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[hist_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 2. For 2015â€“2023 (future scenarios)\n",
    "future_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2023-12-31')\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    diff = df_bias.loc[future_period, 'ERA5-Land'] - df_bias.loc[future_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[future_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 3. Combine all differences into a dataframe\n",
    "diff_df = pd.DataFrame(diff_results)\n",
    "\n",
    "# Optional: sort the dataframe by month\n",
    "diff_df.index.name = 'month'\n",
    "diff_df = diff_df.sort_index()\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c53c1-e1b7-4753-9487-6b0908e34650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the period you want to correct\n",
    "hist_correction_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "future_correction_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2100-12-31')\n",
    "\n",
    "# 2. Loop through each model/scenario you want to correct\n",
    "corrected_data = {}\n",
    "corrected_data['ERA5-Land'] = df_bias['ERA5-Land']\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    # Select the original model data for 2001â€“2014\n",
    "    model_data = df_bias.loc[hist_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[hist_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    # Select the original model data for 2015â€“2100\n",
    "    model_data = df_bias.loc[future_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[future_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "# 3. Combine corrected data into a dataframe\n",
    "corrected_df_rlds = pd.DataFrame(corrected_data, index=df_bias.index)\n",
    "\n",
    "corrected_df_rlds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81997f0-2f87-4a2e-a4a2-0b91364a592a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e759b-e795-4a79-a569-ba1084cf9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rlds_plot = df_rlds.copy() # Original data\n",
    "#df_rlds_plot = corrected_df_rlds.copy() # Corrected data\n",
    "df_rlds_plot.index = pd.to_datetime(df_rlds_plot.index)\n",
    "#df_rlds_plot = df_rlds_plot.loc['2001':'2014']\n",
    "df_rlds_plot = df_rlds_plot.loc['2001':'2023']\n",
    "df_rlds_plot = df_rlds_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot each column\n",
    "for column in df_rlds_plot.columns:\n",
    "    plt.plot(df_rlds_plot.index, df_rlds_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "#years = pd.date_range(start='2001', end='2015', freq='YS')\n",
    "years = pd.date_range(start='2001', end='2023', freq='YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(f'RLDS Time Series for {region}')\n",
    "#plt.title(f'Corrected RLDS Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('W/m2')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/rlds_plot_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef75372e-3bdb-4d49-b1c2-59b6f290b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "#df_rlds_plot = df_rlds.copy() # Original data\n",
    "df_rlds_plot = corrected_df_rlds.copy() # Corrected data\n",
    "df_rlds_plot.index = pd.to_datetime(df_rlds_plot.index)\n",
    "df_rlds_plot = df_rlds_plot.resample('YE').mean()\n",
    "df_rlds_plot.index = df_rlds_plot.index + pd.offsets.Day(1)\n",
    "df_rlds_plot.index = df_rlds_plot.index - pd.offsets.YearBegin(1)\n",
    "df_rlds_plot = df_rlds_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Plot each column\n",
    "for column in df_rlds_plot.columns:\n",
    "    plt.plot(df_rlds_plot.index, df_rlds_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='5YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'RLDS Time Series for {region}')\n",
    "plt.title(f'Corrected RLDS Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('W/m2')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/rlds_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4960b-569a-4683-90ff-195f796a8d47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### RSDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1211fdcd-fe32-4d61-9d98-b3eeba2c8f12",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Process and bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ffc39-7b97-4029-a103-3c9f8f508c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rsds\n",
    "df_rsds = pd.DataFrame({\n",
    "    'ERA5-Land': df_e5l['rsds'],\n",
    "    'ACCESS_HIST': df_access_hist_climate['rsds'],\n",
    "    'ACCESS_SSP126': df_access_126_climate['rsds'],\n",
    "    'ACCESS_SSP245': df_access_245_climate['rsds'],\n",
    "    'ACCESS_SSP370': df_access_370_climate['rsds'],\n",
    "    'MRI_HIST': df_mri_hist_climate['rsds'],\n",
    "    'MRI_SSP126': df_mri_126_climate['rsds'],\n",
    "    'MRI_SSP245': df_mri_245_climate['rsds'],\n",
    "    'MRI_SSP370': df_mri_370_climate['rsds'],\n",
    "})\n",
    "\n",
    "df_rsds.sort_index(inplace=True)\n",
    "df_rsds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68aa3f-e004-460e-930c-0e98de89e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias correction\n",
    "df_bias = df_rsds.copy()\n",
    "\n",
    "# First, ensure the index is datetime\n",
    "df_bias.index = pd.to_datetime(df_bias.index)\n",
    "\n",
    "# Add month as a new column\n",
    "df_bias['month'] = df_bias.index.month\n",
    "\n",
    "# Create a dictionary to store results\n",
    "diff_results = {}\n",
    "\n",
    "# 1. For 2001â€“2014 (historical)\n",
    "hist_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    diff = df_bias.loc[hist_period, 'ERA5-Land'] - df_bias.loc[hist_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[hist_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 2. For 2015â€“2023 (future scenarios)\n",
    "future_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2023-12-31')\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    diff = df_bias.loc[future_period, 'ERA5-Land'] - df_bias.loc[future_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[future_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 3. Combine all differences into a dataframe\n",
    "diff_df = pd.DataFrame(diff_results)\n",
    "\n",
    "# Optional: sort the dataframe by month\n",
    "diff_df.index.name = 'month'\n",
    "diff_df = diff_df.sort_index()\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce2048-dc1e-4063-9743-1855624613ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the period you want to correct\n",
    "hist_correction_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "future_correction_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2100-12-31')\n",
    "\n",
    "# 2. Loop through each model/scenario you want to correct\n",
    "corrected_data = {}\n",
    "corrected_data['ERA5-Land'] = df_bias['ERA5-Land']\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    # Select the original model data for 2001â€“2014\n",
    "    model_data = df_bias.loc[hist_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[hist_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    # Select the original model data for 2015â€“2100\n",
    "    model_data = df_bias.loc[future_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[future_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "# 3. Combine corrected data into a dataframe\n",
    "corrected_df_rsds = pd.DataFrame(corrected_data, index=df_bias.index)\n",
    "\n",
    "corrected_df_rsds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8035fd9-9ca7-4217-92f7-65ec66651804",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00331ee0-b444-424c-989b-f214bd10bad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_rsds_plot = df_rsds.copy() # Original data\n",
    "df_rsds_plot = corrected_df_rsds.copy() # Corrected data\n",
    "df_rsds_plot.index = pd.to_datetime(df_rsds_plot.index)\n",
    "#df_rsds_plot = df_rsds_plot.loc['2001':'2014']\n",
    "df_rsds_plot = df_rsds_plot.loc['2001':'2023']\n",
    "df_rsds_plot = df_rsds_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot each column\n",
    "for column in df_rsds_plot.columns:\n",
    "    plt.plot(df_rsds_plot.index, df_rsds_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2001', end='2015', freq='YS')\n",
    "#years = pd.date_range(start='2001', end='2023', freq='YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'RSDS Time Series for {region}')\n",
    "plt.title(f'Corrected RSDS Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('W/m2')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/rsds_plot_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf8a6b8-de92-4e09-9f90-0de7d53a44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "#df_rsds_plot = df_rsds.copy() # Original data\n",
    "df_rsds_plot = corrected_df_rsds.copy() # Corrected data\n",
    "df_rsds_plot.index = pd.to_datetime(df_rsds_plot.index)\n",
    "df_rsds_plot = df_rsds_plot.resample('YE').mean()\n",
    "df_rsds_plot.index = df_rsds_plot.index + pd.offsets.Day(1)\n",
    "df_rsds_plot.index = df_rsds_plot.index - pd.offsets.YearBegin(1)\n",
    "df_rsds_plot = df_rsds_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Plot each column\n",
    "for column in df_rsds_plot.columns:\n",
    "    plt.plot(df_rsds_plot.index, df_rsds_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='5YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'RSDS Time Series for {region}')\n",
    "plt.title(f'Corrected RSDS Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('W/m2')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/rsds_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2918e1ae-37ec-4acd-b127-1fbf7f37a8b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### WSP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5080a52e-6f23-4b91-92b6-a54febb36fda",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Process and bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1e99a-7bc9-4b1a-9b41-979abe5b9eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wsp\n",
    "df_wsp = pd.DataFrame({\n",
    "    'ERA5-Land': df_e5l['wsp'],\n",
    "    'ACCESS_HIST': df_access_hist_climate['sfcWind'],\n",
    "    'ACCESS_SSP126': df_access_126_climate['wsp'],\n",
    "    'ACCESS_SSP245': df_access_245_climate['wsp'],\n",
    "    'ACCESS_SSP370': df_access_370_climate['wsp'],\n",
    "    'MRI_HIST': df_mri_hist_climate['sfcWind'],\n",
    "    'MRI_SSP126': df_mri_126_climate['wsp'],\n",
    "    'MRI_SSP245': df_mri_245_climate['wsp'],\n",
    "    'MRI_SSP370': df_mri_370_climate['wsp'],\n",
    "})\n",
    "\n",
    "df_wsp.sort_index(inplace=True)\n",
    "df_wsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f251ced-2bf1-4d7a-9588-ddf9bfa2b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias correction\n",
    "df_bias = df_wsp.copy()\n",
    "\n",
    "# First, ensure the index is datetime\n",
    "df_bias.index = pd.to_datetime(df_bias.index)\n",
    "\n",
    "# Add month as a new column\n",
    "df_bias['month'] = df_bias.index.month\n",
    "\n",
    "# Create a dictionary to store results\n",
    "diff_results = {}\n",
    "\n",
    "# 1. For 2001â€“2014 (historical)\n",
    "hist_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    diff = df_bias.loc[hist_period, 'ERA5-Land'] - df_bias.loc[hist_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[hist_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 2. For 2015â€“2023 (future scenarios)\n",
    "future_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2023-12-31')\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    diff = df_bias.loc[future_period, 'ERA5-Land'] - df_bias.loc[future_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[future_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 3. Combine all differences into a dataframe\n",
    "diff_df = pd.DataFrame(diff_results)\n",
    "\n",
    "# Optional: sort the dataframe by month\n",
    "diff_df.index.name = 'month'\n",
    "diff_df = diff_df.sort_index()\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fc9f63-8fd7-44a6-bafc-78f42e58c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the period you want to correct\n",
    "hist_correction_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "future_correction_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2100-12-31')\n",
    "\n",
    "# 2. Loop through each model/scenario you want to correct\n",
    "corrected_data = {}\n",
    "corrected_data['ERA5-Land'] = df_bias['ERA5-Land']\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    # Select the original model data for 2001â€“2014\n",
    "    model_data = df_bias.loc[hist_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[hist_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    # Select the original model data for 2015â€“2100\n",
    "    model_data = df_bias.loc[future_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[future_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "# 3. Combine corrected data into a dataframe\n",
    "corrected_df_wsp = pd.DataFrame(corrected_data, index=df_bias.index)\n",
    "\n",
    "corrected_df_wsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb625d4-12bb-4bce-be5f-3c0e7aa83f21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05b254-bd95-4a6e-9f18-8e426ba98a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_wsp_plot = df_wsp.copy() # Original data\n",
    "df_wsp_plot = corrected_df_wsp.copy() # Corrected data\n",
    "df_wsp_plot.index = pd.to_datetime(df_wsp_plot.index)\n",
    "#df_wsp_plot = df_wsp_plot.loc['2001':'2014']\n",
    "df_wsp_plot = df_wsp_plot.loc['2001':'2023']\n",
    "df_wsp_plot = df_wsp_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot each column\n",
    "for column in df_wsp_plot.columns:\n",
    "    plt.plot(df_wsp_plot.index, df_wsp_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "#years = pd.date_range(start='2001', end='2015', freq='YS')\n",
    "years = pd.date_range(start='2001', end='2023', freq='2YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'Original WSP Time Series for {region}')\n",
    "plt.title(f'Bias Corrected WSP Time Series for {region}')\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlabel('Year', fontsize=18)\n",
    "plt.ylabel('m/s', fontsize=18)\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 4.2)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/wsp_plot_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "#plt.savefig('/home/users/clelland/Model/Analysis/wsp_midbor_new_short', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b89dd5-261a-4bb2-a12e-3bd85667d58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "#df_wsp_plot = df_wsp.copy() # Original data\n",
    "df_wsp_plot = corrected_df_wsp.copy() # Corrected data\n",
    "df_wsp_plot.index = pd.to_datetime(df_wsp_plot.index)\n",
    "df_wsp_plot = df_wsp_plot.resample('YE').mean()\n",
    "df_wsp_plot.index = df_wsp_plot.index + pd.offsets.Day(1)\n",
    "df_wsp_plot.index = df_wsp_plot.index - pd.offsets.YearBegin(1)\n",
    "df_wsp_plot = df_wsp_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Plot each column\n",
    "for column in df_wsp_plot.columns:\n",
    "    plt.plot(df_wsp_plot.index, df_wsp_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='10YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'Original WSP Time Series for {region}')\n",
    "plt.title(f'Bias Corrected WSP Time Series for {region}')\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlabel('Year', fontsize=18)\n",
    "plt.ylabel('m/s', fontsize=18)\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 4.2)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/wsp_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "#plt.savefig('/home/users/clelland/Model/Analysis/wsp_midbor_new_long', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d699324-0a49-4d70-90aa-f07fa85224ab",
   "metadata": {},
   "source": [
    "### T2M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8989f095-cbbc-44ee-a182-cab3a08b8fb2",
   "metadata": {},
   "source": [
    "#### Process and bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62a8b8-3f91-4de6-8951-df2447637f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t2m\n",
    "df_t2m = pd.DataFrame({\n",
    "    'ERA5-Land': df_e5l['t2m'],\n",
    "    'ACCESS_HIST': df_access_hist_climate['tas'],\n",
    "    'ACCESS_SSP126': df_access_126_climate['t2m'],\n",
    "    'ACCESS_SSP245': df_access_245_climate['t2m'],\n",
    "    'ACCESS_SSP370': df_access_370_climate['t2m'],\n",
    "    'MRI_HIST': df_mri_hist_climate['tas'],\n",
    "    'MRI_SSP126': df_mri_126_climate['t2m'],\n",
    "    'MRI_SSP245': df_mri_245_climate['t2m'],\n",
    "    'MRI_SSP370': df_mri_370_climate['t2m'],\n",
    "})\n",
    "\n",
    "df_t2m.sort_index(inplace=True)\n",
    "df_t2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc693c9d-89fe-4da2-8d4e-442053cf3a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias correction\n",
    "df_bias = df_t2m.copy()\n",
    "\n",
    "# First, ensure the index is datetime\n",
    "df_bias.index = pd.to_datetime(df_bias.index)\n",
    "\n",
    "# Add month as a new column\n",
    "df_bias['month'] = df_bias.index.month\n",
    "\n",
    "# Create a dictionary to store results\n",
    "diff_results = {}\n",
    "\n",
    "# 1. For 2001â€“2014 (historical)\n",
    "hist_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    diff = df_bias.loc[hist_period, 'ERA5-Land'] - df_bias.loc[hist_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[hist_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 2. For 2015â€“2023 (future scenarios)\n",
    "future_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2023-12-31')\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    diff = df_bias.loc[future_period, 'ERA5-Land'] - df_bias.loc[future_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[future_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 3. Combine all differences into a dataframe\n",
    "diff_df = pd.DataFrame(diff_results)\n",
    "\n",
    "# Optional: sort the dataframe by month\n",
    "diff_df.index.name = 'month'\n",
    "diff_df = diff_df.sort_index()\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9e2bbf-f00b-4544-b9d5-306b2bb3d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the period you want to correct\n",
    "hist_correction_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "future_correction_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2100-12-31')\n",
    "\n",
    "# 2. Loop through each model/scenario you want to correct\n",
    "corrected_data = {}\n",
    "corrected_data['ERA5-Land'] = df_bias['ERA5-Land']\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    # Select the original model data for 2001â€“2014\n",
    "    model_data = df_bias.loc[hist_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[hist_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    # Select the original model data for 2015â€“2100\n",
    "    model_data = df_bias.loc[future_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[future_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "# 3. Combine corrected data into a dataframe\n",
    "corrected_df_t2m = pd.DataFrame(corrected_data, index=df_bias.index)\n",
    "\n",
    "corrected_df_t2m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c07ce3d-b72f-4a96-b009-3d229849ef43",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01bf492-546f-4d6a-b680-a6a22d49e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t2m_plot = df_t2m.copy() # Original data\n",
    "#df_t2m_plot = corrected_df_t2m.copy() # Corrected data\n",
    "df_t2m_plot.index = pd.to_datetime(df_t2m_plot.index)\n",
    "#df_t2m_plot = df_t2m_plot.loc['2001':'2014']\n",
    "df_t2m_plot = df_t2m_plot.loc['2001':'2023']\n",
    "df_t2m_plot = df_t2m_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot each column\n",
    "for column in df_t2m_plot.columns:\n",
    "    plt.plot(df_t2m_plot.index, df_t2m_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "#years = pd.date_range(start='2001', end='2015', freq='YS')\n",
    "years = pd.date_range(start='2001', end='2023', freq='YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'T2M Time Series for {region}')\n",
    "plt.title(f'Corrected T2M Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('K')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/t2m_plot_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e70616d-f944-4e03-83ef-91861c489b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "#df_t2m_plot = df_t2m.copy() # Original data\n",
    "#df_t2m_plot = corrected_df_t2m.copy() # Corrected data\n",
    "df_t2m_plot = corrected_df_t2m.copy().loc['2025':] # Corrected data\n",
    "df_t2m_plot.index = pd.to_datetime(df_t2m_plot.index)\n",
    "df_t2m_plot = df_t2m_plot.resample('YE').mean()\n",
    "df_t2m_plot.index = df_t2m_plot.index + pd.offsets.Day(1)\n",
    "df_t2m_plot.index = df_t2m_plot.index - pd.offsets.YearBegin(1)\n",
    "df_t2m_plot = df_t2m_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Plot each column\n",
    "for column in df_t2m_plot.columns:\n",
    "    plt.plot(df_t2m_plot.index, df_t2m_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "#years = pd.date_range(start='2000', end='2100', freq='5YS')\n",
    "years = pd.date_range(start='2025', end='2100', freq='5YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'T2M Time Series for {region}')\n",
    "plt.title(f'Corrected T2M Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('K')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/t2m_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e82e3b0-a5d4-41a5-aabe-febd8495044e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### MX2T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd7273-24ba-42b0-ba2d-70d5b1472ace",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Process and bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ba2a2-868f-4d8e-855a-09a37b2b4a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mx2t\n",
    "df_mx2t = pd.DataFrame({\n",
    "    'ERA5-Land': df_e5l['mx2t'],\n",
    "    'ACCESS_HIST': df_access_hist_climate['tasmax'],\n",
    "    'ACCESS_SSP126': df_access_126_climate['mx2t'],\n",
    "    'ACCESS_SSP245': df_access_245_climate['mx2t'],\n",
    "    'ACCESS_SSP370': df_access_370_climate['mx2t'],\n",
    "    'MRI_HIST': df_mri_hist_climate['tasmax'],\n",
    "    'MRI_SSP126': df_mri_126_climate['mx2t'],\n",
    "    'MRI_SSP245': df_mri_245_climate['mx2t'],\n",
    "    'MRI_SSP370': df_mri_370_climate['mx2t'],\n",
    "})\n",
    "\n",
    "df_mx2t.sort_index(inplace=True)\n",
    "df_mx2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eeea48-f61c-4ecb-9e19-72db3f079090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias correction\n",
    "df_bias = df_mx2t.copy()\n",
    "\n",
    "# First, ensure the index is datetime\n",
    "df_bias.index = pd.to_datetime(df_bias.index)\n",
    "\n",
    "# Add month as a new column\n",
    "df_bias['month'] = df_bias.index.month\n",
    "\n",
    "# Create a dictionary to store results\n",
    "diff_results = {}\n",
    "\n",
    "# 1. For 2001â€“2014 (historical)\n",
    "hist_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    diff = df_bias.loc[hist_period, 'ERA5-Land'] - df_bias.loc[hist_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[hist_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 2. For 2015â€“2023 (future scenarios)\n",
    "future_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2023-12-31')\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    diff = df_bias.loc[future_period, 'ERA5-Land'] - df_bias.loc[future_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[future_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 3. Combine all differences into a dataframe\n",
    "diff_df = pd.DataFrame(diff_results)\n",
    "\n",
    "# Optional: sort the dataframe by month\n",
    "diff_df.index.name = 'month'\n",
    "diff_df = diff_df.sort_index()\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef74ce5-15e5-4f3c-839d-3aff24b3dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the period you want to correct\n",
    "hist_correction_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "future_correction_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2100-12-31')\n",
    "\n",
    "# 2. Loop through each model/scenario you want to correct\n",
    "corrected_data = {}\n",
    "corrected_data['ERA5-Land'] = df_bias['ERA5-Land']\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    # Select the original model data for 2001â€“2014\n",
    "    model_data = df_bias.loc[hist_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[hist_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    # Select the original model data for 2015â€“2100\n",
    "    model_data = df_bias.loc[future_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[future_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "# 3. Combine corrected data into a dataframe\n",
    "corrected_df_mx2t = pd.DataFrame(corrected_data, index=df_bias.index)\n",
    "\n",
    "corrected_df_mx2t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7282dba0-a3f4-4046-91b2-4cb2b5929e71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d5e68-cfe1-4c35-96da-9d94fbc530e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_mx2t_plot = df_mx2t.copy() # Original data\n",
    "df_mx2t_plot = corrected_df_mx2t.copy() # Corrected data\n",
    "df_mx2t_plot.index = pd.to_datetime(df_mx2t_plot.index)\n",
    "#df_mx2t_plot = df_mx2t_plot.loc['2001':'2014']\n",
    "df_mx2t_plot = df_mx2t_plot.loc['2001':'2023']\n",
    "df_mx2t_plot = df_mx2t_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot each column\n",
    "for column in df_mx2t_plot.columns:\n",
    "    plt.plot(df_mx2t_plot.index, df_mx2t_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "#years = pd.date_range(start='2001', end='2015', freq='YS')\n",
    "years = pd.date_range(start='2001', end='2023', freq='YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'MX2T Time Series for {region}')\n",
    "plt.title(f'Corrected MX2T Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('K')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/mx2t_plot_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83943b-2a87-43a4-9ac3-c3bdde7fbdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "#df_mx2t_plot = df_mx2t.copy() # Original data\n",
    "df_mx2t_plot = corrected_df_mx2t.copy() # Corrected data\n",
    "df_mx2t_plot.index = pd.to_datetime(df_mx2t_plot.index)\n",
    "df_mx2t_plot = df_mx2t_plot.resample('YE').mean()\n",
    "df_mx2t_plot.index = df_mx2t_plot.index + pd.offsets.Day(1)\n",
    "df_mx2t_plot.index = df_mx2t_plot.index - pd.offsets.YearBegin(1)\n",
    "df_mx2t_plot = df_mx2t_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Plot each column\n",
    "for column in df_mx2t_plot.columns:\n",
    "    plt.plot(df_mx2t_plot.index, df_mx2t_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='5YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'MX2T Time Series for {region}')\n",
    "plt.title(f'Corrected MX2T Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('K')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/mx2t_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44a5b6c-85af-4c6f-ba00-be3505053ce6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### MN2T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03cf7e4-c48f-4a21-a1cb-4beb3d48baaa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Process and bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e3d4e8-2987-4cd9-aa9f-afd1bb16737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mn2t\n",
    "df_mn2t = pd.DataFrame({\n",
    "    'ERA5-Land': df_e5l['mn2t'],\n",
    "    'ACCESS_HIST': df_access_hist_climate['tasmin'],\n",
    "    'ACCESS_SSP126': df_access_126_climate['mn2t'],\n",
    "    'ACCESS_SSP245': df_access_245_climate['mn2t'],\n",
    "    'ACCESS_SSP370': df_access_370_climate['mn2t'],\n",
    "    'MRI_HIST': df_mri_hist_climate['tasmin'],\n",
    "    'MRI_SSP126': df_mri_126_climate['mn2t'],\n",
    "    'MRI_SSP245': df_mri_245_climate['mn2t'],\n",
    "    'MRI_SSP370': df_mri_370_climate['mn2t'],\n",
    "})\n",
    "\n",
    "df_mn2t.sort_index(inplace=True)\n",
    "df_mn2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d716ba8e-e3d2-4035-8627-4d405eb2924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias correction\n",
    "df_bias = df_mn2t.copy()\n",
    "\n",
    "# First, ensure the index is datetime\n",
    "df_bias.index = pd.to_datetime(df_bias.index)\n",
    "\n",
    "# Add month as a new column\n",
    "df_bias['month'] = df_bias.index.month\n",
    "\n",
    "# Create a dictionary to store results\n",
    "diff_results = {}\n",
    "\n",
    "# 1. For 2001â€“2014 (historical)\n",
    "hist_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    diff = df_bias.loc[hist_period, 'ERA5-Land'] - df_bias.loc[hist_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[hist_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 2. For 2015â€“2023 (future scenarios)\n",
    "future_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2023-12-31')\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    diff = df_bias.loc[future_period, 'ERA5-Land'] - df_bias.loc[future_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[future_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 3. Combine all differences into a dataframe\n",
    "diff_df = pd.DataFrame(diff_results)\n",
    "\n",
    "# Optional: sort the dataframe by month\n",
    "diff_df.index.name = 'month'\n",
    "diff_df = diff_df.sort_index()\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8938dea-3226-4d1e-b1f3-4298b27edb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the period you want to correct\n",
    "hist_correction_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "future_correction_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2100-12-31')\n",
    "\n",
    "# 2. Loop through each model/scenario you want to correct\n",
    "corrected_data = {}\n",
    "corrected_data['ERA5-Land'] = df_bias['ERA5-Land']\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    # Select the original model data for 2001â€“2014\n",
    "    model_data = df_bias.loc[hist_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[hist_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    # Select the original model data for 2015â€“2100\n",
    "    model_data = df_bias.loc[future_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[future_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "# 3. Combine corrected data into a dataframe\n",
    "corrected_df_mn2t = pd.DataFrame(corrected_data, index=df_bias.index)\n",
    "\n",
    "corrected_df_mn2t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603f3630-ee38-4ba4-b453-26c10c44fe17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ef664-cbe9-41f9-bbff-e2f0619afa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_mn2t_plot = df_mn2t.copy() # Original data\n",
    "df_mn2t_plot = corrected_df_mn2t.copy() # Corrected data\n",
    "df_mn2t_plot.index = pd.to_datetime(df_mn2t_plot.index)\n",
    "#df_mn2t_plot = df_mn2t_plot.loc['2001':'2014']\n",
    "df_mn2t_plot = df_mn2t_plot.loc['2001':'2023']\n",
    "df_mn2t_plot = df_mn2t_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot each column\n",
    "for column in df_mn2t_plot.columns:\n",
    "    plt.plot(df_mn2t_plot.index, df_mn2t_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "#years = pd.date_range(start='2001', end='2015', freq='YS')\n",
    "years = pd.date_range(start='2001', end='2023', freq='YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'MN2T Time Series for {region}')\n",
    "plt.title(f'Corrected MN2T Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('K')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/mn2t_plot_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84610e22-2958-4491-ac60-12358dec26ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "#df_mn2t_plot = df_mn2t.copy() # Original data\n",
    "df_mn2t_plot = corrected_df_mn2t.copy() # Corrected data\n",
    "df_mn2t_plot.index = pd.to_datetime(df_mn2t_plot.index)\n",
    "df_mn2t_plot = df_mn2t_plot.resample('YE').mean()\n",
    "df_mn2t_plot.index = df_mn2t_plot.index + pd.offsets.Day(1)\n",
    "df_mn2t_plot.index = df_mn2t_plot.index - pd.offsets.YearBegin(1)\n",
    "df_mn2t_plot = df_mn2t_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Plot each column\n",
    "for column in df_mn2t_plot.columns:\n",
    "    plt.plot(df_mn2t_plot.index, df_mn2t_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='5YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'MN2T Time Series for {region}')\n",
    "plt.title(f'Corrected MN2T Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('K')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/mn2t_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6cbe4c-2819-4b69-802a-c24feb0111f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## FWI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5feb92-2531-4626-ab5e-6b7daf9389d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### BUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d67e54-1340-4de2-8765-7eee400979c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Process and bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048dc6d-d0c4-43ed-857c-70b18b1d79f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUI\n",
    "df_bui = pd.DataFrame({\n",
    "    'CEMS': df_cems['BUI'],\n",
    "    'ACCESS_HIST': df_access_hist_fwi['BUI'],\n",
    "    'ACCESS_SSP126': df_access_126_fwi['BUI'],\n",
    "    'ACCESS_SSP245': df_access_245_fwi['BUI'],\n",
    "    'ACCESS_SSP370': df_access_370_fwi['BUI'],\n",
    "    'MRI_HIST': df_mri_hist_fwi['BUI'],\n",
    "    'MRI_SSP126': df_mri_126_fwi['BUI'],\n",
    "    'MRI_SSP245': df_mri_245_fwi['BUI'],\n",
    "    'MRI_SSP370': df_mri_370_fwi['BUI'],\n",
    "})\n",
    "\n",
    "df_bui.sort_index(inplace=True)\n",
    "df_bui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb5e6e6-04fe-42b1-945b-7bcc62ffa02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias correction\n",
    "df_bias = df_bui.copy()\n",
    "\n",
    "# First, ensure the index is datetime\n",
    "df_bias.index = pd.to_datetime(df_bias.index)\n",
    "\n",
    "# Add month as a new column\n",
    "df_bias['month'] = df_bias.index.month\n",
    "\n",
    "# Create a dictionary to store results\n",
    "diff_results = {}\n",
    "\n",
    "# 1. For 2001â€“2014 (historical)\n",
    "hist_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    diff = df_bias.loc[hist_period, 'CEMS'] - df_bias.loc[hist_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[hist_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 2. For 2015â€“2023 (future scenarios)\n",
    "future_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2023-12-31')\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    diff = df_bias.loc[future_period, 'CEMS'] - df_bias.loc[future_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[future_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 3. Combine all differences into a dataframe\n",
    "diff_df = pd.DataFrame(diff_results)\n",
    "\n",
    "# Optional: sort the dataframe by month\n",
    "diff_df.index.name = 'month'\n",
    "diff_df = diff_df.sort_index()\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002858d-f736-46c7-b933-7943bbd21a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the period you want to correct\n",
    "hist_correction_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "future_correction_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2100-12-31')\n",
    "\n",
    "# 2. Loop through each model/scenario you want to correct\n",
    "corrected_data = {}\n",
    "corrected_data['CEMS'] = df_bias['CEMS']\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    # Select the original model data for 2001â€“2014\n",
    "    model_data = df_bias.loc[hist_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[hist_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    # Select the original model data for 2015â€“2100\n",
    "    model_data = df_bias.loc[future_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[future_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "# 3. Combine corrected data into a dataframe\n",
    "corrected_df_bui = pd.DataFrame(corrected_data, index=df_bias.index)\n",
    "\n",
    "corrected_df_bui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49954c3-5b6e-47e9-aa25-03d1c3fa92d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c09f7-0512-41fb-9e7c-d9ad17fb4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_bui_plot = df_bui.copy() # Original data\n",
    "df_bui_plot = corrected_df_bui.copy() # Corrected data\n",
    "df_bui_plot.index = pd.to_datetime(df_bui_plot.index)\n",
    "#df_bui_plot = df_bui_plot.loc['2001':'2014']\n",
    "df_bui_plot = df_bui_plot.loc['2001':'2023']\n",
    "df_bui_plot = df_bui_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot each column\n",
    "for column in df_bui_plot.columns:\n",
    "    plt.plot(df_bui_plot.index, df_bui_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "#years = pd.date_range(start='2001', end='2015', freq='YS')\n",
    "years = pd.date_range(start='2001', end='2023', freq='YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'BUI Time Series for {region}')\n",
    "plt.title(f'Corrected BUI Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('BUI')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/bui_plot_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b334078e-d826-49f5-8198-dfb6b17dd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "#df_bui_plot = df_bui.copy() # Original data\n",
    "df_bui_plot = corrected_df_bui.copy() # Corrected data\n",
    "df_bui_plot.index = pd.to_datetime(df_bui_plot.index)\n",
    "df_bui_plot = df_bui_plot.resample('YE').mean()\n",
    "df_bui_plot.index = df_bui_plot.index + pd.offsets.Day(1)\n",
    "df_bui_plot.index = df_bui_plot.index - pd.offsets.YearBegin(1)\n",
    "df_bui_plot = df_bui_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Plot each column\n",
    "for column in df_bui_plot.columns:\n",
    "    plt.plot(df_bui_plot.index, df_bui_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='5YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'BUI Time Series for {region}')\n",
    "plt.title(f'Corrected BUI Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('BUI')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/bui_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3eb7bd-fc38-48f3-a9db-70876d2ca151",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae17808-3df4-4fa7-b6b9-3bffbc0696cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Process and bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf3850-eec1-4872-b95f-11b966672a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DC\n",
    "df_dc = pd.DataFrame({\n",
    "    'CEMS': df_cems['DC'],\n",
    "    'ACCESS_HIST': df_access_hist_fwi['DC'],\n",
    "    'ACCESS_SSP126': df_access_126_fwi['DC'],\n",
    "    'ACCESS_SSP245': df_access_245_fwi['DC'],\n",
    "    'ACCESS_SSP370': df_access_370_fwi['DC'],\n",
    "    'MRI_HIST': df_mri_hist_fwi['DC'],\n",
    "    'MRI_SSP126': df_mri_126_fwi['DC'],\n",
    "    'MRI_SSP245': df_mri_245_fwi['DC'],\n",
    "    'MRI_SSP370': df_mri_370_fwi['DC'],\n",
    "})\n",
    "\n",
    "df_dc.sort_index(inplace=True)\n",
    "df_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d9e32-f582-455b-ac10-8e28c2b072c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias correction\n",
    "df_bias = df_dc.copy()\n",
    "\n",
    "# First, ensure the index is datetime\n",
    "df_bias.index = pd.to_datetime(df_bias.index)\n",
    "\n",
    "# Add month as a new column\n",
    "df_bias['month'] = df_bias.index.month\n",
    "\n",
    "# Create a dictionary to store results\n",
    "diff_results = {}\n",
    "\n",
    "# 1. For 2001â€“2014 (historical)\n",
    "hist_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    diff = df_bias.loc[hist_period, 'CEMS'] - df_bias.loc[hist_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[hist_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 2. For 2015â€“2023 (future scenarios)\n",
    "future_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2023-12-31')\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    diff = df_bias.loc[future_period, 'CEMS'] - df_bias.loc[future_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[future_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 3. Combine all differences into a dataframe\n",
    "diff_df = pd.DataFrame(diff_results)\n",
    "\n",
    "# Optional: sort the dataframe by month\n",
    "diff_df.index.name = 'month'\n",
    "diff_df = diff_df.sort_index()\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8eede1-1723-4f8f-939b-6dbc94fd483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the period you want to correct\n",
    "hist_correction_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "future_correction_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2100-12-31')\n",
    "\n",
    "# 2. Loop through each model/scenario you want to correct\n",
    "corrected_data = {}\n",
    "corrected_data['CEMS'] = df_bias['CEMS']\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    # Select the original model data for 2001â€“2014\n",
    "    model_data = df_bias.loc[hist_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[hist_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    # Select the original model data for 2015â€“2100\n",
    "    model_data = df_bias.loc[future_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[future_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "# 3. Combine corrected data into a dataframe\n",
    "corrected_df_dc = pd.DataFrame(corrected_data, index=df_bias.index)\n",
    "\n",
    "corrected_df_dc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf4b4f9-62d7-4c87-a0f0-0ee574859c55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b490699-5f12-4fd4-9953-54a55ea118e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dc_plot = df_dc.copy() # Original data\n",
    "df_dc_plot = corrected_df_dc.copy() # Corrected data\n",
    "df_dc_plot.index = pd.to_datetime(df_dc_plot.index)\n",
    "#df_dc_plot = df_dc_plot.loc['2001':'2014']\n",
    "df_dc_plot = df_dc_plot.loc['2001':'2023']\n",
    "df_dc_plot = df_dc_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot each column\n",
    "for column in df_dc_plot.columns:\n",
    "    plt.plot(df_dc_plot.index, df_dc_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "#years = pd.date_range(start='2001', end='2015', freq='YS')\n",
    "years = pd.date_range(start='2001', end='2023', freq='YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'DC Time Series for {region}')\n",
    "plt.title(f'Corrected DC Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('DC')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/dc_plot_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd2e32-64e8-4918-a0dd-bbd2600b9a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))# Set figure size\n",
    "\n",
    "#df_dc_plot = df_dc.copy() # Original data\n",
    "df_dc_plot = corrected_df_dc.copy() # Corrected data\n",
    "df_dc_plot.index = pd.to_datetime(df_dc_plot.index)\n",
    "df_dc_plot = df_dc_plot.resample('YE').mean()\n",
    "df_dc_plot.index = df_dc_plot.index + pd.offsets.Day(1)\n",
    "df_dc_plot.index = df_dc_plot.index - pd.offsets.YearBegin(1)\n",
    "df_dc_plot = df_dc_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Plot each column\n",
    "for column in df_dc_plot.columns:\n",
    "    plt.plot(df_dc_plot.index, df_dc_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='5YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'DC Time Series for {region}')\n",
    "plt.title(f'Corrected DC Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('DC')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/dc_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cdb89e-a433-4798-b9ff-6c40abd8660c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DMC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0280977a-23ff-4272-a824-497e6c2207b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Process and bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b770ea1-a02d-4b86-a388-b70104fa3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMC\n",
    "df_dmc = pd.DataFrame({\n",
    "    'CEMS': df_cems['DMC'],\n",
    "    'ACCESS_HIST': df_access_hist_fwi['DMC'],\n",
    "    'ACCESS_SSP126': df_access_126_fwi['DMC'],\n",
    "    'ACCESS_SSP245': df_access_245_fwi['DMC'],\n",
    "    'ACCESS_SSP370': df_access_370_fwi['DMC'],\n",
    "    'MRI_HIST': df_mri_hist_fwi['DMC'],\n",
    "    'MRI_SSP126': df_mri_126_fwi['DMC'],\n",
    "    'MRI_SSP245': df_mri_245_fwi['DMC'],\n",
    "    'MRI_SSP370': df_mri_370_fwi['DMC'],\n",
    "})\n",
    "\n",
    "df_dmc.sort_index(inplace=True)\n",
    "df_dmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3cd29-826a-46fc-b126-67084b1f2d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias correction\n",
    "df_bias = df_dmc.copy()\n",
    "\n",
    "# First, ensure the index is datetime\n",
    "df_bias.index = pd.to_datetime(df_bias.index)\n",
    "\n",
    "# Add month as a new column\n",
    "df_bias['month'] = df_bias.index.month\n",
    "\n",
    "# Create a dictionary to store results\n",
    "diff_results = {}\n",
    "\n",
    "# 1. For 2001â€“2014 (historical)\n",
    "hist_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    diff = df_bias.loc[hist_period, 'CEMS'] - df_bias.loc[hist_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[hist_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 2. For 2015â€“2023 (future scenarios)\n",
    "future_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2023-12-31')\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    diff = df_bias.loc[future_period, 'CEMS'] - df_bias.loc[future_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[future_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 3. Combine all differences into a dataframe\n",
    "diff_df = pd.DataFrame(diff_results)\n",
    "\n",
    "# Optional: sort the dataframe by month\n",
    "diff_df.index.name = 'month'\n",
    "diff_df = diff_df.sort_index()\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd288f0d-5238-4690-840c-cbb406d9973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the period you want to correct\n",
    "hist_correction_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "future_correction_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2100-12-31')\n",
    "\n",
    "# 2. Loop through each model/scenario you want to correct\n",
    "corrected_data = {}\n",
    "corrected_data['CEMS'] = df_bias['CEMS']\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    # Select the original model data for 2001â€“2014\n",
    "    model_data = df_bias.loc[hist_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[hist_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    # Select the original model data for 2015â€“2100\n",
    "    model_data = df_bias.loc[future_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[future_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "# 3. Combine corrected data into a dataframe\n",
    "corrected_df_dmc = pd.DataFrame(corrected_data, index=df_bias.index)\n",
    "\n",
    "corrected_df_dmc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be9e10-2c5d-4ce4-b0f5-e526c41406ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b093f6e-b578-424c-ab1b-1f04c5e1d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dmc_plot = df_dmc.copy() # Original data\n",
    "df_dmc_plot = corrected_df_dmc.copy() # Corrected data\n",
    "df_dmc_plot.index = pd.to_datetime(df_dmc_plot.index)\n",
    "#df_dmc_plot = df_dmc_plot.loc['2001':'2014']\n",
    "df_dmc_plot = df_dmc_plot.loc['2001':'2023']\n",
    "df_dmc_plot = df_dmc_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot each column\n",
    "for column in df_dmc_plot.columns:\n",
    "    plt.plot(df_dmc_plot.index, df_dmc_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "#years = pd.date_range(start='2001', end='2015', freq='YS')\n",
    "years = pd.date_range(start='2001', end='2023', freq='YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'DMC Time Series for {region}')\n",
    "plt.title(f'Corrected DMC Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('DMC')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/dmc_plot_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9799078f-639a-4ab2-a0f6-317fc856c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "#df_dmc_plot = df_dmc.copy() # Original data\n",
    "df_dmc_plot = corrected_df_dmc.copy() # Corrected data\n",
    "df_dmc_plot.index = pd.to_datetime(df_dmc_plot.index)\n",
    "df_dmc_plot = df_dmc_plot.resample('YE').mean()\n",
    "df_dmc_plot.index = df_dmc_plot.index + pd.offsets.Day(1)\n",
    "df_dmc_plot.index = df_dmc_plot.index - pd.offsets.YearBegin(1)\n",
    "df_dmc_plot = df_dmc_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Plot each column\n",
    "for column in df_dmc_plot.columns:\n",
    "    plt.plot(df_dmc_plot.index, df_dmc_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='5YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'DMC Time Series for {region}')\n",
    "plt.title(f'Corrected DMC Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('DMC')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/dmc_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003853aa-f03f-4995-9b1a-c1bc1bb057bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### FFMC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab11eb7a-551b-462d-9857-12d1b578aef0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Process and bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6ccc10-6e81-4224-8f71-fa90f1eb2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFMC\n",
    "df_ffmc = pd.DataFrame({\n",
    "    'CEMS': df_cems['FFMC'],\n",
    "    'ACCESS_HIST': df_access_hist_fwi['FFMC'],\n",
    "    'ACCESS_SSP126': df_access_126_fwi['FFMC'],\n",
    "    'ACCESS_SSP245': df_access_245_fwi['FFMC'],\n",
    "    'ACCESS_SSP370': df_access_370_fwi['FFMC'],\n",
    "    'MRI_HIST': df_mri_hist_fwi['FFMC'],\n",
    "    'MRI_SSP126': df_mri_126_fwi['FFMC'],\n",
    "    'MRI_SSP245': df_mri_245_fwi['FFMC'],\n",
    "    'MRI_SSP370': df_mri_370_fwi['FFMC'],\n",
    "})\n",
    "\n",
    "df_ffmc.sort_index(inplace=True)\n",
    "df_ffmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae7751c-c85a-4271-876e-7e8b4403af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias correction\n",
    "df_bias = df_ffmc.copy()\n",
    "\n",
    "# First, ensure the index is datetime\n",
    "df_bias.index = pd.to_datetime(df_bias.index)\n",
    "\n",
    "# Add month as a new column\n",
    "df_bias['month'] = df_bias.index.month\n",
    "\n",
    "# Create a dictionary to store results\n",
    "diff_results = {}\n",
    "\n",
    "# 1. For 2001â€“2014 (historical)\n",
    "hist_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    diff = df_bias.loc[hist_period, 'CEMS'] - df_bias.loc[hist_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[hist_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 2. For 2015â€“2023 (future scenarios)\n",
    "future_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2023-12-31')\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    diff = df_bias.loc[future_period, 'CEMS'] - df_bias.loc[future_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[future_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 3. Combine all differences into a dataframe\n",
    "diff_df = pd.DataFrame(diff_results)\n",
    "\n",
    "# Optional: sort the dataframe by month\n",
    "diff_df.index.name = 'month'\n",
    "diff_df = diff_df.sort_index()\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4606f2-e8c3-4fff-ae7e-f7d7ff90c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the period you want to correct\n",
    "hist_correction_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "future_correction_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2100-12-31')\n",
    "\n",
    "# 2. Loop through each model/scenario you want to correct\n",
    "corrected_data = {}\n",
    "corrected_data['CEMS'] = df_bias['CEMS']\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    # Select the original model data for 2001â€“2014\n",
    "    model_data = df_bias.loc[hist_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[hist_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    # Select the original model data for 2015â€“2100\n",
    "    model_data = df_bias.loc[future_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[future_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "# 3. Combine corrected data into a dataframe\n",
    "corrected_df_ffmc = pd.DataFrame(corrected_data, index=df_bias.index)\n",
    "\n",
    "corrected_df_ffmc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed32140-21d7-4c8d-a4a2-b21cb9c83057",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f82830-1a5a-4b20-9a87-6ea686672871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ffmc_plot = df_ffmc.copy() # Original data\n",
    "df_ffmc_plot = corrected_df_ffmc.copy() # Corrected data\n",
    "df_ffmc_plot.index = pd.to_datetime(df_ffmc_plot.index)\n",
    "#df_ffmc_plot = df_ffmc_plot.loc['2001':'2014']\n",
    "df_ffmc_plot = df_ffmc_plot.loc['2001':'2023']\n",
    "df_ffmc_plot = df_ffmc_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot each column\n",
    "for column in df_ffmc_plot.columns:\n",
    "    plt.plot(df_ffmc_plot.index, df_ffmc_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "#years = pd.date_range(start='2001', end='2015', freq='YS')\n",
    "years = pd.date_range(start='2001', end='2023', freq='YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'FFMC Time Series for {region}')\n",
    "plt.title(f'Corrected FFMC Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('FFMC')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/ffmc_plot_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9056c09-7fb7-47df-be1c-79608ed73f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "#df_ffmc_plot = df_ffmc.copy() # Original data\n",
    "df_ffmc_plot = corrected_df_ffmc.copy() # Corrected data\n",
    "df_ffmc_plot.index = pd.to_datetime(df_ffmc_plot.index)\n",
    "df_ffmc_plot = df_ffmc_plot.resample('YE').mean()\n",
    "df_ffmc_plot.index = df_ffmc_plot.index + pd.offsets.Day(1)\n",
    "df_ffmc_plot.index = df_ffmc_plot.index - pd.offsets.YearBegin(1)\n",
    "df_ffmc_plot = df_ffmc_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Plot each column\n",
    "for column in df_ffmc_plot.columns:\n",
    "    plt.plot(df_ffmc_plot.index, df_ffmc_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='5YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'FFMC Time Series for {region}')\n",
    "plt.title(f'Corrected FFMC Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('FFMC')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/ffmc_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f26176-ea85-4aed-a262-ddedd2cbd9d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### FWI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b8dd21-7e40-4faf-8c06-c1d6b64a21cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Process and bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a13216-e291-475c-80a2-e0c019e7983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FWI\n",
    "df_fwi = pd.DataFrame({\n",
    "    'CEMS': df_cems['FWI'],\n",
    "    'ACCESS_HIST': df_access_hist_fwi['FWI'],\n",
    "    'ACCESS_SSP126': df_access_126_fwi['FWI'],\n",
    "    'ACCESS_SSP245': df_access_245_fwi['FWI'],\n",
    "    'ACCESS_SSP370': df_access_370_fwi['FWI'],\n",
    "    'MRI_HIST': df_mri_hist_fwi['FWI'],\n",
    "    'MRI_SSP126': df_mri_126_fwi['FWI'],\n",
    "    'MRI_SSP245': df_mri_245_fwi['FWI'],\n",
    "    'MRI_SSP370': df_mri_370_fwi['FWI'],\n",
    "})\n",
    "\n",
    "df_fwi.sort_index(inplace=True)\n",
    "df_fwi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe70ce1-da2a-425e-ba96-a5b875003bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias correction\n",
    "df_bias = df_fwi.copy()\n",
    "\n",
    "# First, ensure the index is datetime\n",
    "df_bias.index = pd.to_datetime(df_bias.index)\n",
    "\n",
    "# Add month as a new column\n",
    "df_bias['month'] = df_bias.index.month\n",
    "\n",
    "# Create a dictionary to store results\n",
    "diff_results = {}\n",
    "\n",
    "# 1. For 2001â€“2014 (historical)\n",
    "hist_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    diff = df_bias.loc[hist_period, 'CEMS'] - df_bias.loc[hist_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[hist_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 2. For 2015â€“2023 (future scenarios)\n",
    "future_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2023-12-31')\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    diff = df_bias.loc[future_period, 'CEMS'] - df_bias.loc[future_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[future_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 3. Combine all differences into a dataframe\n",
    "diff_df = pd.DataFrame(diff_results)\n",
    "\n",
    "# Optional: sort the dataframe by month\n",
    "diff_df.index.name = 'month'\n",
    "diff_df = diff_df.sort_index()\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fbc804-9e29-428b-847f-3b3c2e0a8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the period you want to correct\n",
    "hist_correction_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "future_correction_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2100-12-31')\n",
    "\n",
    "# 2. Loop through each model/scenario you want to correct\n",
    "corrected_data = {}\n",
    "corrected_data['CEMS'] = df_bias['CEMS']\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    # Select the original model data for 2001â€“2014\n",
    "    model_data = df_bias.loc[hist_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[hist_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    # Select the original model data for 2015â€“2100\n",
    "    model_data = df_bias.loc[future_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[future_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "# 3. Combine corrected data into a dataframe\n",
    "corrected_df_fwi = pd.DataFrame(corrected_data, index=df_bias.index)\n",
    "\n",
    "corrected_df_fwi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76503bce-fe95-4529-bbf0-0790f7b10c2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f009e-45c5-4e4c-ae3b-c152d90337bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fwi_plot = df_fwi.copy() # Original data\n",
    "df_fwi_plot = corrected_df_fwi.copy() # Corrected data\n",
    "df_fwi_plot.index = pd.to_datetime(df_fwi_plot.index)\n",
    "#df_fwi_plot = df_fwi_plot.loc['2001':'2014']\n",
    "df_fwi_plot = df_fwi_plot.loc['2001':'2023']\n",
    "df_fwi_plot = df_fwi_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot each column\n",
    "for column in df_fwi_plot.columns:\n",
    "    plt.plot(df_fwi_plot.index, df_fwi_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "#years = pd.date_range(start='2001', end='2015', freq='YS')\n",
    "years = pd.date_range(start='2001', end='2023', freq='YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'FWI Time Series for {region}')\n",
    "plt.title(f'Corrected FWI Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('FWI')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/fwi_plot_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d797b0c9-708f-485a-bda3-b15a6407a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "#df_fwi_plot = df_fwi.copy() # Original data\n",
    "df_fwi_plot = corrected_df_fwi.copy() # Corrected data\n",
    "df_fwi_plot.index = pd.to_datetime(df_fwi_plot.index)\n",
    "df_fwi_plot = df_fwi_plot.resample('YE').mean()\n",
    "df_fwi_plot.index = df_fwi_plot.index + pd.offsets.Day(1)\n",
    "df_fwi_plot.index = df_fwi_plot.index - pd.offsets.YearBegin(1)\n",
    "df_fwi_plot = df_fwi_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Plot each column\n",
    "for column in df_fwi_plot.columns:\n",
    "    plt.plot(df_fwi_plot.index, df_fwi_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='5YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'FWI Time Series for {region}')\n",
    "plt.title(f'Corrected FWI Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('FWI')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/fwi_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c50c3c-6ad4-457b-9cb5-5eeb5d12e55d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ISI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe43c26a-4b86-4e99-8de6-48b0c26ba767",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Process and bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd645e-9810-4c65-afd7-3ff362f0e7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISI\n",
    "df_isi = pd.DataFrame({\n",
    "    'CEMS': df_cems['ISI'],\n",
    "    'ACCESS_HIST': df_access_hist_fwi['ISI'],\n",
    "    'ACCESS_SSP126': df_access_126_fwi['ISI'],\n",
    "    'ACCESS_SSP245': df_access_245_fwi['ISI'],\n",
    "    'ACCESS_SSP370': df_access_370_fwi['ISI'],\n",
    "    'MRI_HIST': df_mri_hist_fwi['ISI'],\n",
    "    'MRI_SSP126': df_mri_126_fwi['ISI'],\n",
    "    'MRI_SSP245': df_mri_245_fwi['ISI'],\n",
    "    'MRI_SSP370': df_mri_370_fwi['ISI'],\n",
    "})\n",
    "\n",
    "df_isi.sort_index(inplace=True)\n",
    "df_isi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d26782d-eb6e-4e4a-9916-3254202a0ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias correction\n",
    "df_bias = df_isi.copy()\n",
    "\n",
    "# First, ensure the index is datetime\n",
    "df_bias.index = pd.to_datetime(df_bias.index)\n",
    "\n",
    "# Add month as a new column\n",
    "df_bias['month'] = df_bias.index.month\n",
    "\n",
    "# Create a dictionary to store results\n",
    "diff_results = {}\n",
    "\n",
    "# 1. For 2001â€“2014 (historical)\n",
    "hist_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    diff = df_bias.loc[hist_period, 'CEMS'] - df_bias.loc[hist_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[hist_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 2. For 2015â€“2023 (future scenarios)\n",
    "future_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2023-12-31')\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    diff = df_bias.loc[future_period, 'CEMS'] - df_bias.loc[future_period, model]\n",
    "    monthly_diff = diff.groupby(df_bias.loc[future_period, 'month']).mean()\n",
    "    diff_results[model] = monthly_diff\n",
    "\n",
    "# 3. Combine all differences into a dataframe\n",
    "diff_df = pd.DataFrame(diff_results)\n",
    "\n",
    "# Optional: sort the dataframe by month\n",
    "diff_df.index.name = 'month'\n",
    "diff_df = diff_df.sort_index()\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c35b4bf-5737-4387-b2ab-a4b42a12aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the period you want to correct\n",
    "hist_correction_period = (df_bias.index >= '2001-01-01') & (df_bias.index <= '2014-12-31')\n",
    "future_correction_period = (df_bias.index >= '2015-01-01') & (df_bias.index <= '2100-12-31')\n",
    "\n",
    "# 2. Loop through each model/scenario you want to correct\n",
    "corrected_data = {}\n",
    "corrected_data['CEMS'] = df_bias['CEMS']\n",
    "\n",
    "for model in ['ACCESS_HIST', 'MRI_HIST']:\n",
    "    # Select the original model data for 2001â€“2014\n",
    "    model_data = df_bias.loc[hist_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[hist_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "for model in ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "              'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']:\n",
    "    # Select the original model data for 2015â€“2100\n",
    "    model_data = df_bias.loc[future_correction_period, model].copy()\n",
    "    \n",
    "    # Get the corresponding month for each row\n",
    "    months = df_bias.loc[future_correction_period, 'month']\n",
    "    \n",
    "    # Subtract the bias correction based on the month\n",
    "    corrected_values = model_data + months.map(diff_df[model])\n",
    "    \n",
    "    # Store in a dictionary\n",
    "    corrected_data[model] = corrected_values\n",
    "\n",
    "# 3. Combine corrected data into a dataframe\n",
    "corrected_df_isi = pd.DataFrame(corrected_data, index=df_bias.index)\n",
    "\n",
    "corrected_df_isi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c539f-0a8b-4cc0-bec0-3be9d9f67ce3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e78749-4891-49fa-8504-6f8304c91af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_isi_plot = df_isi.copy() # Original data\n",
    "df_isi_plot = corrected_df_isi.copy() # Corrected data\n",
    "df_isi_plot.index = pd.to_datetime(df_isi_plot.index)\n",
    "#df_isi_plot = df_isi_plot.loc['2001':'2014']\n",
    "df_isi_plot = df_isi_plot.loc['2001':'2023']\n",
    "df_isi_plot = df_isi_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot each column\n",
    "for column in df_isi_plot.columns:\n",
    "    plt.plot(df_isi_plot.index, df_isi_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "#years = pd.date_range(start='2001', end='2015', freq='YS')\n",
    "years = pd.date_range(start='2001', end='2023', freq='YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'ISI Time Series for {region}')\n",
    "plt.title(f'Corrected ISI Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('ISI')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/isi_plot_{region}_2001_2023.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c600c-a282-439e-80e0-60ae35495739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "#df_isi_plot = df_isi.copy() # Original data\n",
    "df_isi_plot = corrected_df_isi.copy() # Corrected data\n",
    "df_isi_plot.index = pd.to_datetime(df_isi_plot.index)\n",
    "df_isi_plot = df_isi_plot.resample('YE').mean()\n",
    "df_isi_plot.index = df_isi_plot.index + pd.offsets.Day(1)\n",
    "df_isi_plot.index = df_isi_plot.index - pd.offsets.YearBegin(1)\n",
    "df_isi_plot = df_isi_plot.dropna(axis=1, how='all')\n",
    "\n",
    "# Plot each column\n",
    "for column in df_isi_plot.columns:\n",
    "    plt.plot(df_isi_plot.index, df_isi_plot[column], label=column)\n",
    "\n",
    "# Set major ticks to every 5 years\n",
    "years = pd.date_range(start='2000', end='2100', freq='5YS')\n",
    "plt.gca().set_xticks(years)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add title and labels\n",
    "#plt.title(f'ISI Time Series for {region}')\n",
    "plt.title(f'Corrected ISI Time Series for {region}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('ISI')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "           ncol=3, fancybox=True, shadow=True) # Legend below\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}/isi_plot_{region}_2001_2100.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4160c-6b4d-4204-a8c6-53d6bb2178f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
