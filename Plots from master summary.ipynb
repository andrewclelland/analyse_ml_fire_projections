{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57dfd276-50d7-4ecc-b634-db831af7d989",
   "metadata": {},
   "source": [
    "# Make plots from the master summary file\n",
    "\n",
    "Before running any of this code, combine all the individual ecoregion summary files (over quarter-century future periods) into one master file called `master_summary.csv`.\n",
    "\n",
    "This Notebook then makes circumpolar plots of:\n",
    "\n",
    "*  Bias-corrected raw/percent changes in climate and fire weather indices over time compared to the observed historic values\n",
    "*  Bar plots of the modelled future burned area per grouped region (North America boreal/Eurasia boreal/all tundra)\n",
    "*  Extreme year bar plots\n",
    "*  Raw change of BA per time period\n",
    "*  Calculates the Fire Return Interval (FRI) and makes plots of the model/actual/change in FRI over time periods\n",
    "*  Basic ecoregion maps (i.e. boreal vs tundra, with/without numerical labels, with/without permafrost)\n",
    "*  Spearman correlations of each variable against BA\n",
    "\n",
    "Edit as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a5b9e-72b9-40a1-8d77-0eb4bf7cf70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize, BoundaryNorm\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616016c5-afcc-4f1e-9c30-6da5dabb9922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load shapefile\n",
    "shp_path = '/home/users/clelland/Model/Analysis/RESOLVE shapefile from GEE/resolve_shapefile_from_gee.shp'\n",
    "gdf = gpd.read_file(shp_path)\n",
    "gdf = gdf.to_crs(epsg=6931)\n",
    "selected_ecoregions = gdf[gdf['BIOME_NAME'].isin(['Boreal Forests/Taiga', 'Tundra'])].reset_index(drop=True)\n",
    "\n",
    "world_path = '/home/users/clelland/Model/Analysis/Countries shapefile/world-administrative-boundaries.shp'\n",
    "gdf_world = gpd.read_file(world_path)\n",
    "gdf_world = gdf_world.to_crs(epsg=6931)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d8801-f412-454e-a8d7-330faee3981c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Climate and FWI variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc54d2-eaeb-4427-9237-ab2fd3937c88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### % change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf327a-85bf-455b-a149-92665cf0c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load master summary file\n",
    "summary_df = pd.read_csv('/home/users/clelland/Model/Analysis/Summary stats/master_summary.csv')\n",
    "\n",
    "# Get unique values\n",
    "variables = summary_df['variable'].unique()\n",
    "models = [m for m in summary_df['model'].unique() if m != 'Observed']\n",
    "periods = summary_df['period'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f9062-6566-412d-b1df-9f31fb1a84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = summary_df[summary_df['variable'] == 'ISI']\n",
    "quantiles = new['percent_change'].quantile([0.05, 0.5, 0.95])\n",
    "print(\"Min: \", new['percent_change'].min())\n",
    "print(quantiles)\n",
    "print(\"Max: \", new['percent_change'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e42fb9-dd75-49c6-a2a9-b0e3c994b38b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop and create plots\n",
    "#for var in variables:\n",
    "for var in ['t2m']:\n",
    "    #for model in models:\n",
    "    for model in ['ACCESS_SSP126']:\n",
    "        #for period in periods:\n",
    "        for period in ['2025_2050']:\n",
    "            if period == 'historical':\n",
    "                continue\n",
    "            df_filtered = summary_df[\n",
    "                (summary_df['variable'] == var) &\n",
    "                (summary_df['model'] == model) &\n",
    "                (summary_df['period'] == period)\n",
    "            ].reset_index(drop=True)\n",
    "\n",
    "            if len(df_filtered) != len(selected_ecoregions):\n",
    "                print(f\"Skipping {var}-{model}-{period}: mismatch in rows ({len(df_filtered)} vs {len(selected_ecoregions)})\")\n",
    "                continue\n",
    "\n",
    "            # Attach percent_change to shapefile GeoDataFrame\n",
    "            selected_ecoregions['percent_change'] = df_filtered['percent_change'].values\n",
    "\n",
    "            # Plot with stretched colormap from -5 to 5\n",
    "            fig, ax = plt.subplots(figsize=(10, 10))\n",
    "            minx, miny, maxx, maxy = selected_ecoregions.total_bounds\n",
    "            buffer = 300000 # 300 km\n",
    "            ax.set_xlim(minx-buffer, maxx+buffer)\n",
    "            ax.set_ylim(miny-buffer, maxy+buffer)\n",
    "            \n",
    "            # Plot light blue background (ocean)\n",
    "            ax.add_patch(plt.Rectangle((minx - buffer, miny - buffer), (maxx - minx) + 2 * buffer, (maxy - miny) + 2 * buffer, \n",
    "                                       facecolor='#f8fcff', zorder=0))\n",
    "            \n",
    "            gdf_world.plot(ax=ax, color='white', edgecolor='black', linewidth=0.1)\n",
    "        \n",
    "            norm = Normalize(vmin=-2, vmax=2)\n",
    "            gdf.plot(\n",
    "                column=selected_ecoregions['percent_change'],\n",
    "                cmap='coolwarm',\n",
    "                linewidth=0.1,\n",
    "                edgecolor='black',\n",
    "                norm=norm,\n",
    "                ax=ax\n",
    "            )\n",
    "            \n",
    "            # Add colorbar\n",
    "            sm = plt.cm.ScalarMappable(cmap='coolwarm', norm=norm)\n",
    "            sm._A = []\n",
    "            cbar = fig.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.05, pad=0.01)\n",
    "            cbar.set_label('% Change')\n",
    "            \n",
    "            plt.title(f'{var} - {model} ({period})', fontsize=14)\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Save figure\n",
    "            out_path = f'/home/users/clelland/Model/Analysis/Summary stats/{var}/{var}_{model}_{period}_percent_change.png'\n",
    "            #plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64d5b1e-d6c1-4253-913d-962eb8c397d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Raw change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678235d-99c5-4ad5-b712-a9cdeb9f660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load master summary file\n",
    "summary_df = pd.read_csv('/home/users/clelland/Model/Analysis/Summary stats/master_summary.csv')\n",
    "\n",
    "# Get unique values\n",
    "variables = summary_df['variable'].unique()\n",
    "models = [m for m in summary_df['model'].unique() if m != 'Observed']\n",
    "periods = summary_df['period'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfdccd6-b935-481c-81eb-d16b4e0829fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = summary_df[summary_df['variable'] == 't2m']\n",
    "observed_means = new[new['model'] == 'Observed'][['region', 'variable', 'mean_value']]\n",
    "observed_means = observed_means.rename(columns={'mean_value': 'observed_mean'})\n",
    "\n",
    "# Step 2: Merge with the original DataFrame\n",
    "summary_df = summary_df.merge(observed_means, on=['region', 'variable'], how='left')\n",
    "\n",
    "# Step 3: Calculate raw_change\n",
    "summary_df['raw_change'] = summary_df['mean_value'] - summary_df['observed_mean']\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496c5765-ea56-4033-8cd4-8c62b00b1193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop and create plots\n",
    "#for var in variables:\n",
    "for var in ['t2m']:\n",
    "    for model in models:\n",
    "    #for model in ['ACCESS_SSP370']:\n",
    "        for period in periods:\n",
    "        #for period in ['2025_2050']:\n",
    "            if period == 'historical':\n",
    "                continue\n",
    "            df_filtered = summary_df[\n",
    "                (summary_df['variable'] == var) &\n",
    "                (summary_df['model'] == model) &\n",
    "                (summary_df['period'] == period)\n",
    "            ].reset_index(drop=True)\n",
    "\n",
    "            if len(df_filtered) != len(selected_ecoregions):\n",
    "                print(f\"Skipping {var}-{model}-{period}: mismatch in rows ({len(df_filtered)} vs {len(selected_ecoregions)})\")\n",
    "                continue\n",
    "\n",
    "            # Attach percent_change to shapefile GeoDataFrame\n",
    "            selected_ecoregions['raw_change'] = df_filtered['raw_change'].values\n",
    "\n",
    "            # Plot with stretched colormap from -5 to 5\n",
    "            fig, ax = plt.subplots(figsize=(10, 10))\n",
    "            minx, miny, maxx, maxy = selected_ecoregions.total_bounds\n",
    "            buffer = 300000 # 300 km\n",
    "            ax.set_xlim(minx-buffer, maxx+buffer)\n",
    "            ax.set_ylim(miny-buffer, maxy+buffer)\n",
    "            \n",
    "            # Plot light blue background (ocean)\n",
    "            ax.add_patch(plt.Rectangle((minx - buffer, miny - buffer), (maxx - minx) + 2 * buffer, (maxy - miny) + 2 * buffer, \n",
    "                                       facecolor='#f8fcff', zorder=0))\n",
    "            \n",
    "            gdf_world.plot(ax=ax, color='white', edgecolor='black', linewidth=0.1)\n",
    "        \n",
    "            norm = Normalize(vmin=-9, vmax=9)\n",
    "            gdf.plot(\n",
    "                column=selected_ecoregions['raw_change'],\n",
    "                cmap='coolwarm',\n",
    "                linewidth=0.1,\n",
    "                edgecolor='black',\n",
    "                norm=norm,\n",
    "                ax=ax\n",
    "            )\n",
    "            \n",
    "            # Add colorbar\n",
    "            sm = plt.cm.ScalarMappable(cmap='coolwarm', norm=norm)\n",
    "            sm._A = []\n",
    "            cbar = fig.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.05, pad=0.01)\n",
    "            cbar.set_label('Raw Change (°C)')\n",
    "            \n",
    "            plt.title(f'{var} - {model} ({period})', fontsize=14)\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Save figure\n",
    "            out_path = f'/home/users/clelland/Model/Analysis/Summary stats/{var}/{var}_{model}_{period}_raw_change.png'\n",
    "            plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa01a8d-8307-4e61-91be-63abf35f4773",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load for BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33979be7-e930-40ae-a2fa-79a422e4760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of region names — must match order of selected_ecoregions\n",
    "region_mappings  = [('alaspen', 'alapen'), ('centcan', 'cancsh'), ('cookinl', 'cookin'), ('copppla', 'copper'), ('eastcan', 'eastcf'), ('eashti', 'eashti'),\n",
    "               ('inteala', 'intlow'), ('mid-bor', 'midbor'), ('midwcan', 'midwes'), ('musklak', 'muslta'), ('nortcan', 'norths'), ('southud', 'sohudb'),\n",
    "               ('watshig', 'watson'), ('nortcor', 'norcor'), ('nortter', 'nwterr'), ('eastsib', 'eastsib'), ('icelbor', 'icelnd'), ('kamcmea', 'kamkurm'),\n",
    "               ('kamctai', 'kamtaig'), ('nesibta', 'nesibta'), ('okhotai', 'okhman'), ('sakhisl', 'sakhtai'), ('trancon', 'trzconf'), ('westsib', 'westsib'),\n",
    "               ('scanand', 'scrusta'), ('uralmon', 'uralfor'), ('ahkland', 'ahklun'), ('berilow', 'berlow'), ('brooran', 'brookr'), ('kalanun', 'kalhar'),\n",
    "               ('pacicoa', 'pacice'), ('novoisl', 'novoisl'), ('wranisl', 'wrangel'), ('alaseli', 'aleias'), ('arctcoa', 'arccoa'), ('arctfoo', 'arcfoo'),\n",
    "               ('beriupl', 'berupl'), ('canalow', 'canlow'), ('davihig', 'davish'), ('canahig', 'canhig'), ('inteyuk', 'intalp'), ('canamid', 'canmid'),\n",
    "               ('ogilalp', 'ogilvi'), ('tornmou', 'tornga'), ('kalste', 'kalste'), ('russarc', 'rusarc'), ('russber', 'rusbert'), ('chermou', 'cherski'),\n",
    "               ('chukpen', 'chukchi'), ('kolapen', 'kolapen'), ('nortsib', 'nesibco'), ('nortrus', 'nwrunz'), ('scanmon', 'scambf'), ('taimsib', 'taicens'),\n",
    "               ('tranbal', 'trzbald'), ('yamatun', 'yamalgy'), ('kamctun', 'kamtund')]\n",
    "\n",
    "# Model/scenario combinations\n",
    "models = ['access 126', 'access 245', 'access 370', 'mri 126', 'mri 245', 'mri 370']\n",
    "model_labels = {\n",
    "    'access 126': 'ACCESS_SSP126',\n",
    "    'access 245': 'ACCESS_SSP245',\n",
    "    'access 370': 'ACCESS_SSP370',\n",
    "    'mri 126': 'MRI_SSP126',\n",
    "    'mri 245': 'MRI_SSP245',\n",
    "    'mri 370': 'MRI_SSP370'\n",
    "}\n",
    "\n",
    "# Time periods for projections\n",
    "periods = {\n",
    "    '2025_2050': ('2025', '2050'),\n",
    "    '2051_2075': ('2051', '2075'),\n",
    "    '2076_2100': ('2076', '2100')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88de223-c80e-4d7c-8dcb-10cab517ff64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Bar plot of regional BA, including extreme years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c770f-b367-4e38-b8e2-6a174ec2de09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "region_mappings  = [('alaspen', 'alapen'), ('centcan', 'cancsh'), ('cookinl', 'cookin'), ('copppla', 'copper'), ('eastcan', 'eastcf'), ('eashti', 'eashti'),\n",
    "               ('inteala', 'intlow'), ('mid-bor', 'midbor'), ('midwcan', 'midwes'), ('musklak', 'muslta'), ('nortcan', 'norths'), ('southud', 'sohudb'),\n",
    "               ('watshig', 'watson'), ('nortcor', 'norcor'), ('nortter', 'nwterr')] # N America boreal\n",
    "#region_mappings  = [('eastsib', 'eastsib'), ('icelbor', 'icelnd'), ('kamcmea', 'kamkurm'),\n",
    "#               ('kamctai', 'kamtaig'), ('nesibta', 'nesibta'), ('okhotai', 'okhman'), ('sakhisl', 'sakhtai'), ('trancon', 'trzconf'), ('westsib', 'westsib'),\n",
    "#               ('scanand', 'scrusta'), ('uralmon', 'uralfor')] # Eurasia boreal\n",
    "#region_mappings  = [('ahkland', 'ahklun'), ('berilow', 'berlow'), ('brooran', 'brookr'), ('kalanun', 'kalhar'),\n",
    "#               ('pacicoa', 'pacice'), ('novoisl', 'novoisl'), ('wranisl', 'wrangel'), ('alaseli', 'aleias'), ('arctcoa', 'arccoa'), ('arctfoo', 'arcfoo'),\n",
    "#               ('beriupl', 'berupl'), ('canalow', 'canlow'), ('davihig', 'davish'), ('canahig', 'canhig'), ('inteyuk', 'intalp'), ('canamid', 'canmid'),\n",
    "#               ('ogilalp', 'ogilvi'), ('tornmou', 'tornga'), ('kalste', 'kalste'), ('russarc', 'rusarc'), ('russber', 'rusbert'), ('chermou', 'cherski'),\n",
    "#               ('chukpen', 'chukchi'), ('kolapen', 'kolapen'), ('nortsib', 'nesibco'), ('nortrus', 'nwrunz'), ('scanmon', 'scambf'), ('taimsib', 'taicens'),\n",
    "#               ('tranbal', 'trzbald'), ('yamatun', 'yamalgy'), ('kamctun', 'kamtund')] # All tundra\n",
    "\n",
    "# Collect region-level data\n",
    "ba_dfs = []\n",
    "\n",
    "for region, region_model in region_mappings:\n",
    "    try:\n",
    "        # Load actual data\n",
    "        df_actual = pd.read_csv(\n",
    "            '/home/users/clelland/Model/Analysis/Fire actual 2001-2024.csv',\n",
    "            parse_dates=['date'], index_col='date'\n",
    "        )[[region]].rename(columns={region: 'Actual'})\n",
    "\n",
    "        # Load model data\n",
    "        df_model = pd.read_csv(\n",
    "            f'/home/users/clelland/Model/Analysis/Ecoregion plots combined/area_timeseries_{region_model}_all.csv',\n",
    "            parse_dates=['time'], index_col='time'\n",
    "        ).rename(columns={\n",
    "            'access 126': 'ACCESS_SSP126',\n",
    "            'access 245': 'ACCESS_SSP245',\n",
    "            'access 370': 'ACCESS_SSP370',\n",
    "            'mri 126': 'MRI_SSP126',\n",
    "            'mri 245': 'MRI_SSP245',\n",
    "            'mri 370': 'MRI_SSP370'\n",
    "        })\n",
    "\n",
    "        # Resample model data to annual\n",
    "        df_model_annual = df_model.resample('YE').sum().astype(float)\n",
    "\n",
    "        # Resample actual data to annual\n",
    "        df_actual_annual = df_actual.resample('YE').sum()\n",
    "\n",
    "        # Combine\n",
    "        df_ba = pd.concat([df_actual_annual, df_model_annual], axis=1)\n",
    "        ba_dfs.append(df_ba)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping region {region} ({region_model}) due to error: {e}\")\n",
    "\n",
    "# ---- Combine and sum across all regions ----\n",
    "df_ba_all = pd.concat(ba_dfs, axis=0).groupby(level=0).sum(min_count=1)\n",
    "df_ba_all.index = pd.to_datetime(df_ba_all.index)\n",
    "df_ba_all.sort_index(inplace=True)\n",
    "\n",
    "# ---- Compute extreme threshold from actuals (2001–2024) ----\n",
    "historic_actual = df_ba_all.loc['2001':'2024', 'Actual']\n",
    "extreme_threshold = historic_actual.quantile(0.95)\n",
    "\n",
    "# ---- Plot each model/scenario separately ----\n",
    "model_cols = [\n",
    "    'ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "    'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370'\n",
    "]\n",
    "\n",
    "for col in model_cols:\n",
    "#for col in ['ACCESS_SSP126']:\n",
    "    if col in df_ba_all.columns:\n",
    "        df_future = df_ba_all.loc['2025':, col].dropna()\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(df_future.index.year, df_future.values, label=col)\n",
    "        plt.axhline(extreme_threshold, color='red', linestyle='--', linewidth=2,\n",
    "                    label='Extreme Threshold (2001–2024 Actuals)')\n",
    "        plt.title(f'Yearly Burned Area (2025–2100) North America boreal ecoregions – {col}', fontsize=18)\n",
    "        plt.ylabel('Burned Area (Mha)', fontsize=16)\n",
    "        plt.xlabel('Year', fontsize=16)\n",
    "        plt.xticks(fontsize=16)\n",
    "        plt.yticks(fontsize=16)\n",
    "        #plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.5)\n",
    "        plt.ylim(0, 18) # 18, 27, 4.5\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save or show\n",
    "        #plt.savefig(f'/home/users/clelland/Model/Analysis/Summary stats/BA/Bar plots/ba_barplot_NAbor_{col.replace(\" \", \"_\")}.png', dpi=300)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b1484-3d71-4ba3-9ae7-05024b3a4df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = historic_actual.copy()\n",
    "quantiles = new.quantile([0.05, 0.5, 0.95])\n",
    "print(\"Min: \", new.min())\n",
    "print(quantiles)\n",
    "print(\"Max: \", new.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d196853-848a-4a64-b580-606d8abedebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_mappings  = [('alaspen', 'alapen'), ('centcan', 'cancsh'), ('cookinl', 'cookin'), ('copppla', 'copper'), ('eastcan', 'eastcf'), ('eashti', 'eashti'),\n",
    "               ('inteala', 'intlow'), ('mid-bor', 'midbor'), ('midwcan', 'midwes'), ('musklak', 'muslta'), ('nortcan', 'norths'), ('southud', 'sohudb'),\n",
    "               ('watshig', 'watson'), ('nortcor', 'norcor'), ('nortter', 'nwterr'),\n",
    "('eastsib', 'eastsib'), ('icelbor', 'icelnd'), ('kamcmea', 'kamkurm'),\n",
    "               ('kamctai', 'kamtaig'), ('nesibta', 'nesibta'), ('okhotai', 'okhman'), ('sakhisl', 'sakhtai'), ('trancon', 'trzconf'), ('westsib', 'westsib'),\n",
    "               ('scanand', 'scrusta'), ('uralmon', 'uralfor'), ('ahkland', 'ahklun'), ('berilow', 'berlow'), ('brooran', 'brookr'), ('kalanun', 'kalhar'),\n",
    "               ('pacicoa', 'pacice'), ('novoisl', 'novoisl'), ('wranisl', 'wrangel'), ('alaseli', 'aleias'), ('arctcoa', 'arccoa'), ('arctfoo', 'arcfoo'),\n",
    "               ('beriupl', 'berupl'), ('canalow', 'canlow'), ('davihig', 'davish'), ('canahig', 'canhig'), ('inteyuk', 'intalp'), ('canamid', 'canmid'),\n",
    "               ('ogilalp', 'ogilvi'), ('tornmou', 'tornga'), ('kalste', 'kalste'), ('russarc', 'rusarc'), ('russber', 'rusbert'), ('chermou', 'cherski'),\n",
    "               ('chukpen', 'chukchi'), ('kolapen', 'kolapen'), ('nortsib', 'nesibco'), ('nortrus', 'nwrunz'), ('scanmon', 'scambf'), ('taimsib', 'taicens'),\n",
    "               ('tranbal', 'trzbald'), ('yamatun', 'yamalgy'), ('kamctun', 'kamtund')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca77b6-323c-4f66-8dc3-b31fadcbf66f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#region_mappings  = [('alaspen', 'alapen'), ('centcan', 'cancsh'), ('cookinl', 'cookin'), ('copppla', 'copper'), ('eastcan', 'eastcf'), ('eashti', 'eashti'),\n",
    "#               ('inteala', 'intlow'), ('mid-bor', 'midbor'), ('midwcan', 'midwes'), ('musklak', 'muslta'), ('nortcan', 'norths'), ('southud', 'sohudb'),\n",
    "#               ('watshig', 'watson'), ('nortcor', 'norcor'), ('nortter', 'nwterr')] # N America boreal\n",
    "region_mappings  = [('eastsib', 'eastsib'), ('icelbor', 'icelnd'), ('kamcmea', 'kamkurm'),\n",
    "               ('kamctai', 'kamtaig'), ('nesibta', 'nesibta'), ('okhotai', 'okhman'), ('sakhisl', 'sakhtai'), ('trancon', 'trzconf'), ('westsib', 'westsib'),\n",
    "               ('scanand', 'scrusta'), ('uralmon', 'uralfor')] # Eurasia boreal\n",
    "#region_mappings  = [('ahkland', 'ahklun'), ('berilow', 'berlow'), ('brooran', 'brookr'), ('kalanun', 'kalhar'),\n",
    "#               ('pacicoa', 'pacice'), ('novoisl', 'novoisl'), ('wranisl', 'wrangel'), ('alaseli', 'aleias'), ('arctcoa', 'arccoa'), ('arctfoo', 'arcfoo'),\n",
    "#               ('beriupl', 'berupl'), ('canalow', 'canlow'), ('davihig', 'davish'), ('canahig', 'canhig'), ('inteyuk', 'intalp'), ('canamid', 'canmid'),\n",
    "#               ('ogilalp', 'ogilvi'), ('tornmou', 'tornga'), ('kalste', 'kalste'), ('russarc', 'rusarc'), ('russber', 'rusbert'), ('chermou', 'cherski'),\n",
    "#               ('chukpen', 'chukchi'), ('kolapen', 'kolapen'), ('nortsib', 'nesibco'), ('nortrus', 'nwrunz'), ('scanmon', 'scambf'), ('taimsib', 'taicens'),\n",
    "#               ('tranbal', 'trzbald'), ('yamatun', 'yamalgy'), ('kamctun', 'kamtund')] # All tundra\n",
    "\n",
    "# Collect region-level data\n",
    "ba_dfs = []\n",
    "\n",
    "for region, region_model in region_mappings:\n",
    "    try:\n",
    "        # Load actual data\n",
    "        df_actual = pd.read_csv(\n",
    "            '/home/users/clelland/Model/Analysis/Fire actual 2001-2024.csv',\n",
    "            parse_dates=['date'], index_col='date'\n",
    "        )[[region]].rename(columns={region: 'Actual'})\n",
    "\n",
    "        # Load model data\n",
    "        df_model = pd.read_csv(\n",
    "            f'/home/users/clelland/Model/Analysis/Ecoregion plots combined/area_timeseries_{region_model}_all.csv',\n",
    "            parse_dates=['time'], index_col='time'\n",
    "        ).rename(columns={\n",
    "            'access 126': 'ACCESS_SSP126',\n",
    "            'access 245': 'ACCESS_SSP245',\n",
    "            'access 370': 'ACCESS_SSP370',\n",
    "            'mri 126': 'MRI_SSP126',\n",
    "            'mri 245': 'MRI_SSP245',\n",
    "            'mri 370': 'MRI_SSP370'\n",
    "        })\n",
    "\n",
    "        # Resample model data to annual\n",
    "        df_model_annual = df_model.resample('YE').sum().astype(float)\n",
    "\n",
    "        # Resample actual data to annual\n",
    "        df_actual_annual = df_actual.resample('YE').sum()\n",
    "\n",
    "        # Combine\n",
    "        df_ba = pd.concat([df_actual_annual, df_model_annual], axis=1)\n",
    "        ba_dfs.append(df_ba)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping region {region} ({region_model}) due to error: {e}\")\n",
    "\n",
    "# ---- Combine and sum across all regions ----\n",
    "df_ba_all = pd.concat(ba_dfs, axis=0).groupby(level=0).sum(min_count=1)\n",
    "df_ba_all.index = pd.to_datetime(df_ba_all.index)\n",
    "df_ba_all.sort_index(inplace=True)\n",
    "\n",
    "# ---- Compute extreme threshold from actuals (2001–2024) ----\n",
    "historic_actual = df_ba_all.loc['2001':'2024', 'Actual']\n",
    "extreme_threshold = historic_actual.quantile(0.95)\n",
    "\n",
    "# Define scenario groupings\n",
    "access_scenarios = ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370']\n",
    "mri_scenarios = ['MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']\n",
    "\n",
    "# Colors for SSP scenarios\n",
    "colors = {\n",
    "    'ACCESS_SSP126': 'blue',\n",
    "    'ACCESS_SSP245': 'green',\n",
    "    'ACCESS_SSP370': 'purple',\n",
    "    'MRI_SSP126': 'orange',\n",
    "    'MRI_SSP245': 'red',\n",
    "    'MRI_SSP370': 'brown'\n",
    "}\n",
    "\n",
    "def plot_extreme_years(group_name, scenario_list):\n",
    "    # Collect extreme-year data for the group\n",
    "    extreme_data = []\n",
    "    for col in scenario_list:\n",
    "        if col in df_ba_all.columns:\n",
    "            df_future = df_ba_all.loc['2025':, col].dropna()\n",
    "            extreme_years = df_future[df_future > extreme_threshold]\n",
    "            for year, value in extreme_years.items():\n",
    "                extreme_data.append((year, value, col))\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    for year, value, scenario in extreme_data:\n",
    "        plt.bar(year.year, value, color=colors[scenario], label=scenario)\n",
    "\n",
    "    # Threshold line\n",
    "    plt.axhline(extreme_threshold, color='black', linestyle='--', linewidth=1.5,\n",
    "                label='95th Percentile (from 2001–2023)')\n",
    "\n",
    "    # Legend\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    unique_labels = dict(zip(labels, handles))\n",
    "    #plt.legend(unique_labels.values(), unique_labels.keys(), fontsize=10)\n",
    "\n",
    "    # Styling\n",
    "    plt.title(f'Extreme Years for {group_name} Scenarios in North America boreal ecoregions', fontsize=14)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.ylabel('Burned Area (Mha)', fontsize=18)\n",
    "    plt.xlabel('Year', fontsize=18)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.xlim(2024, 2103)\n",
    "    plt.ylim(0, 18) # 18, 27, 4.5 - 35 for all\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f'/home/users/clelland/Model/Analysis/Summary stats/BA/Bar plots/extreme_years_{group_name.lower()}_NAbor.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Plot each group\n",
    "plot_extreme_years(\"ACCESS\", access_scenarios)\n",
    "plot_extreme_years(\"MRI\", mri_scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0c5c16-fdf3-4ced-8617-950754b3dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find means of non-extreme years\n",
    "# Define time periods\n",
    "periods = {\n",
    "    '2025–2050': ('2025', '2050'),\n",
    "    '2051–2075': ('2051', '2075'),\n",
    "    '2076–2100': ('2076', '2100')\n",
    "}\n",
    "\n",
    "# Container for results\n",
    "mean_non_extreme = []\n",
    "\n",
    "# Loop through each model scenario\n",
    "for scenario in access_scenarios + mri_scenarios:\n",
    "    if scenario not in df_ba_all.columns:\n",
    "        continue\n",
    "\n",
    "    df_scenario = df_ba_all[[scenario]].copy()\n",
    "    df_scenario = df_scenario.loc['2025':]  # Limit to future years\n",
    "\n",
    "    # Mask out extreme years (keep only non-extreme years)\n",
    "    df_scenario = df_scenario[df_scenario[scenario] <= extreme_threshold]\n",
    "\n",
    "    # Loop through periods and compute mean\n",
    "    for label, (start, end) in periods.items():\n",
    "        df_period = df_scenario.loc[start:end]\n",
    "        mean_val = df_period[scenario].mean()\n",
    "        mean_non_extreme.append({\n",
    "            'scenario': scenario,\n",
    "            'period': label,\n",
    "            'mean_burned_area': mean_val\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_non_extreme_means = pd.DataFrame(mean_non_extreme)\n",
    "\n",
    "# Optional: Sort and save\n",
    "df_non_extreme_means.sort_values(by=['scenario', 'period'], inplace=True)\n",
    "#df_non_extreme_means.to_csv(\n",
    "#    '/home/users/clelland/Model/Analysis/Summary stats/BA/non_extreme_means_by_period.csv',\n",
    "#    index=False\n",
    "#)\n",
    "\n",
    "# Show result\n",
    "df_non_extreme_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce5dece-39de-417b-9030-3519172785a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FOR LEGEND ONLY\n",
    "region_mappings  = [('eastsib', 'eastsib'), ('icelbor', 'icelnd'), ('kamcmea', 'kamkurm'),\n",
    "               ('kamctai', 'kamtaig'), ('nesibta', 'nesibta'), ('okhotai', 'okhman'), ('sakhisl', 'sakhtai'), ('trancon', 'trzconf'), ('westsib', 'westsib'),\n",
    "               ('scanand', 'scrusta'), ('uralmon', 'uralfor')] # Eurasia boreal\n",
    "\n",
    "# Collect region-level data\n",
    "ba_dfs = []\n",
    "\n",
    "for region, region_model in region_mappings:\n",
    "    try:\n",
    "        # Load actual data\n",
    "        df_actual = pd.read_csv(\n",
    "            '/home/users/clelland/Model/Analysis/Fire actual 2001-2024.csv',\n",
    "            parse_dates=['date'], index_col='date'\n",
    "        )[[region]].rename(columns={region: 'Actual'})\n",
    "\n",
    "        # Load model data\n",
    "        df_model = pd.read_csv(\n",
    "            f'/home/users/clelland/Model/Analysis/Ecoregion plots combined/area_timeseries_{region_model}_all.csv',\n",
    "            parse_dates=['time'], index_col='time'\n",
    "        ).rename(columns={\n",
    "            'access 126': 'ACCESS_SSP126',\n",
    "            'access 245': 'ACCESS_SSP245',\n",
    "            'access 370': 'ACCESS_SSP370',\n",
    "            'mri 126': 'MRI_SSP126',\n",
    "            'mri 245': 'MRI_SSP245',\n",
    "            'mri 370': 'MRI_SSP370'\n",
    "        })\n",
    "\n",
    "        # Resample model data to annual\n",
    "        df_model_annual = df_model.resample('YE').sum().astype(float)\n",
    "\n",
    "        # Resample actual data to annual\n",
    "        df_actual_annual = df_actual.resample('YE').sum()\n",
    "\n",
    "        # Combine\n",
    "        df_ba = pd.concat([df_actual_annual, df_model_annual], axis=1)\n",
    "        ba_dfs.append(df_ba)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping region {region} ({region_model}) due to error: {e}\")\n",
    "\n",
    "# ---- Combine and sum across all regions ----\n",
    "df_ba_all = pd.concat(ba_dfs, axis=0).groupby(level=0).sum(min_count=1)\n",
    "df_ba_all.index = pd.to_datetime(df_ba_all.index)\n",
    "df_ba_all.sort_index(inplace=True)\n",
    "\n",
    "# Recompute 95th percentile threshold from 2001–2024 actual burned area\n",
    "historic_actual = df_ba_all.loc['2001':'2024', 'Actual']\n",
    "threshold_95 = historic_actual.quantile(0.95)\n",
    "\n",
    "# Model scenario columns\n",
    "model_cols = [\n",
    "    'ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "    'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370'\n",
    "]\n",
    "\n",
    "# Colors for each scenario\n",
    "colors = {\n",
    "    'ACCESS_SSP126': 'blue',\n",
    "    'ACCESS_SSP245': 'green',\n",
    "    'ACCESS_SSP370': 'purple',\n",
    "    'MRI_SSP126': 'orange',\n",
    "    'MRI_SSP245': 'red',\n",
    "    'MRI_SSP370': 'brown'\n",
    "}\n",
    "\n",
    "# Collect extreme-year bars\n",
    "extreme_data = []\n",
    "\n",
    "for col in model_cols:\n",
    "    if col in df_ba_all.columns:\n",
    "        df_future = df_ba_all.loc['2025':, col].dropna()\n",
    "        extreme_years = df_future[df_future > threshold_95]\n",
    "        for year, value in extreme_years.items():\n",
    "            extreme_data.append((year, value, col))\n",
    "\n",
    "# Create plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot each bar\n",
    "for year, value, scenario in extreme_data:\n",
    "    plt.bar(year.year, value, color=colors[scenario], label=scenario)\n",
    "\n",
    "# Add 95th percentile threshold line\n",
    "plt.axhline(threshold_95, color='black', linestyle='--', linewidth=1.5,\n",
    "            label='95th Percentile (2001–2023)')\n",
    "\n",
    "# Handle legend (remove duplicates)\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "unique_labels = dict(zip(labels, handles))\n",
    "# Remove duplicates in legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "unique_labels = dict(zip(labels, handles))\n",
    "    \n",
    "# Legend below the plot with 2 columns\n",
    "plt.legend(\n",
    "    unique_labels.values(),\n",
    "    unique_labels.keys(),\n",
    "    fontsize=10,\n",
    "    loc='upper center',\n",
    "    bbox_to_anchor=(0.5, -0.15),\n",
    "    ncol=2\n",
    ")\n",
    "# Labels and styling\n",
    "plt.title('Extreme Years (Above 95th Percentile) for Burned Area per Scenario (2025–2100)', fontsize=14)\n",
    "plt.ylabel('Burned Area (Summed Across Regions)', fontsize=12)\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show or save\n",
    "#plt.savefig('/home/users/clelland/Model/Analysis/Summary stats/BA/Bar plots/extreme_bar_legend.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff7ed7c-0638-4d15-bb05-72b364cc258a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## % Change of BA per time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc02fbc3-d5d8-46fa-b165-ac2e262d35c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# % CHANGE OF BA PER TIME PERIOD\n",
    "# Store percent change results for mapping\n",
    "change_records = []\n",
    "\n",
    "for region_actual, region_model in region_mappings:\n",
    "    actual_path = '/home/users/clelland/Model/Analysis/Fire actual 2001-2024.csv'\n",
    "    model_path = f'/home/users/clelland/Model/Analysis/Ecoregion plots combined/area_timeseries_{region_model}_all.csv'\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Missing model file for region: {region_model}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df_actual = pd.read_csv(actual_path, parse_dates=['date'], index_col='date')[region_actual]\n",
    "        df_model = pd.read_csv(model_path, parse_dates=['time'], index_col='time')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading data for {region_actual}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Monthly -> Annual\n",
    "    df_actual_annual = df_actual.resample('YE').sum()\n",
    "    df_model_annual = df_model.resample('YE').sum().astype(float)\n",
    "    \n",
    "    # Historical mean (2001–2024)\n",
    "    hist_mean = df_actual_annual['2001':'2024'].mean()\n",
    "\n",
    "    for model in models:\n",
    "        model_series = df_model_annual[model]\n",
    "\n",
    "        for period_label, (start, end) in periods.items():\n",
    "            future_mean = model_series[start:end].mean()\n",
    "            if hist_mean == 0 or future_mean == 0:\n",
    "                percent_change = 0\n",
    "            else:\n",
    "                percent_change = 100 * (future_mean - hist_mean) / hist_mean\n",
    "            change_records.append({\n",
    "                'region_model': region_model,\n",
    "                'model': model_labels[model],\n",
    "                'period': period_label,\n",
    "                'percent_change': percent_change\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame for mapping\n",
    "df_change = pd.DataFrame(change_records)\n",
    "\n",
    "# Loop over models/periods to plot maps\n",
    "for model in model_labels.values():\n",
    "#for model in ['ACCESS_SSP126']:\n",
    "    for period in periods.keys():\n",
    "    #for period in ['2025_2050']:\n",
    "        df_plot = df_change[(df_change['model'] == model) & (df_change['period'] == period)].reset_index(drop=True)\n",
    "\n",
    "        # Ensure alignment\n",
    "        if len(df_plot) != len(selected_ecoregions):\n",
    "            print(f\"Skipping {model}-{period}: mismatch in row counts\")\n",
    "            continue\n",
    "\n",
    "        selected_ecoregions['percent_change'] = df_plot['percent_change'].values\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        minx, miny, maxx, maxy = selected_ecoregions.total_bounds\n",
    "        buffer = 300000 # 300 km\n",
    "        ax.set_xlim(minx-buffer, maxx+buffer)\n",
    "        ax.set_ylim(miny-buffer, maxy+buffer)\n",
    "        \n",
    "        # Plot light blue background (ocean)\n",
    "        ax.add_patch(plt.Rectangle((minx - buffer, miny - buffer), (maxx - minx) + 2 * buffer, (maxy - miny) + 2 * buffer, \n",
    "                                   facecolor='#f0f8ff', zorder=0))\n",
    "        \n",
    "        gdf_world.plot(ax=ax, color='white', edgecolor='black', linewidth=0.1)\n",
    "\n",
    "        norm = Normalize(vmin=-100, vmax=100)\n",
    "        selected_ecoregions.plot(\n",
    "            column='percent_change',\n",
    "            cmap='coolwarm',\n",
    "            edgecolor='black',\n",
    "            linewidth=0.2,\n",
    "            norm=norm,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        # Colorbar\n",
    "        sm = plt.cm.ScalarMappable(cmap='coolwarm', norm=norm)\n",
    "        sm._A = []\n",
    "        cbar = fig.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.05, pad=0.01)\n",
    "        cbar.set_label('% Change in Burned Area')\n",
    "        #cbar.set_label('% Change in Burned Area', fontsize=18)\n",
    "        #cbar.ax.tick_params(labelsize=16) \n",
    "        \n",
    "        plt.title(f'Burned Area % Change - {model} ({period})', fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        out_path = f'/home/users/clelland/Model/Analysis/Summary stats/BA/Percent change/ba_percent_change_{model}_{period}.png'\n",
    "        #out_path = '/home/users/clelland/Model/Analysis/Summary stats/BA/Percent change/ba_percent_change_legend.png'\n",
    "        plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb9210-b790-40ad-93b9-61bf8f6b0873",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = df_change.copy()\n",
    "quantiles = new['percent_change'].quantile([0.05, 0.5, 0.95])\n",
    "print(\"Min: \", new['percent_change'].min())\n",
    "print(quantiles)\n",
    "print(\"Max: \", new['percent_change'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e114f7-56da-4498-8e4e-67ff4790671f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Raw change of BA per time period in Mha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a428f2fc-b18f-4afe-9f89-3ddbe3aef4aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RAW CHANGE OF BA PER TIME PERIOD IN MHA\n",
    "# Store percent change results for mapping\n",
    "change_records = []\n",
    "\n",
    "for region_actual, region_model in region_mappings:\n",
    "    actual_path = '/home/users/clelland/Model/Analysis/Fire actual 2001-2024.csv'\n",
    "    model_path = f'/home/users/clelland/Model/Analysis/Ecoregion plots combined/area_timeseries_{region_model}_all.csv'\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Missing model file for region: {region_model}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df_actual = pd.read_csv(actual_path, parse_dates=['date'], index_col='date')[region_actual]\n",
    "        df_model = pd.read_csv(model_path, parse_dates=['time'], index_col='time')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading data for {region_actual}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Monthly -> Annual\n",
    "    df_actual_annual = df_actual.resample('YE').sum()\n",
    "    df_model_annual = df_model.resample('YE').sum().astype(float)\n",
    "    \n",
    "    # Historical mean (2001–2024)\n",
    "    hist_mean = df_actual_annual['2001':'2024'].mean()\n",
    "\n",
    "    for model in models:\n",
    "        model_series = df_model_annual[model]\n",
    "\n",
    "        for period_label, (start, end) in periods.items():\n",
    "            future_mean = model_series[start:end].mean()\n",
    "            raw_change = (future_mean - hist_mean)\n",
    "            change_records.append({\n",
    "                'region_model': region_model,\n",
    "                'model': model_labels[model],\n",
    "                'period': period_label,\n",
    "                'raw_change_mha': raw_change\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame for mapping\n",
    "df_change = pd.DataFrame(change_records)\n",
    "\n",
    "# Loop over models/periods to plot maps\n",
    "#for model in model_labels.values():\n",
    "for model in ['ACCESS_SSP370']:\n",
    "    for period in periods.keys():\n",
    "        df_plot = df_change[(df_change['model'] == model) & (df_change['period'] == period)].reset_index(drop=True)\n",
    "\n",
    "        # Ensure alignment\n",
    "        if len(df_plot) != len(selected_ecoregions):\n",
    "            print(f\"Skipping {model}-{period}: mismatch in row counts\")\n",
    "            continue\n",
    "\n",
    "        selected_ecoregions['raw_change_mha'] = df_plot['raw_change_mha'].values\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        minx, miny, maxx, maxy = selected_ecoregions.total_bounds\n",
    "        buffer = 300000 # 300 km\n",
    "        ax.set_xlim(minx-buffer, maxx+buffer)\n",
    "        ax.set_ylim(miny-buffer, maxy+buffer)\n",
    "        \n",
    "        # Plot light blue background (ocean)\n",
    "        ax.add_patch(plt.Rectangle((minx - buffer, miny - buffer), (maxx - minx) + 2 * buffer, (maxy - miny) + 2 * buffer, \n",
    "                                   facecolor='#f8fcff', zorder=0))\n",
    "        \n",
    "        gdf_world.plot(ax=ax, color='white', edgecolor='black', linewidth=0.1)\n",
    "\n",
    "        norm = Normalize(vmin=-1, vmax=1)\n",
    "        selected_ecoregions.plot(\n",
    "            column='raw_change_mha',\n",
    "            cmap='coolwarm',\n",
    "            edgecolor='black',\n",
    "            linewidth=0.2,\n",
    "            norm=norm,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        # Colorbar\n",
    "        sm = plt.cm.ScalarMappable(cmap='coolwarm', norm=norm)\n",
    "        sm._A = []\n",
    "        cbar = fig.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.05, pad=0.01)\n",
    "        cbar.set_label('Change in Mean Burned Area (Mha)')\n",
    "              \n",
    "        plt.title(f'Burned Area Change (Mha) - {model} ({period})', fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        out_path = f'/home/users/clelland/Model/Analysis/Summary stats/BA/ba_change_mha_{model}_{period}.png'\n",
    "        #plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208d4782-7a63-44b5-9a5f-642327e08ede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grouped ecoregions\n",
    "nabor  = [('alaspen', 'alapen'), ('centcan', 'cancsh'), ('cookinl', 'cookin'), ('copppla', 'copper'), ('eastcan', 'eastcf'), ('eashti', 'eashti'),\n",
    "               ('inteala', 'intlow'), ('mid-bor', 'midbor'), ('midwcan', 'midwes'), ('musklak', 'muslta'), ('nortcan', 'norths'), ('southud', 'sohudb'),\n",
    "               ('watshig', 'watson'), ('nortcor', 'norcor'), ('nortter', 'nwterr')]\n",
    "eubor  = [('eastsib', 'eastsib'), ('icelbor', 'icelnd'), ('kamcmea', 'kamkurm'),\n",
    "               ('kamctai', 'kamtaig'), ('nesibta', 'nesibta'), ('okhotai', 'okhman'), ('sakhisl', 'sakhtai'), ('trancon', 'trzconf'), ('westsib', 'westsib'),\n",
    "               ('scanand', 'scrusta'), ('uralmon', 'uralfor')]\n",
    "tundra  = [('ahkland', 'ahklun'), ('berilow', 'berlow'), ('brooran', 'brookr'), ('kalanun', 'kalhar'),\n",
    "               ('pacicoa', 'pacice'), ('novoisl', 'novoisl'), ('wranisl', 'wrangel'), ('alaseli', 'aleias'), ('arctcoa', 'arccoa'), ('arctfoo', 'arcfoo'),\n",
    "               ('beriupl', 'berupl'), ('canalow', 'canlow'), ('davihig', 'davish'), ('canahig', 'canhig'), ('inteyuk', 'intalp'), ('canamid', 'canmid'),\n",
    "               ('ogilalp', 'ogilvi'), ('tornmou', 'tornga'), ('kalste', 'kalste'), ('russarc', 'rusarc'), ('russber', 'rusbert'), ('chermou', 'cherski'),\n",
    "               ('chukpen', 'chukchi'), ('kolapen', 'kolapen'), ('nortsib', 'nesibco'), ('nortrus', 'nwrunz'), ('scanmon', 'scambf'), ('taimsib', 'taicens'),\n",
    "               ('tranbal', 'trzbald'), ('yamatun', 'yamalgy'), ('kamctun', 'kamtund')]\n",
    "\n",
    "# Combine all groups\n",
    "all_groups = [('nabor', nabor), ('eubor', eubor), ('tundra', tundra)]\n",
    "\n",
    "# Mapping observed name → group\n",
    "observed_to_group = {obs: grp for grp, pairs in all_groups for obs, _ in pairs}\n",
    "\n",
    "df_actual_all = pd.read_csv(actual_path, parse_dates=['date'], index_col='date')\n",
    "mean_actual = df_actual_all.resample('YE').sum().mean()\n",
    "\n",
    "# --- Step 1: Process mean_actual\n",
    "# Convert Series to DataFrame\n",
    "mean_actual_df = mean_actual.reset_index()\n",
    "mean_actual_df.columns = ['observed_name', 'sum_actual_mha']\n",
    "\n",
    "# Map observed_name to group\n",
    "mean_actual_df['group'] = mean_actual_df['observed_name'].map(observed_to_group)\n",
    "\n",
    "# Group by group to get average mean_actual_mha\n",
    "grouped_actual = mean_actual_df.groupby('group')['sum_actual_mha'].sum().reset_index()\n",
    "\n",
    "# --- Step 2: Process df_change (future data)\n",
    "# Mapping future name → group\n",
    "future_to_group = {fut: grp for grp, pairs in all_groups for _, fut in pairs}\n",
    "\n",
    "# Assign group\n",
    "df_change['group'] = df_change['region_model'].map(future_to_group)\n",
    "\n",
    "# Group future change by group, model, and period\n",
    "grouped_means = df_change.groupby(['group', 'model', 'period'])['raw_change_mha'].sum().reset_index()\n",
    "\n",
    "# --- Step 3: Merge historical mean into future data\n",
    "final_df = grouped_means.merge(grouped_actual, on='group', how='left')\n",
    "final_df['pct_change'] = final_df['raw_change_mha'] / final_df['sum_actual_mha'] * 100\n",
    "final_df['final_tot'] = final_df['raw_change_mha'] + final_df['sum_actual_mha']\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc5b45c-b200-45f7-8a74-c2ea86481a12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Individual ecoregions\n",
    "region_mappings  = [('alaspen', 'alapen'), ('centcan', 'cancsh'), ('cookinl', 'cookin'), ('copppla', 'copper'), ('eastcan', 'eastcf'), ('eashti', 'eashti'),\n",
    "               ('inteala', 'intlow'), ('mid-bor', 'midbor'), ('midwcan', 'midwes'), ('musklak', 'muslta'), ('nortcan', 'norths'), ('southud', 'sohudb'),\n",
    "               ('watshig', 'watson'), ('nortcor', 'norcor'), ('nortter', 'nwterr'), ('eastsib', 'eastsib'), ('icelbor', 'icelnd'), ('kamcmea', 'kamkurm'),\n",
    "               ('kamctai', 'kamtaig'), ('nesibta', 'nesibta'), ('okhotai', 'okhman'), ('sakhisl', 'sakhtai'), ('trancon', 'trzconf'), ('westsib', 'westsib'),\n",
    "               ('scanand', 'scrusta'), ('uralmon', 'uralfor'), ('ahkland', 'ahklun'), ('berilow', 'berlow'), ('brooran', 'brookr'), ('kalanun', 'kalhar'),\n",
    "               ('pacicoa', 'pacice'), ('novoisl', 'novoisl'), ('wranisl', 'wrangel'), ('alaseli', 'aleias'), ('arctcoa', 'arccoa'), ('arctfoo', 'arcfoo'),\n",
    "               ('beriupl', 'berupl'), ('canalow', 'canlow'), ('davihig', 'davish'), ('canahig', 'canhig'), ('inteyuk', 'intalp'), ('canamid', 'canmid'),\n",
    "               ('ogilalp', 'ogilvi'), ('tornmou', 'tornga'), ('kalste', 'kalste'), ('russarc', 'rusarc'), ('russber', 'rusbert'), ('chermou', 'cherski'),\n",
    "               ('chukpen', 'chukchi'), ('kolapen', 'kolapen'), ('nortsib', 'nesibco'), ('nortrus', 'nwrunz'), ('scanmon', 'scambf'), ('taimsib', 'taicens'),\n",
    "               ('tranbal', 'trzbald'), ('yamatun', 'yamalgy'), ('kamctun', 'kamtund')]\n",
    "\n",
    "# Create future → observed name mapping\n",
    "future_to_observed = {future: observed for observed, future in region_mappings}\n",
    "\n",
    "# Assign observed_name to df_change\n",
    "df_change['observed_name'] = df_change['region_model'].map(future_to_observed)\n",
    "\n",
    "# Convert mean_actual to DataFrame\n",
    "mean_actual_df = mean_actual.reset_index()\n",
    "mean_actual_df.columns = ['observed_name', 'sum_actual_mha']\n",
    "\n",
    "# Merge individual ecoregion change data with historical means\n",
    "df_ecoregion_change = df_change.merge(mean_actual_df, on='observed_name', how='left')\n",
    "\n",
    "# Compute percent change per ecoregion/model/period\n",
    "df_ecoregion_change['pct_change'] = (\n",
    "    df_ecoregion_change['raw_change_mha'] / df_ecoregion_change['sum_actual_mha'] * 100\n",
    ")\n",
    "df_ecoregion_change.loc[\n",
    "    (df_ecoregion_change['sum_actual_mha'] == 0) & \n",
    "    (df_ecoregion_change['raw_change_mha'] != 0),\n",
    "    'pct_change'\n",
    "] = 100\n",
    "\n",
    "# Keep only relevant columns\n",
    "result = df_ecoregion_change[['region_model', 'model', 'period', 'raw_change_mha', 'sum_actual_mha', 'pct_change', 'group']]\n",
    "result['final_tot'] = result['raw_change_mha'] + result['sum_actual_mha']\n",
    "#result\n",
    "\n",
    "result[result['region_model'] == 'westsib']\n",
    "#result[(result['model'] == 'MRI_SSP126') & (result['period'] == '2076_2100')].sort_values(by='pct_change', ascending=False)\n",
    "#result[(result['group'] == 'nabor') & (result['model'] == 'ACCESS_SSP370') & (result['period'] == '2076_2100')].sort_values(by='pct_change', ascending=False)\n",
    "\n",
    "# Use those indices to extract full rows\n",
    "#idx_max = result.groupby(['period', 'model'])['pct_change'].idxmax()\n",
    "#max_per_group = result.loc[idx_max].reset_index(drop=True)\n",
    "#max_per_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818f62cf-7c84-46df-9de8-0415f816b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_summary = result.groupby(['model', 'period'])[['raw_change_mha', 'sum_actual_mha']].sum().reset_index()\n",
    "\n",
    "# Compute total percent change\n",
    "total_summary['total_pct_change'] = (\n",
    "    total_summary['raw_change_mha'] / total_summary['sum_actual_mha'] * 100\n",
    ")\n",
    "total_summary['final_tot'] = total_summary['raw_change_mha'] + total_summary['sum_actual_mha']\n",
    "\n",
    "total_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a1048a-8fa4-4de8-a147-62d5d9f6561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = df_change.copy()\n",
    "quantiles = new['raw_change_mha'].quantile([0.05, 0.5, 0.95])\n",
    "print(\"Min: \", new['raw_change_mha'].min())\n",
    "print(quantiles)\n",
    "print(\"Max: \", new['raw_change_mha'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aed012-9b2b-4e1c-9a84-f949cf3b0d34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Calculate FRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45f10be-6c57-45f3-85cf-4c70d4f8fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load region areas (Mha)\n",
    "df_ecoarea = pd.read_csv('/home/users/clelland/Model/Analysis/ecoregion_area.csv')\n",
    "area_dict = dict(zip(df_ecoarea['short_name'], df_ecoarea['area_Mha']))\n",
    "\n",
    "# Store FRI results\n",
    "fri_records = []\n",
    "\n",
    "for region_actual, region_model in region_mappings:\n",
    "    actual_path = '/home/users/clelland/Model/Analysis/Fire actual 2001-2024.csv'\n",
    "    model_path = f'/home/users/clelland/Model/Analysis/Ecoregion plots combined/area_timeseries_{region_model}_all.csv'\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Missing model file for region: {region_model}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df_actual = pd.read_csv(actual_path, parse_dates=['date'], index_col='date')[region_actual]\n",
    "        df_model = pd.read_csv(model_path, parse_dates=['time'], index_col='time')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading data for {region_actual}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Monthly -> Annual BA (Mha)\n",
    "    df_actual_annual = df_actual.resample('YE').sum()\n",
    "    df_model_annual = df_model.resample('YE').sum().astype(float)\n",
    "    \n",
    "    # Get region area in Mha\n",
    "    area_Mha = area_dict.get(region_actual)\n",
    "    if area_Mha is None:\n",
    "        print(f\"Missing area for region: {region_actual}\")\n",
    "        continue\n",
    "\n",
    "    # Compute mean FBA and FRI for historical (actual)\n",
    "    hist_mean_fba = df_actual_annual['2001':'2024'].mean() / area_Mha\n",
    "    hist_fri = 1 / hist_mean_fba if hist_mean_fba > 0 else float('inf')\n",
    "\n",
    "    fri_records.append({\n",
    "        'region': region_actual,\n",
    "        'model': 'Observed',\n",
    "        'period': '2001–2024',\n",
    "        'mean_fba': hist_mean_fba,\n",
    "        'fri': hist_fri\n",
    "    })\n",
    "\n",
    "    for model in models:\n",
    "        model_series = df_model_annual[model]\n",
    "\n",
    "        for period_label, (start, end) in periods.items():\n",
    "            mean_ba = model_series[start:end].mean()\n",
    "            mean_fba = mean_ba / area_Mha\n",
    "            fri = 1 / mean_fba if mean_fba > 0 else float('inf')\n",
    "\n",
    "            fri_records.append({\n",
    "                'region': region_actual,\n",
    "                'model': model_labels[model],\n",
    "                'period': period_label,\n",
    "                'mean_fba': mean_fba,\n",
    "                'fri': fri\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_fri = pd.DataFrame(fri_records)\n",
    "\n",
    "# Define FRI bins and labels\n",
    "bins = [0, 100, 200, 300, 400, 500, 600, float('inf')]\n",
    "labels = ['<100', '100–200', '200–300', '300–400', '400–500', '500–600', '600+']\n",
    "\n",
    "# Add 'fri_grouped' column\n",
    "df_fri['fri_grouped'] = pd.cut(df_fri['fri'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Optional: Save\n",
    "#df_fri.to_csv('/home/users/clelland/Model/Analysis/fri_by_ecoregion.csv', index=False)\n",
    "df_fri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc4ed5-144a-42b0-a1ff-3400ba7445bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## FRI - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a718d-3169-45ff-9665-970374971de5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_fri = pd.read_csv('/home/users/clelland/Model/Analysis/fri_by_ecoregion.csv')\n",
    "\n",
    "# Map fri values to selected_ecoregions\n",
    "selected_ecoregions['region'] = [pair[0] for pair in region_mappings]\n",
    "\n",
    "# Set categorical ordering for fri_grouped\n",
    "fri_labels = ['<100', '100–200', '200–300', '300–400', '400–500', '500–600', '600+']\n",
    "fri_labels_cat = pd.CategoricalDtype(categories=fri_labels, ordered=True)\n",
    "\n",
    "# Plotting loop\n",
    "#for model in model_labels.values():\n",
    "for model in ['ACCESS_SSP126']:\n",
    "    for period in periods.keys():\n",
    "        \n",
    "        # Filter for observed model and period only\n",
    "        df_fri_sel = df_fri[(df_fri['model'] == model) & (df_fri['period'] == period)][['region', 'fri_grouped']].copy()\n",
    "        df_fri_sel['fri_grouped'] = df_fri_sel['fri_grouped'].astype(fri_labels_cat)\n",
    "        df_fri_sel['fri_grouped_int'] = df_fri_sel['fri_grouped'].cat.codes\n",
    "        selected_ecoregions_merged = selected_ecoregions.merge(df_fri_sel, on='region', how='left')\n",
    "       \n",
    "        # Define colormap\n",
    "        cmap = plt.get_cmap('coolwarm', len(fri_labels)).reversed()\n",
    "        \n",
    "        # Plotting\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        minx, miny, maxx, maxy = selected_ecoregions.total_bounds\n",
    "        buffer = 300000\n",
    "        ax.set_xlim(minx - buffer, maxx + buffer)\n",
    "        ax.set_ylim(miny - buffer, maxy + buffer)\n",
    "        \n",
    "        # Light background\n",
    "        ax.add_patch(plt.Rectangle((minx - buffer, miny - buffer),\n",
    "                                   (maxx - minx) + 2 * buffer, (maxy - miny) + 2 * buffer,\n",
    "                                   facecolor='#f8fcff', zorder=0))\n",
    "        \n",
    "        # Background map\n",
    "        gdf_world.plot(ax=ax, color='white', edgecolor='black', linewidth=0.1)\n",
    "        \n",
    "        # Drop rows with NaN in fri_grouped before plotting\n",
    "        selected_ecoregions_plot = selected_ecoregions_merged.dropna(subset=['fri_grouped'])\n",
    "\n",
    "        # Plot FRI categories\n",
    "        selected_ecoregions_plot.plot(\n",
    "            column='fri_grouped_int',\n",
    "            cmap=cmap,\n",
    "            edgecolor='black',\n",
    "            linewidth=0.2,\n",
    "            ax=ax,\n",
    "            categorical=True,\n",
    "            legend=False\n",
    "        )\n",
    "        \n",
    "        # Colorbar\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=Normalize(vmin=0, vmax=len(fri_labels)))\n",
    "        sm._A = []\n",
    "        cbar = fig.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.05, pad=0.01,\n",
    "                            ticks=np.arange(len(fri_labels)) + 0.5)\n",
    "        cbar.ax.set_xticklabels(fri_labels)\n",
    "        cbar.set_label('Fire Return Interval (Years)')\n",
    "        \n",
    "        plt.title(f'Mean Fire Return Interval - {model} ({period})', fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save or show\n",
    "        out_path = f'/home/users/clelland/Model/Analysis/Summary stats/BA/FRI/ba_fri_{model}_{period}.png'\n",
    "        #plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb48bc2-9762-481f-a416-51ac17650b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = df_fri.copy()\n",
    "quantiles = new['fri'].quantile([0.05, 0.5, 0.95])\n",
    "print(\"Min: \", new['fri'].min())\n",
    "print(quantiles)\n",
    "print(\"Max: \", new['fri'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49583540-1779-47da-a5fa-37755c320d0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## FRI - Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812e550-f674-4478-9d1e-4576f6754210",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_fri = pd.read_csv('/home/users/clelland/Model/Analysis/fri_by_ecoregion.csv')\n",
    "\n",
    "# Filter for observed model only\n",
    "df_fri_obs = df_fri[df_fri['model'] == 'Observed'][['region', 'fri', 'fri_grouped']]\n",
    "\n",
    "# Map fri values to selected_ecoregions\n",
    "selected_ecoregions['region'] = [pair[0] for pair in region_mappings]\n",
    "selected_ecoregions = selected_ecoregions.merge(df_fri_obs, on='region', how='left')\n",
    "\n",
    "# Set categorical ordering for fri_grouped\n",
    "fri_labels = ['<100', '100–200', '200–300', '300–400', '400–500', '500–600', '600+']\n",
    "selected_ecoregions['fri_grouped'] = pd.Categorical(selected_ecoregions['fri_grouped'], categories=fri_labels, ordered=True)\n",
    "selected_ecoregions['fri_grouped_int'] = selected_ecoregions['fri_grouped'].cat.codes\n",
    "\n",
    "# Define colormap\n",
    "cmap = plt.get_cmap('coolwarm', len(fri_labels)).reversed()\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "minx, miny, maxx, maxy = selected_ecoregions.total_bounds\n",
    "buffer = 300000\n",
    "ax.set_xlim(minx - buffer, maxx + buffer)\n",
    "ax.set_ylim(miny - buffer, maxy + buffer)\n",
    "\n",
    "# Light background\n",
    "ax.add_patch(plt.Rectangle((minx - buffer, miny - buffer),\n",
    "                           (maxx - minx) + 2 * buffer, (maxy - miny) + 2 * buffer,\n",
    "                           facecolor='#f8fcff', zorder=0))\n",
    "\n",
    "# Background map\n",
    "gdf_world.plot(ax=ax, color='white', edgecolor='black', linewidth=0.1)\n",
    "\n",
    "# Drop rows with NaN in fri_grouped before plotting\n",
    "selected_ecoregions_plot = selected_ecoregions.dropna(subset=['fri_grouped'])\n",
    "\n",
    "# Plot FRI categories\n",
    "selected_ecoregions_plot.plot(\n",
    "    column='fri_grouped_int',\n",
    "    cmap=cmap,\n",
    "    edgecolor='black',\n",
    "    linewidth=0.2,\n",
    "    ax=ax,\n",
    "    categorical=True,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "# Colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=Normalize(vmin=0, vmax=len(fri_labels)))\n",
    "sm._A = []\n",
    "cbar = fig.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.05, pad=0.01,\n",
    "                    ticks=np.arange(len(fri_labels)) + 0.5)\n",
    "cbar.ax.set_xticklabels(fri_labels)\n",
    "cbar.set_label('Fire Return Interval (Years)')\n",
    "\n",
    "plt.title('Mean Fire Return Interval (FRI) - Observed (2001–2024)', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save or show\n",
    "out_path = '/home/users/clelland/Model/Analysis/Summary stats/BA/ba_fri_actual.png'\n",
    "plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e279921b-1159-457a-9991-74275ed5be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = selected_ecoregions_plot.copy()\n",
    "quantiles = new['fri'].quantile([0.05, 0.5, 0.95])\n",
    "print(\"Min: \", new['fri'].min())\n",
    "print(quantiles)\n",
    "print(\"Max: \", new['fri'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae43339-c500-4d23-b127-768e8bd97164",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## FRI - Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20203e0a-7ff0-44ae-922e-7bad637ba223",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DISCRETE\n",
    "df_fri = pd.read_csv('/home/users/clelland/Model/Analysis/fri_by_ecoregion.csv')\n",
    "# Categorical FRI labels and codes\n",
    "fri_labels = ['<100', '100–200', '200–300', '300–400', '400–500', '500–600', '600+']\n",
    "fri_labels_cat = pd.CategoricalDtype(categories=fri_labels, ordered=True)\n",
    "\n",
    "# Observed FRI mapping\n",
    "df_fri_obs = df_fri[df_fri['model'] == 'Observed'][['region', 'fri_grouped']]\n",
    "df_fri_obs['fri_grouped'] = pd.Categorical(df_fri_obs['fri_grouped'], categories=fri_labels, ordered=True)\n",
    "df_fri_obs['fri_grouped_int'] = df_fri_obs['fri_grouped'].cat.codes\n",
    "\n",
    "# Add region column to geometry\n",
    "selected_ecoregions['region'] = [pair[0] for pair in region_mappings]\n",
    "\n",
    "# Loop over future scenarios and periods\n",
    "#for model in model_labels.values():\n",
    "for model in ['ACCESS_SSP126']:\n",
    "    for period in periods.keys():\n",
    "        # Filter projected data\n",
    "        df_fri_sel = df_fri[(df_fri['model'] == model) & (df_fri['period'] == period)][['region', 'fri_grouped']].copy()\n",
    "        df_fri_sel['fri_grouped'] = pd.Categorical(df_fri_sel['fri_grouped'], categories=fri_labels, ordered=True)\n",
    "        df_fri_sel['fri_grouped_int'] = df_fri_sel['fri_grouped'].cat.codes\n",
    "\n",
    "        # Merge observed and projected with an outer join to catch NaNs\n",
    "        df_diff = df_fri_sel.merge(df_fri_obs, on='region', how='left', suffixes=('_proj', '_obs'))\n",
    "        \n",
    "        # Assign category difference\n",
    "        def compute_diff(row):\n",
    "            if pd.isna(row['fri_grouped_obs']) and not pd.isna(row['fri_grouped_proj']):\n",
    "                return -1\n",
    "            elif not pd.isna(row['fri_grouped_obs']) and pd.isna(row['fri_grouped_proj']):\n",
    "                return 1\n",
    "            elif not pd.isna(row['fri_grouped_int_proj']) and not pd.isna(row['fri_grouped_int_obs']):\n",
    "                return row['fri_grouped_int_proj'] - row['fri_grouped_int_obs']\n",
    "            else:\n",
    "                return np.nan\n",
    "        \n",
    "        df_diff['diff_cat'] = df_diff.apply(compute_diff, axis=1)\n",
    "\n",
    "        # Merge into geodataframe\n",
    "        gdf_diff = selected_ecoregions.merge(df_diff[['region', 'diff_cat']], on='region', how='left')\n",
    "\n",
    "        # Plotting\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        minx, miny, maxx, maxy = gdf_diff.total_bounds\n",
    "        buffer = 300000\n",
    "        ax.set_xlim(minx - buffer, maxx + buffer)\n",
    "        ax.set_ylim(miny - buffer, maxy + buffer)\n",
    "\n",
    "        # Background\n",
    "        ax.add_patch(plt.Rectangle((minx - buffer, miny - buffer),\n",
    "                                   (maxx - minx) + 2 * buffer, (maxy - miny) + 2 * buffer,\n",
    "                                   facecolor='#f8fcff', zorder=0))\n",
    "        gdf_world.plot(ax=ax, color='white', edgecolor='black', linewidth=0.1)\n",
    "\n",
    "        # Drop NaNs\n",
    "        gdf_diff_plot = gdf_diff.dropna(subset=['diff_cat'])\n",
    "\n",
    "        # Colormap (diverging for ± values)\n",
    "        bounds = np.arange(-6.5, 7.5, 1)  # This creates 14 boundaries, which makes 13 bins\n",
    "        cmap = plt.get_cmap('coolwarm', 13).reversed()\n",
    "        norm = BoundaryNorm(boundaries=bounds, ncolors=cmap.N)\n",
    "\n",
    "        gdf_diff_plot.plot(\n",
    "            column='diff_cat',\n",
    "            cmap=cmap,\n",
    "            norm=norm,\n",
    "            edgecolor='black',\n",
    "            linewidth=0.2,\n",
    "            ax=ax,\n",
    "            legend=False\n",
    "        )\n",
    "\n",
    "        # Colorbar\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm._A = []\n",
    "        cbar = fig.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.05, pad=0.01, ticks=np.arange(-6, 7, 1))\n",
    "        cbar.set_label('Change in FRI Category (Projected - Observed)', fontsize=11)\n",
    "\n",
    "        # Title and save\n",
    "        plt.title(f'FRI Category Change - {model} ({period})', fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        out_path = f'/home/users/clelland/Model/Analysis/Summary stats/BA/FRI/Change/ba_fri_change_{model}_{period}.png'\n",
    "        #plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b0850-448d-4040-95f9-55468b06ced8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CONTINUOUS\n",
    "# Load data\n",
    "df_fri = pd.read_csv('/home/users/clelland/Model/Analysis/fri_by_ecoregion.csv')\n",
    "\n",
    "# Observed FRI (assumes numeric FRI value is in a column named 'fri')\n",
    "df_fri_obs = df_fri[df_fri['model'] == 'Observed'][['region', 'fri']].rename(columns={'fri': 'fri_obs'})\n",
    "\n",
    "# Add region column to geometry\n",
    "selected_ecoregions['region'] = [pair[0] for pair in region_mappings]\n",
    "\n",
    "# Loop over future scenarios and periods\n",
    "for model in model_labels.values():\n",
    "#for model in ['ACCESS_SSP126']:\n",
    "    for period in periods.keys():\n",
    "        # Select projected FRI data\n",
    "        df_fri_sel = df_fri[(df_fri['model'] == model) & (df_fri['period'] == period)][['region', 'fri']].copy()\n",
    "        df_fri_sel.rename(columns={'fri': 'fri_proj'}, inplace=True)\n",
    "\n",
    "        # Merge observed and projected\n",
    "        df_diff = df_fri_sel.merge(df_fri_obs, on='region', how='left')\n",
    "\n",
    "        # Calculate continuous difference\n",
    "        df_diff['diff_fri'] = df_diff['fri_proj'] - df_diff['fri_obs']\n",
    "\n",
    "        # Merge into geodataframe\n",
    "        gdf_diff = selected_ecoregions.merge(df_diff[['region', 'diff_fri']], on='region', how='left')\n",
    "\n",
    "        # Plotting\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        minx, miny, maxx, maxy = gdf_diff.total_bounds\n",
    "        buffer = 300000\n",
    "        ax.set_xlim(minx - buffer, maxx + buffer)\n",
    "        ax.set_ylim(miny - buffer, maxy + buffer)\n",
    "\n",
    "        # Background\n",
    "        ax.add_patch(plt.Rectangle((minx - buffer, miny - buffer),\n",
    "                                   (maxx - minx) + 2 * buffer, (maxy - miny) + 2 * buffer,\n",
    "                                   facecolor='#f8fcff', zorder=0))\n",
    "        gdf_world.plot(ax=ax, color='white', edgecolor='black', linewidth=0.1)\n",
    "\n",
    "        # Drop NaNs\n",
    "        gdf_diff_plot = gdf_diff.dropna(subset=['diff_fri'])\n",
    "\n",
    "        # Continuous colormap: -600 to +600\n",
    "        vmin, vmax = -600, 600\n",
    "        norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "        cmap = plt.get_cmap('coolwarm').reversed()\n",
    "\n",
    "        gdf_diff_plot.plot(\n",
    "            column='diff_fri',\n",
    "            cmap=cmap,\n",
    "            norm=norm,\n",
    "            edgecolor='black',\n",
    "            linewidth=0.2,\n",
    "            ax=ax,\n",
    "            legend=False\n",
    "        )\n",
    "\n",
    "        # Colorbar\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm._A = []\n",
    "        cbar = fig.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.05, pad=0.01)\n",
    "        cbar.set_label('Change in FRI (Years)', fontsize=11)\n",
    "\n",
    "        # Title and save\n",
    "        plt.title(f'FRI Change (Years) - {model} ({period})', fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        out_path = f'/home/users/clelland/Model/Analysis/Summary stats/BA/FRI/Change/ba_fri_change_{model}_{period}_continuous.png'\n",
    "        #plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601caede-727b-4592-8d66-65885c18c7ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CONTINUOUS - log transformed\n",
    "# Load data\n",
    "df_fri = pd.read_csv('/home/users/clelland/Model/Analysis/fri_by_ecoregion.csv')\n",
    "\n",
    "# Observed FRI (assumes numeric FRI value is in a column named 'fri')\n",
    "df_fri_obs = df_fri[df_fri['model'] == 'Observed'][['region', 'fri']].rename(columns={'fri': 'fri_obs'})\n",
    "\n",
    "# Add region column to geometry\n",
    "selected_ecoregions['region'] = [pair[0] for pair in region_mappings]\n",
    "\n",
    "# Loop over future scenarios and periods\n",
    "#for model in model_labels.values():\n",
    "for model in ['ACCESS_SSP126']:\n",
    "    for period in periods.keys():\n",
    "        # Select projected FRI data\n",
    "        df_fri_sel = df_fri[(df_fri['model'] == model) & (df_fri['period'] == period)][['region', 'fri']].copy()\n",
    "        df_fri_sel.rename(columns={'fri': 'fri_proj'}, inplace=True)\n",
    "\n",
    "        # Merge observed and projected\n",
    "        df_diff = df_fri_sel.merge(df_fri_obs, on='region', how='left')\n",
    "\n",
    "        # Calculate continuous difference\n",
    "        df_diff['diff_fri'] = df_diff['fri_proj'] - df_diff['fri_obs']\n",
    "\n",
    "        # Log-transform while preserving sign\n",
    "        def signed_log_transform(x):\n",
    "            if pd.isna(x):\n",
    "                return np.nan\n",
    "            return np.sign(x) * np.log10(1 + abs(x))\n",
    "\n",
    "        df_diff['diff_fri_log'] = df_diff['diff_fri'].apply(signed_log_transform)\n",
    "\n",
    "        # Merge into geodataframe\n",
    "        gdf_diff = selected_ecoregions.merge(df_diff[['region', 'diff_fri_log']], on='region', how='left')\n",
    "\n",
    "        # Plotting\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        minx, miny, maxx, maxy = gdf_diff.total_bounds\n",
    "        buffer = 300000\n",
    "        ax.set_xlim(minx - buffer, maxx + buffer)\n",
    "        ax.set_ylim(miny - buffer, maxy + buffer)\n",
    "\n",
    "        # Background\n",
    "        ax.add_patch(plt.Rectangle((minx - buffer, miny - buffer),\n",
    "                                   (maxx - minx) + 2 * buffer, (maxy - miny) + 2 * buffer,\n",
    "                                   facecolor='#f8fcff', zorder=0))\n",
    "        gdf_world.plot(ax=ax, color='white', edgecolor='black', linewidth=0.1)\n",
    "\n",
    "        # Drop NaNs\n",
    "        gdf_diff_plot = gdf_diff.dropna(subset=['diff_fri_log'])\n",
    "\n",
    "        # Continuous colormap: -6 to +6\n",
    "        vmin, vmax = -6, 6\n",
    "        norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "        cmap = plt.get_cmap('coolwarm').reversed()\n",
    "\n",
    "        gdf_diff_plot.plot(\n",
    "            column='diff_fri_log',\n",
    "            cmap=cmap,\n",
    "            norm=norm,\n",
    "            edgecolor='black',\n",
    "            linewidth=0.2,\n",
    "            ax=ax,\n",
    "            legend=False\n",
    "        )\n",
    "\n",
    "        # Colorbar\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm._A = []\n",
    "        cbar = fig.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.05, pad=0.01)\n",
    "        cbar.set_label('Log Change in FRI', fontsize=11)\n",
    "\n",
    "        # Title and save\n",
    "        plt.title(f'Log Change in FRI - {model} ({period})', fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        out_path = f'/home/users/clelland/Model/Analysis/Summary stats/BA/FRI/Change/ba_fri_log_change_{model}_{period}_continuous.png'\n",
    "        #plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef3ae8-490e-425b-806c-1f9e1d361edf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plot basic ecoregion maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ab64d3-8b59-4128-82db-31538fd32536",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Orginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1e5463-2248-4215-87da-a7bd4f27bc32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boreal/tundra map\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "minx, miny, maxx, maxy = selected_ecoregions.total_bounds\n",
    "buffer = 300000\n",
    "ax.set_xlim(minx - buffer, maxx + buffer)\n",
    "ax.set_ylim(miny - buffer, maxy + buffer)\n",
    "\n",
    "# Background\n",
    "ax.add_patch(plt.Rectangle(\n",
    "    (minx - buffer, miny - buffer), \n",
    "    (maxx - minx) + 2 * buffer, \n",
    "    (maxy - miny) + 2 * buffer, \n",
    "    facecolor='#f8fcff', zorder=0)\n",
    ")\n",
    "\n",
    "# Plot world outline\n",
    "gdf_world.plot(ax=ax, color='white', edgecolor='black', linewidth=0.1)\n",
    "\n",
    "# Default color for other biomes\n",
    "selected_ecoregions.loc[selected_ecoregions['BIOME_NUM'] == 6, 'biome_color'] = 'green'\n",
    "selected_ecoregions.loc[selected_ecoregions['BIOME_NUM'] == 11, 'biome_color'] = 'blue'\n",
    "\n",
    "# Plot the ecoregions with assigned colors\n",
    "selected_ecoregions.plot(\n",
    "    color=selected_ecoregions['biome_color'],\n",
    "    edgecolor='black',\n",
    "    linewidth=0.2,\n",
    "    ax=ax,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Add legend manually\n",
    "legend_handles = [\n",
    "    mpatches.Patch(color='green', label='Boreal', alpha=0.7),\n",
    "    mpatches.Patch(color='blue', label='Tundra', alpha=0.7),\n",
    "]\n",
    "ax.legend(handles=legend_handles, loc='lower left')\n",
    "\n",
    "plt.title('Ecoregions by Biome', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save or show\n",
    "#plt.savefig('/home/users/clelland/Model/Analysis/ecoregions_by_biome.png', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b7949-1e37-4b8b-8a10-d95082e6a1e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Basic map with numbered ecoregions\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Set up map extent with buffer\n",
    "minx, miny, maxx, maxy = selected_ecoregions.total_bounds\n",
    "buffer = 300000\n",
    "ax.set_xlim(minx - buffer, maxx + buffer)\n",
    "ax.set_ylim(miny - buffer, maxy + buffer)\n",
    "\n",
    "# Background rectangle\n",
    "ax.add_patch(plt.Rectangle(\n",
    "    (minx - buffer, miny - buffer),\n",
    "    (maxx - minx) + 2 * buffer,\n",
    "    (maxy - miny) + 2 * buffer,\n",
    "    facecolor='#f8fcff', zorder=0)\n",
    ")\n",
    "\n",
    "# Plot world outline\n",
    "gdf_world.plot(ax=ax, color='white', edgecolor='black', linewidth=0.1)\n",
    "\n",
    "# Plot all ecoregions in a neutral color\n",
    "selected_ecoregions.loc[selected_ecoregions['BIOME_NUM'] == 6, 'biome_color'] = 'green'\n",
    "selected_ecoregions.loc[selected_ecoregions['BIOME_NUM'] == 11, 'biome_color'] = 'blue'\n",
    "selected_ecoregions.plot(\n",
    "    #color='#a6cee3', edgecolor='black', linewidth=0.2, ax=ax, alpha=0.5\n",
    "    color=selected_ecoregions['biome_color'], edgecolor='black', linewidth=0.2, ax=ax, alpha=0.2\n",
    ")\n",
    "\n",
    "texts = []\n",
    "# Annotate each ecoregion\n",
    "for i, row in selected_ecoregions.iterrows():\n",
    "    label = i + 1\n",
    "    # Place label at centroid\n",
    "    if row.geometry.centroid.is_empty:\n",
    "        continue\n",
    "    x, y = row.geometry.centroid.coords[0]\n",
    "    texts.append(ax.text(x, y, str(label), fontsize=7, ha='center', va='center', zorder=5, weight='bold'))\n",
    "adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='gray', lw=0.5))\n",
    "\n",
    "# Final styling\n",
    "plt.title('Ecoregions with Index Labels', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/home/users/clelland/Model/Analysis/basic_ecoregions_with_numbers_coloured.png', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d220f628-80e2-4f17-9a4a-5c6da4c127cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### With permafrost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb2e440-563e-4c11-a8d6-522625baabba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfrost_path = '/home/users/clelland/Model/Analysis/Permafrost shapefile/Brown_et_al_permafrost.shp'\n",
    "gdf_pfrost = gpd.read_file(pfrost_path)\n",
    "gdf_pfrost = gdf_pfrost.to_crs(epsg=6931)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7170124f-66d7-48ee-9b0f-4729b585401b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boreal map with permafrost\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "minx, miny, maxx, maxy = selected_ecoregions.total_bounds\n",
    "buffer = 300000\n",
    "ax.set_xlim(minx - buffer, maxx + buffer)\n",
    "ax.set_ylim(miny - buffer, maxy + buffer)\n",
    "\n",
    "# Background\n",
    "ax.add_patch(plt.Rectangle(\n",
    "    (minx - buffer, miny - buffer), \n",
    "    (maxx - minx) + 2 * buffer, \n",
    "    (maxy - miny) + 2 * buffer, \n",
    "    facecolor='#f0f8ff', zorder=0)\n",
    ")\n",
    "\n",
    "# Plot world outline\n",
    "gdf_world.plot(ax=ax, color='white', edgecolor='black', linewidth=0.1)\n",
    "\n",
    "# Default color for other biomes\n",
    "selected_ecoregions.loc[selected_ecoregions['BIOME_NUM'] == 6, 'biome_color'] = 'green'\n",
    "pfrost_in_boreal = gpd.overlay(gdf_pfrost, selected_ecoregions.loc[selected_ecoregions['BIOME_NUM'] == 6], how='intersection')\n",
    "\n",
    "# Plot the ecoregions with assigned colors\n",
    "pfrost_in_boreal.plot(\n",
    "    color='blue',\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "selected_ecoregions.loc[selected_ecoregions['BIOME_NUM'] == 6].plot(\n",
    "    color=selected_ecoregions['biome_color'],\n",
    "    ax=ax,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Add legend manually\n",
    "#legend_handles = [\n",
    "#    mpatches.Patch(color='green', label='Boreal', alpha=0.7),\n",
    "#    mpatches.Patch(color='blue', label='Permafrost', alpha=0.6),\n",
    "#]\n",
    "#ax.legend(handles=legend_handles, loc='lower left')\n",
    "\n",
    "plt.title('Boreal Biome with Permafrost', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save or show\n",
    "#plt.savefig('/home/users/clelland/Model/Analysis/boreal_with_permafrost.png', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498da93b-60b5-45dc-85e4-17b3b3747e7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Correlation plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77fa75-e012-4205-887c-ac511e6ba22f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157fb41a-3d0a-46b5-ad28-7fb3fa1d1c22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define your variables and time periods\n",
    "climate_vars = ['rh', 'tp', 'rlds', 'rsds', 'wsp', 't2m', 'mx2t', 'mn2t']\n",
    "fwi_vars = ['BUI', 'DC', 'DMC', 'FFMC', 'FWI', 'ISI']\n",
    "all_vars = climate_vars + fwi_vars\n",
    "\n",
    "periods = {\n",
    "    'historical': ('2001-01-01', '2023-12-31'),\n",
    "    '2025_2050': ('2025-01-01', '2050-12-31'),\n",
    "    '2051_2075': ('2051-01-01', '2075-12-31'),\n",
    "    '2076_2100': ('2076-01-01', '2100-12-31')\n",
    "}\n",
    "\n",
    "# Model mapping\n",
    "model_groups = {\n",
    "    'ssp': ['ACCESS_SSP126', 'ACCESS_SSP245', 'ACCESS_SSP370',\n",
    "            'MRI_SSP126', 'MRI_SSP245', 'MRI_SSP370']\n",
    "}\n",
    "\n",
    "# Provide region list as tuples: (region_code, region_model_code)\n",
    "region_pairs = [('alaspen', 'alapen'), ('centcan', 'cancsh'), ('cookinl', 'cookin'), ('copppla', 'copper'), ('eastcan', 'eastcf'), ('eashti', 'eashti'),\n",
    "               ('inteala', 'intlow'), ('mid-bor', 'midbor'), ('midwcan', 'midwes'), ('musklak', 'muslta'), ('nortcan', 'norths'), ('southud', 'sohudb'),\n",
    "               ('watshig', 'watson'), ('nortcor', 'norcor'), ('nortter', 'nwterr'), ('eastsib', 'eastsib'), ('icelbor', 'icelnd'), ('kamcmea', 'kamkurm'),\n",
    "               ('kamctai', 'kamtaig'), ('nesibta', 'nesibta'), ('okhotai', 'okhman'), ('sakhisl', 'sakhtai'), ('trancon', 'trzconf'), ('westsib', 'westsib'),\n",
    "               ('scanand', 'scrusta'), ('uralmon', 'uralfor'), ('ahkland', 'ahklun'), ('berilow', 'berlow'), ('brooran', 'brookr'), ('kalanun', 'kalhar'),\n",
    "               ('pacicoa', 'pacice'), ('novoisl', 'novoisl'), ('wranisl', 'wrangel'), ('alaseli', 'aleias'), ('arctcoa', 'arccoa'), ('arctfoo', 'arcfoo'),\n",
    "               ('beriupl', 'berupl'), ('canalow', 'canlow'), ('davihig', 'davish'), ('canahig', 'canhig'), ('inteyuk', 'intalp'), ('canamid', 'canmid'),\n",
    "               ('ogilalp', 'ogilvi'), ('tornmou', 'tornga'), ('kalste', 'kalste'), ('russarc', 'rusarc'), ('russber', 'rusbert'), ('chermou', 'cherski'),\n",
    "               ('chukpen', 'chukchi'), ('kolapen', 'kolapen'), ('nortsib', 'nesibco'), ('nortrus', 'nwrunz'), ('scanmon', 'scambf'), ('taimsib', 'taicens'),\n",
    "               ('tranbal', 'trzbald'), ('yamatun', 'yamalgy'), ('kamctun', 'kamtund')]\n",
    "\n",
    "for region, region_model in region_pairs:\n",
    "    print(f\"Processing {region}...\")\n",
    "    root = f'/home/users/clelland/Model/Analysis/CMIP and FWI time series/Ecoregion CSVs/{region}'\n",
    "\n",
    "    # Load CSVs\n",
    "    csvs = {}\n",
    "    for var in all_vars:\n",
    "        def read_df(suffix):  # Helper to build file path\n",
    "            return pd.read_csv(\n",
    "                f'{root}/{suffix}_{region}.csv', parse_dates=['date'], index_col='date'\n",
    "            )\n",
    "\n",
    "        if var in climate_vars:\n",
    "            csvs[var] = {\n",
    "                'Observed': read_df('e5l_2001_2023'),\n",
    "                'ACCESS_SSP126': read_df('access_ssp126_climate_2015_2100'),\n",
    "                'ACCESS_SSP245': read_df('access_ssp245_climate_2015_2100'),\n",
    "                'ACCESS_SSP370': read_df('access_ssp370_climate_2015_2100'),\n",
    "                'MRI_SSP126': read_df('mri_ssp126_climate_2015_2100'),\n",
    "                'MRI_SSP245': read_df('mri_ssp245_climate_2015_2100'),\n",
    "                'MRI_SSP370': read_df('mri_ssp370_climate_2015_2100'),\n",
    "            }\n",
    "        else:\n",
    "            csvs[var] = {\n",
    "                'Observed': read_df('cems_2001_2023'),\n",
    "                'ACCESS_SSP126': read_df('access_ssp126_fwi_2015_2100'),\n",
    "                'ACCESS_SSP245': read_df('access_ssp245_fwi_2015_2100'),\n",
    "                'ACCESS_SSP370': read_df('access_ssp370_fwi_2015_2100'),\n",
    "                'MRI_SSP126': read_df('mri_ssp126_fwi_2015_2100'),\n",
    "                'MRI_SSP245': read_df('mri_ssp245_fwi_2015_2100'),\n",
    "                'MRI_SSP370': read_df('mri_ssp370_fwi_2015_2100'),\n",
    "            }\n",
    "\n",
    "    # Output container for plotting\n",
    "    results = []\n",
    "    raw_means = []\n",
    "\n",
    "    for var in all_vars:\n",
    "        df_all = pd.DataFrame({model: df[var] for model, df in csvs[var].items()})\n",
    "        df_all.index = pd.to_datetime(df_all.index)\n",
    "        df_all['month'] = df_all.index.month\n",
    "\n",
    "        # --- Save raw historical mean (2001–2023) before any bias correction ---\n",
    "        raw_historical_mask = (df_all.index >= periods['historical'][0]) & (df_all.index <= periods['historical'][1])\n",
    "        raw_historical_mean = df_all.loc[raw_historical_mask, 'Observed'].mean()\n",
    "\n",
    "        # Compute monthly bias correction for SSPs\n",
    "        bias_diffs = {}\n",
    "        for model in model_groups['ssp']:\n",
    "            if model in df_all.columns:\n",
    "                period = ('2015-01-01', '2023-12-31')\n",
    "                period_mask = (df_all.index >= period[0]) & (df_all.index <= period[1])\n",
    "                diff = df_all.loc[period_mask, 'Observed'] - df_all.loc[period_mask, model]\n",
    "                bias_diffs[model] = diff.groupby(df_all.loc[period_mask, 'month']).mean()\n",
    "\n",
    "        # Apply correction\n",
    "        corrected = {}\n",
    "        corrected['Observed'] = df_all['Observed']\n",
    "        for model in df_all.columns.drop(['Observed', 'month']):\n",
    "            corrected_series = df_all[model].copy()\n",
    "            corrected_series.index = pd.to_datetime(corrected_series.index)\n",
    "            corrected_series = corrected_series + df_all['month'].map(bias_diffs[model])\n",
    "            corrected[model] = corrected_series\n",
    "\n",
    "        corrected_df = pd.DataFrame(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1668da76-5880-4552-97d9-a70e0bd6d965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize nested dictionary\n",
    "correlation_dict = defaultdict(lambda: defaultdict(dict))  # model -> period -> region -> {var: corr}\n",
    "\n",
    "for region_actual, region_model in region_pairs:\n",
    "    print(f\"Calculating correlations for {region_actual}...\")\n",
    "\n",
    "    # Load actual burned area\n",
    "    actual_path = '/home/users/clelland/Model/Analysis/Fire actual 2001-2024.csv'\n",
    "    model_path = f'/home/users/clelland/Model/Analysis/Ecoregion plots combined/area_timeseries_{region_model}_all.csv'\n",
    "    try:\n",
    "        df_ba = pd.read_csv(model_path, parse_dates=['time'], index_col='time')\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {region_actual}: {e}\")\n",
    "        continue\n",
    "\n",
    "    for var in all_vars:\n",
    "        if var not in csvs:\n",
    "            print(f\"Missing variable: {var}\")\n",
    "            continue\n",
    "\n",
    "        for model in model_groups['ssp']:\n",
    "            if model not in csvs[var]:\n",
    "                continue\n",
    "\n",
    "            df_var = csvs[var][model][var].copy()\n",
    "            df_var.index = pd.to_datetime(df_var.index)\n",
    "            df_ba_model = df_ba['mean_ba'] if 'mean_ba' in df_ba else df_ba.iloc[:, 0]\n",
    "\n",
    "            for period_name, (start, end) in periods.items():\n",
    "                if period_name == 'historical':\n",
    "                    continue  # Skip historical\n",
    "\n",
    "                # Slice both time series\n",
    "                var_period = df_var.loc[start:end]\n",
    "                ba_period = df_ba_model.loc[start:end]\n",
    "\n",
    "                # Align by date\n",
    "                df_combined = pd.concat([var_period, ba_period], axis=1, keys=[var, 'BA']).dropna()\n",
    "\n",
    "                if df_combined.empty:\n",
    "                    corr = np.nan\n",
    "                else:\n",
    "                    corr = df_combined[var].corr(df_combined['BA'], method='spearman')\n",
    "\n",
    "                # Store\n",
    "                if region_actual not in correlation_dict[model][period_name]:\n",
    "                    correlation_dict[model][period_name][region_actual] = {}\n",
    "                correlation_dict[model][period_name][region_actual][var] = corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb6018b-5c57-496f-b7c2-2202f573ef54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop over variables and save correlation values for each\n",
    "for var in all_vars:\n",
    "    combined_data = []\n",
    "\n",
    "    for model in model_groups['ssp']:\n",
    "        for period in ['2025_2050', '2051_2075', '2076_2100']:\n",
    "            for region, value_dict in correlation_dict[model][period].items():\n",
    "                if var in value_dict:\n",
    "                    combined_data.append({\n",
    "                        'region': region,\n",
    "                        'scenario': model,\n",
    "                        'period': period,\n",
    "                        'correlation': value_dict[var]\n",
    "                    })\n",
    "\n",
    "    # Create DataFrame and save to CSV\n",
    "    df_combined = pd.DataFrame(combined_data)\n",
    "    out_path = f'/home/users/clelland/Model/Analysis/Summary stats/Correlations/{var}/correlations_{var}_spearman.csv'\n",
    "    #df_combined.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94633ec7-1241-41d0-95b4-4f50edd6d5ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20396c2-1b94-428e-8785-9326c0700ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define your variables and time periods\n",
    "climate_vars = ['rh', 'tp', 'rlds', 'rsds', 'wsp', 't2m', 'mx2t', 'mn2t']\n",
    "fwi_vars = ['BUI', 'DC', 'DMC', 'FFMC', 'FWI', 'ISI']\n",
    "all_vars = climate_vars + fwi_vars\n",
    "\n",
    "# Provide region list as tuples: (region_code, region_model_code)\n",
    "region_pairs = [('alaspen', 'alapen'), ('centcan', 'cancsh'), ('cookinl', 'cookin'), ('copppla', 'copper'), ('eastcan', 'eastcf'), ('eashti', 'eashti'),\n",
    "               ('inteala', 'intlow'), ('mid-bor', 'midbor'), ('midwcan', 'midwes'), ('musklak', 'muslta'), ('nortcan', 'norths'), ('southud', 'sohudb'),\n",
    "               ('watshig', 'watson'), ('nortcor', 'norcor'), ('nortter', 'nwterr'), ('eastsib', 'eastsib'), ('icelbor', 'icelnd'), ('kamcmea', 'kamkurm'),\n",
    "               ('kamctai', 'kamtaig'), ('nesibta', 'nesibta'), ('okhotai', 'okhman'), ('sakhisl', 'sakhtai'), ('trancon', 'trzconf'), ('westsib', 'westsib'),\n",
    "               ('scanand', 'scrusta'), ('uralmon', 'uralfor'), ('ahkland', 'ahklun'), ('berilow', 'berlow'), ('brooran', 'brookr'), ('kalanun', 'kalhar'),\n",
    "               ('pacicoa', 'pacice'), ('novoisl', 'novoisl'), ('wranisl', 'wrangel'), ('alaseli', 'aleias'), ('arctcoa', 'arccoa'), ('arctfoo', 'arcfoo'),\n",
    "               ('beriupl', 'berupl'), ('canalow', 'canlow'), ('davihig', 'davish'), ('canahig', 'canhig'), ('inteyuk', 'intalp'), ('canamid', 'canmid'),\n",
    "               ('ogilalp', 'ogilvi'), ('tornmou', 'tornga'), ('kalste', 'kalste'), ('russarc', 'rusarc'), ('russber', 'rusbert'), ('chermou', 'cherski'),\n",
    "               ('chukpen', 'chukchi'), ('kolapen', 'kolapen'), ('nortsib', 'nesibco'), ('nortrus', 'nwrunz'), ('scanmon', 'scambf'), ('taimsib', 'taicens'),\n",
    "               ('tranbal', 'trzbald'), ('yamatun', 'yamalgy'), ('kamctun', 'kamtund')]\n",
    "\n",
    "selected_ecoregions['region'] = [pair[0] for pair in region_pairs]\n",
    "\n",
    "correlation_data = {}\n",
    "for var in all_vars:\n",
    "    csv_path = f'/home/users/clelland/Model/Analysis/Summary stats/Correlations/{var}/correlations_{var}_spearman.csv'\n",
    "    correlation_data[var] = pd.read_csv(csv_path)\n",
    "\n",
    "# Loop through models, periods, and variables to filter the relevant data\n",
    "#for model in model_groups['ssp']:\n",
    "for model in['ACCESS_SSP126']:\n",
    "    #for period in ['2025_2050', '2051_2075', '2076_2100']:\n",
    "    for period in ['2025_2050']:\n",
    "        #for var in all_vars:\n",
    "        for var in ['rh']:\n",
    "            df_var = correlation_data[var]\n",
    "            df_corr = df_var[\n",
    "                (df_var['scenario'] == model) &\n",
    "                (df_var['period'] == period)\n",
    "            ][['region', 'correlation']]\n",
    "\n",
    "            # Join to shapefile (must match by region name)\n",
    "            plot_gdf = selected_ecoregions.merge(df_corr, left_on='region', right_on='region', how='left')  # adjust 'region_col'\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(10, 10))\n",
    "            minx, miny, maxx, maxy = plot_gdf.total_bounds\n",
    "            buffer = 300000\n",
    "\n",
    "            ax.set_xlim(minx-buffer, maxx+buffer)\n",
    "            ax.set_ylim(miny-buffer, maxy+buffer)\n",
    "            ax.add_patch(plt.Rectangle((minx - buffer, miny - buffer), (maxx - minx) + 2*buffer, (maxy - miny) + 2*buffer, \n",
    "                                       facecolor='#f8fcff', zorder=0))\n",
    "            gdf_world.plot(ax=ax, color='white', edgecolor='black', linewidth=0.1)\n",
    "\n",
    "            norm = Normalize(vmin=-1, vmax=1)\n",
    "            plot_gdf.plot(\n",
    "                column='correlation',\n",
    "                cmap='coolwarm',\n",
    "                edgecolor='black',\n",
    "                linewidth=0.2,\n",
    "                norm=norm,\n",
    "                ax=ax\n",
    "            )\n",
    "\n",
    "            sm = plt.cm.ScalarMappable(cmap='coolwarm', norm=norm)\n",
    "            sm._A = []\n",
    "            cbar = fig.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.05, pad=0.01)\n",
    "            cbar.set_label('Correlation')\n",
    "\n",
    "            plt.title(f'Spearman Correlation of {var} with Burned Area\\n{model}, {period}', fontsize=14)\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "\n",
    "            out_path = f'/home/users/clelland/Model/Analysis/Summary stats/Correlations/{var}/corr_spearman_{var}_{model}_{period}.png'\n",
    "            #plt.savefig(out_path, dpi=300)\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a6cfd5-d334-429f-b657-821709bd99fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e0f094-7dfa-4a9d-a8ce-882bdad68d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your variables and time periods\n",
    "climate_vars = ['rh', 'tp', 'rlds', 'rsds', 'wsp', 't2m', 'mx2t', 'mn2t']\n",
    "fwi_vars = ['BUI', 'DC', 'DMC', 'FFMC', 'FWI', 'ISI']\n",
    "all_vars = climate_vars + fwi_vars\n",
    "\n",
    "# Grouped ecoregions\n",
    "nabor  = ['alaspen', 'centcan', 'cookinl', 'copppla', 'eastcan', 'eashti', 'inteala', 'mid-bor', \n",
    "          'midwcan', 'musklak', 'nortcan', 'southud', 'watshig', 'nortcor', 'nortter']\n",
    "eubor  = ['eastsib', 'icelbor', 'kamcmea', 'kamctai', 'nesibta', 'okhotai', \n",
    "          'sakhisl', 'trancon', 'westsib', 'scanand', 'uralmon']\n",
    "tundra  = ['ahkland', 'berilow', 'brooran', 'kalanun', 'pacicoa', 'novoisl', 'wranisl', 'alaseli', 'arctcoa', 'arctfoo',\n",
    "               'beriupl', 'canalow', 'davihig', 'canahig', 'inteyuk', 'canamid', 'ogilalp', 'tornmou', 'kalste', 'russarc', 'russber', 'chermou',\n",
    "               'chukpen', 'kolapen', 'nortsib', 'nortrus', 'scanmon', 'taimsib', 'tranbal', 'yamatun', 'kamctun']\n",
    "\n",
    "# Combine all groups\n",
    "all_groups = [('nabor', nabor), ('eubor', eubor), ('tundra', tundra)]\n",
    "\n",
    "correlation_data = {}\n",
    "for var in all_vars:\n",
    "    csv_path = f'/home/users/clelland/Model/Analysis/Summary stats/Correlations/{var}/correlations_{var}_spearman.csv'\n",
    "    correlation_data[var] = pd.read_csv(csv_path)\n",
    "\n",
    "# Output containers\n",
    "group_means_by_var = {}  # Stores a dict of DataFrames for each variable\n",
    "all_results = []         # List of rows to build final combined DataFrame\n",
    "\n",
    "# Loop over variables\n",
    "for var, df in correlation_data.items():\n",
    "    group_dfs = {}  # Temporary dict to store per-group results for this variable\n",
    "\n",
    "    for group_name, region_list in all_groups:\n",
    "        # Filter DataFrame to just regions in the group\n",
    "        group_df = df[df['region'].isin(region_list)]\n",
    "\n",
    "        # Group by scenario and period, then take mean correlation\n",
    "        #grouped_mean = group_df.groupby(['scenario', 'period'])['correlation'].mean().reset_index()\n",
    "        grouped_mean = group_df.groupby(['scenario'])['correlation'].mean().reset_index()\n",
    "        grouped_mean['group'] = group_name\n",
    "        grouped_mean['variable'] = var\n",
    "\n",
    "        # Store result\n",
    "        group_dfs[group_name] = grouped_mean\n",
    "        all_results.append(grouped_mean)\n",
    "\n",
    "    # Save per-variable grouped DataFrames\n",
    "    group_means_by_var[var] = pd.concat(group_dfs.values(), ignore_index=True)\n",
    "\n",
    "# Combine all results into one big DataFrame\n",
    "combined_df = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Now you have:\n",
    "# - group_means_by_var['pr']['nabor'] for example\n",
    "# - combined_df for all in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc92c8d-96b8-4264-a8fb-d4d51ba6da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bff4bf-cd63-48d3-85c4-30638e6b6816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
